{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=[\"SFFF\", \"FHHH\", \"FFFF\", \"HFHF\", \"FFGF\"]\n",
    "# env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x4\", is_slippery=False, render_mode='human')\n",
    "env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x4\", is_slippery=False)\n",
    "observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom rewards\n",
    "custom_rewards = {\n",
    "    'S': 0.0,  # Reward for frozen tiles (very small positive reward)\n",
    "    'F': -0.5,  # Reward for falling in a hole (negative reward)\n",
    "    'G': 1.0,   # Reward for reaching the goal (the \"gift\" state)\n",
    "}\n",
    "\n",
    "# Map custom rewards to the environment's reward table\n",
    "env.env.rewards = custom_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom policy to avoid edges\n",
    "def custom_policy(state):\n",
    "    if state % 4 == 0:  # Agent is at leftmost column\n",
    "        return [1, 2, 3]  # Avoid going left\n",
    "    elif state % 4 == 3:  # Agent is at rightmost column\n",
    "        return [0, 1, 3]  # Avoid going right\n",
    "    elif state < 4:  # Agent is at top row\n",
    "        return [0, 1, 2]  # Avoid going up\n",
    "    elif state > 15:  # Agent is at bottom row\n",
    "        return [0, 2, 3]  # Avoid going down\n",
    "    else:\n",
    "        return [0, 1, 2, 3]  # All actions are allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q-table with zeros\n",
    "Q = np.random.rand(env.observation_space.n, env.action_space.n) * 0.01\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.99\n",
    "# discount_factor = 0.0\n",
    "epsilon = 0.1\n",
    "num_episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0018560053549478792\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007428358712197096\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04197755969541828\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007466632321149513\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0023060400837992536\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007501078569206688\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.002117895245535812\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007260799131428129\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0007699933623563967\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04334576608515664\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007469789826297404\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007068722482765935\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005501169322533387\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04345651106341589\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007422614369461491\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006906465997420147\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08804976225929817\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007364093066259936\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006760435160608938\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005365265924478617\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00429673891014673\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.12828335881602554\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0072969668405342275\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0066155529710714275\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16449359571708017\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0072222099006168765\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006485159000487668\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0014951363386369858\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0063678044269622845\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005254116484135282\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00438722255106145\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005163039868276837\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004459641242914711\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00508824036449771\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004517412914708513\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005026640206604082\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004563309003691466\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004975743777309129\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0010921418453897593\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.008901716339630498\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004599576737275924\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004933527496568533\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004628038285708616\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004898350537196832\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00465017116032024\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004868882428348853\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004667173404694753\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004844044352578748\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004680016455130573\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0048229615463788\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004689488002709017\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004804924704009113\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004696226748135018\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0019760353430425537\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006206711529962958\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004789358681673568\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004700750582807199\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004775797121204124\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047034794395256875\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004763861873596755\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004704753821059197\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00475324631452194\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00470484982409095\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00474370181565475\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004703991321431675\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00473502677491101\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047023598400046974\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004727057721580374\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047001025704406845\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004719662103895964\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004697338861682316\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004712732440812917\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004694165487154563\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047061815799599276\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003921489967038564\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.008690458425195053\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0049154459593629485\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.008308041732652479\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005246397494959249\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007996630911388197\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0055266456116010365\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04172141036322344\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007114453352021522\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006051952353382696\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004700285805192237\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004690077233153138\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004694574870755174\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004685832422042587\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004689014793461873\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004681461644391053\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0023775750917231853\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005910969582597151\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004683578016910399\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004676989703626077\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046782421958783404\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004672436710655425\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004672989210645393\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004667818971443777\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027250035712279848\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0057824985561913305\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004667804367753788\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004663149706707024\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004662675751942404\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004321007430562139\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0077441057357978795\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.10338794870413791\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0069754753738823115\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005665853600014496\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046580599977121585\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004657982675809825\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004653394282846115\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004652870442230608\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004648689028342334\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004647803611813438\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004643952683077631\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00464277456625678\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004639192096829289\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004637777127217201\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046344128227408625\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004632806283946827\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004629619362577512\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004627857972447318\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004624815365592045\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004622928896396199\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004620003789776064\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004618016381944409\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046151870326109545\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004613118259978453\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004610367037087726\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004608232770652292\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00460554537767353\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046033584859767425\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004600723330017875\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004598494247050838\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00459590192747412\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004593639113165692\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004591082006930112\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004588792320535204\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004586264245970086\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004583953248832722\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004581449193007517\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004655573155349915\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.017205102083927743\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.19374438796694465\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006838847342895515\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0055528317101207906\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004584206016086407\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00589332094612377\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03466528628426249\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.27506518330347074\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006704692947907922\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005451384934701266\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004709224188144019\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00873585219365338\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05843021080287985\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.3482538991063442\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006573910761652556\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0053724596358573976\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005103151136501302\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.013646857843773147\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.08706432573411994\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.4141237433289303\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006448393189437182\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005340425634785287\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005943874949384713\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.020901540307073706\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.11935614375027205\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.4734066031292578\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006332256008337207\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005394826691295845\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007418739944846539\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03062764450764327\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.15428778308504137\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.5267611769495526\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006233118249941775\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005589799276706068\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00970900275661857\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04283937058229804\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08658784210955828\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006163196553341499\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005992010621940699\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.012979200168604219\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05382992404948733\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19100836129454296\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.5747802933878179\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0061400859495794775\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006677750376438447\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.19708280892802935\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0015933637706569237\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04042731901655982\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006187174641888936\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002687966364966333\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.004253601053352868\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006229554464967449\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00729491615548642\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.017010442632643043\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.06735675941269835\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.22881077421048263\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.6179974981822566\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006328795717863859\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00824945836056944\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.021977717551235877\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0832733501182663\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26711144910947776\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.6568929824972515\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006512612523773848\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.009600306562084849\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.028024007457820653\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10139004856827796\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3054327094657579\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.6918989183807469\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006811781621042863\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.011414652644200609\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.035259221520298104\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1214888819485602\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.34338743143887607\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.7234042606758927\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007260654070714437\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01376385031029006\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.043760698681175755\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1433353494661529\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3806657101019018\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.751759068741524\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00789720984436171\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.016719774448697454\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05357482841020732\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.16668771981962588\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.41702328689712254\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.7772783960005921\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.008762746530346586\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.020351705016438234\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.06471942983132956\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19130425324047842\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4522715194114689\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8002457905337534\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.009901290673939312\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.024723758068096038\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07718660791900396\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.216948708338166\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.021928940571252036\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.24002871792608482\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.48626870073316364\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8209164456135987\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01135881365528689\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.029892856445267825\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09323079020178596\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26416644750605955\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5189125587755935\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8395200351854594\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.013182325077839716\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03613341903071785\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.11006018948470726\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.28912214607423736\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5501337863813947\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8562632658001339\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.015441301054096811\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.043416035886632086\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.12767726299758603\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3146731763185717\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5798904710574684\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.871332173353341\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.018195358501463706\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.051714481334729896\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.14606218115336603\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3406150153214039\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6081633091137023\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8848941901512274\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.021495556303455596\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.061003189135440145\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2264131008178836\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.025385316397518613\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.06936302615607937\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1651768495548484\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.36676168139152004\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6349515030273036\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8971000052693252\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.029713724347218612\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07877923164640142\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.18496857105712405\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.39294571205207107\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6602692532462364\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9080852388756132\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.010886582237642939\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03454149584549049\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08711444379739594\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03888649019393518\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.08921319701641656\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.011284609718730427\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09860376584943019\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.019917921565950972\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10705527779914245\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.20537333944456668\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.41901779691824137\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6841427665702985\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9179719491212724\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04559631367665677\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1166817106242403\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2263187673950159\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0018641975784742027\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04949430660057334\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4448461511168768\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7066077128762747\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9268699883423657\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05258817166079088\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007625398722887997\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.058880843846511585\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.12741909753392286\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.24772665961608512\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.47031569957994035\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7277070704345414\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9348782236413496\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.06560725011771879\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.139202127082523\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2695152479128907\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4953271295949659\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04834512906435311\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07282753568711668\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.15196392391764688\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.29160110895150326\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006577714174083543\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09358226177041763\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5178374166084889\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7474893075315809\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9420856354104352\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.08058921058625206\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.165636041312081\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2528103635187524\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.08892825761752288\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.17794094696707174\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.31370690230059334\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5400551163932665\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7660068546840559\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9485723060026122\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0976515856055107\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19120383559812332\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3358016685934674\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5618842833676614\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.783314827509909\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9544103095355715\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10681560676917384\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.20532781722906426\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3578480457875191\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5832440229543763\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07747720478661009\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6024677885824197\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7994699654029397\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9596645127152349\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.11646149999793382\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.22022199203912224\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.38170755227842673\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6213685362990687\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.814529755621454\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9643932955769319\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.12661732721001354\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.23598884051077426\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.40505228214419187\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.015184586671946535\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.14573952068698368\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6398701284756858\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.0925875532952651\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.13731848969957883\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2524901323919718\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4278941966488656\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6565215614346411\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.13472511888997857\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.671507851097701\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8285517163214249\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9686492001524593\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.14858316383642617\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26960264462101236\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4515840542426514\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6863836859037519\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8415928155043758\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9724795142704339\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.16041550927026377\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2873492015289336\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4743776337228577\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08844550002859378\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.17282152929460182\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.12773763948917582\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.18398694731650606\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.30557766711460316\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.49489185525504337\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7010630060483098\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8537090058667112\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.975926796976611\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19584044162920117\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.32401419407339216\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5148079073283217\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7154738970242833\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8649548581807245\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9790293514121704\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.20833380267954688\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3425787574915568\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5341590324008936\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.028094340552763268\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.20199748442368937\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7295570382817467\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8753832781524569\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9818216504041739\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2214157194032563\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.36120262595008956\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5529692759506971\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7432642789906653\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8850452937272244\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.984334719496977\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.23503320743198952\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3798263216741996\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5712555119757032\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.756557335170594\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8939899015847027\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9865964816804998\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.24913269253453632\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3983979851923743\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5890291369600217\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7694066019104202\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9022639631126019\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9886320676456704\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26366082381512773\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.416872071232179\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6062974768531512\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7817900740675258\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.12696763068125966\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2785650764856007\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4352083143174231\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6230649465005211\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7929351990089207\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099121414982632\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9904640950143239\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2937941919544655\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.45337091258923234\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6392590365523522\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8037229811163568\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.916976872754855\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.992112919646112\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002110338977367111\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007090208824305168\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.040682849394865654\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.30929849310535296\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.47132046594899196\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6549017080276363\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8141313934074517\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9234983645243345\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9935968618147214\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.32502936992376785\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.48902368844882876\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6700105451722104\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8241445921546157\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9295146173915585\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9949324097664698\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3409397780878251\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04061589688129389\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.35525914543547665\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5064523635759948\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6845998052782962\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8337520800609184\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9350614642192832\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9961344029230433\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.36987201488595245\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5235825079409466\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0697607976955096\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5389996378694033\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.27656789994953435\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.38624577754642814\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5528750548050143\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6986812806764975\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8429479570125356\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9401726236867362\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9972161967639596\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4023558302174817\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5667569961114861\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7122650003530887\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8517302510562689\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9448797647976945\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9981898112207841\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4182291898107707\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07795899698443079\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.021606765777387647\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.43251521344473076\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5805955315352933\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7253597951723505\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8601003226656138\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9492125796287827\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9990660642319262\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.44674264972225175\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5943465981038267\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7379737475990112\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8680623357823019\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9531988620248651\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9998546919419541\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.46090869796230544\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6079713393057462\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.750114544081558\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8756227895445333\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9568645903246321\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0005644568809793\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.47500699075734376\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6214355452392458\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7617897458383109\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8827901050322186\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9602340125233858\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.001203245326102\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.48902841066029473\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6347091755533141\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7730069916526695\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8895742617688119\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9633297325583313\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0017781549267122\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5029617779740434\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.647765950171597\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7837741444025149\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8959864791152056\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9661727966402427\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0022955735672614\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5167944292436272\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6605829954502863\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7940993913946688\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.902038938071069\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9687827787593773\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0027612503437557\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5305127028688428\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6731405356533299\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8039913071242377\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9077445393611405\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9711778646674715\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0031803594426008\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.06196684678366432\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5441023456116382\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6854216214932964\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8134588858085668\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9131166940271062\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9733749337855417\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0035575576315612\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5575488515783107\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6974118890390149\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8225115499363936\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9181691430691642\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9753896386125122\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0038970360016255\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026012357532366115\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007123620680315968\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007437905463018703\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006995597474784338\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007386679066720483\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007027318954911232\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007343715736584646\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007051614917341988\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007307454039743038\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007069891375542351\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007276627881947427\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007083288398300911\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007250210645184474\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007092730412344083\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007227369891488091\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007098966990366995\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007207430634385614\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007102605924134471\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0071898455574363656\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007104140041907224\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007174170865841544\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007103968953434815\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007160046705647436\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00710241668195043\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007147181286595785\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007099745961128369\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0071353380080879155\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007096934877575241\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 1\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006297666804164789\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00711842212484408\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 3\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0028640772823520346\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007124400760159072\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007092557065073465\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0071141238335854385\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007087599618091077\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007104383812417911\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007082173653711342\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.0858603383872438\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5708377434353421\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7090993435788163\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8311591401066015\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9229158029848865\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772364813154218\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0042025665346834\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5839548041061107\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7204741640914882\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8394118905914452\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9273706343366246\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9789288872708133\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0044775440144356\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5968862659405569\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7315285248508925\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8472803943316265\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9315475307427726\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9804792754011611\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0047250237462126\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6096189633067396\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7422564314046343\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8547755604419983\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9354602259332103\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.98189912521192\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0049477555048119\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6221404536851244\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7526535687479287\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8619085667651863\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9391222167358694\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9831990404857044\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10231068605852567\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9843689642321103\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0051482140875512\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6344391116226569\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7627171599828892\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8686908095455188\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9426625225212614\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9854417410035669\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0053286268120165\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6465041992986972\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7724458341296067\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8751453183205717\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9459550026284883\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9864251009575998\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0054909982640354\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6583259169476585\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7818406372303826\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8812803317487349\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9490155873604419\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9873261996899794\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0056371325708524\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6698955483387006\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.790903326350469\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8871048417225451\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9518593223937056\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9881516558454958\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0057686534469876\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6812054228135269\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.799636373045954\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1419487188575081\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8074961150718906\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8926284304672675\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9545004040830392\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9889075869521979\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0058870222355094\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6930269959242914\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.815116718180961\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8978611274247617\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9569522147830029\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9895996434582935\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.005993554145179\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7044208514317774\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8224932979779163\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9028132839458027\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9592273580070736\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9902330409728369\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0060894328638816\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7154056027884134\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.829622483290759\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9074954639939228\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.961337693262677\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9908125907290775\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006175723710714\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7259976683553572\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8365022858970815\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9119183492275356\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.963294370418588\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9913427283035304\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0062533854728632\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7362116278236326\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8431319738808994\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9160926569762222\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9651078634787787\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9918275406349908\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0063232810587974\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7460605304554784\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8495119495334555\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2979496827372381\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7555561604137426\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.855253927620756\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9200290697629991\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9667880036537649\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9922707913963127\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19031442580090807\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9926697170815024\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0063861870861381\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7646706832068232\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8608114127652173\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9237381751484219\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9683835052794572\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9930349778948798\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0064428025107448\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7734239447498974\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8661803508283894\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.927234324656246\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9698556175631046\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9933693175539555\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0064937563928908\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7818334050069182\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8713585138865189\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9305265983293688\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9712136182446357\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9936752676814562\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0065396148868222\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030458359682725145\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0835353558133127\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7899145573809918\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8763447957324745\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.21451198174927227\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8808324493938345\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9336240867026508\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9724661079206363\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9939551627871059\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0065808875313604\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7981255141328822\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8851779890380135\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9365358227165288\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9736210582444961\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.994211154374\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006618032911445\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8059455836343573\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8893772365831485\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.939270725211081\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9746858567030725\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.994445224194833\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0066514637535209\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8133993716926533\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8934273147207307\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9418375525035771\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9756673482280538\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9946591966869484\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0066815515113894\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8205087386807404\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8973265009465118\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9442448647277968\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9765718738772563\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9948547506178811\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006708630493471\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01101125259696322\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.15641218536137474\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.827293188406371\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.15206512293821844\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8333991931594386\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9010740924599125\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9465009937688655\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9774053068007009\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9950334299749466\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0067330015773444\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8392656089970261\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.904670281597039\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9486140197652484\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9781730856881505\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.995196654133609\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0067549355528305\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8449014059754303\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9081160413940947\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9505917532718504\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9788802458785628\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9953457273399784\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0067746761307679\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8503147534759027\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9114130208285984\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.952441722286643\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9795314482973644\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9954818475429266\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0067924426509116\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8555131671903436\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9145634492521162\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9541711634394178\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9801310063743777\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9956061146110742\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006808432519041\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.1304659656571419\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8605036319472688\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.917570049507407\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9557870167265394\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9806829110834363\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9957195379693518\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068228234003573\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8652927036537752\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9204359592125937\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9572959232511457\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9811908542340585\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.995823043689052\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068357751935422\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8698865932504445\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9231646596931977\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9587042254952028\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9816582501358688\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9959174810643074\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068474318074085\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.025394933688043\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2268897395570313\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.1935381418232217\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8742912352350266\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16429851561177772\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.2507391599291672\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8782554130211505\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.925759912047903\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9600179697091336\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04528265745543219\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2789819027447714\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9820882557476484\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9960036287068101\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068579227598882\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8820801030117779\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9282256998443169\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2849551278589324\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.22418454084256262\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8857664369951874\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9304449088610894\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9612429100572374\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9824837894148577\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9960822001893581\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068673646171198\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8893038392729166\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.932563466070647\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9623845142035845\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9828475482921184\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9961538492675172\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068758622886282\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.892697238486619\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9345831863697371\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9634479700641457\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9831820245403907\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9962191747073397\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068835101929858\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.895951250088561\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2904652605170739\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8988798605303089\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9365062167691138\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9644381934872298\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9834895203823782\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9962787247457113\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068903933069078\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9017059899374202\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9383349762474382\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9653598366563623\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9837721620939659\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9963330012085241\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068965881094376\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9044305535921746\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9400721024516743\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9662172970380287\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9840319130042132\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996382463310506\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069021634317143\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9070546363756729\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9417204046132717\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670147267216429\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.984270585571532\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996427531159195\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069071812217634\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9095794927948194\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9432828220973871\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3498446144606805\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.19720330412211942\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9120065429029788\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.944688997833091\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9677560420210602\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9844898525991391\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9964685889842301\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069116972328076\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9143300993981569\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9460279462098669\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.968444933226269\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9846912576486639\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996505988111855\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069157616427473\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.916553856133118\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9473011999782808\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9690848744108599\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9848762247068712\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9965400497033015\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006919419611693\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.918681289317656\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9485104825471278\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9696791332157542\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9850460671568109\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9965710672745289\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069227117837443\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9207156981580561\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9496576684807747\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9702307805427031\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9852019961013081\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9965993090136667\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069256747385904\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9226602375218472\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9507447489064248\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9707427001024622\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.1289355900972539\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9245179439113985\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.951773801325926\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9712034277062455\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9853451280835303\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9966250199114205\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006928341397952\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9262917558515253\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9527455605362517\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9716322526158904\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9854764922464079\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9966484237186757\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26995117716896616\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9966694871452053\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069307413913773\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9279843907594617\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9536625974915997\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9720312000866957\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9855991222491424\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9966886818284312\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00693290138546\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9295985488351839\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9545274265510225\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9724023931806912\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9857113895252428\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967061708827486\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3416299703694617\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967219110316343\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4061424425246473\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967360771656314\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069348453801346\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9311369091802167\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9553425208208087\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9727475814256211\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.985817122212116\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967490191417016\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069365949753417\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9326021278234551\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9561102792998644\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9730687183820586\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9859135628859329\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967608401300903\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006938169611028\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9339968326917961\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9568330544897017\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9733672892695601\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9860015297702185\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996771634908573\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069395867831457\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9353236218170969\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575131106784179\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9736447117898557\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9860817686491453\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967814905092471\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069408622380516\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9365850575925506\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9581526260777719\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9739023357071355\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9861549593446463\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967904868198896\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037344806231608997\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 16\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0007878448412487107\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 3\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04080082844681529\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.937783661814995\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.958753694705001\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9741414431115419\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9862217216053507\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967985834994677\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069420101474669\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9389219114092906\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9593183281025436\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9743632492393175\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986282609211263\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968059841541201\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069430432659408\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9400022347505134\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9598484569669816\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.31719328724617146\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9410270085151932\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9603255729449759\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3345125313042115\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9419965393852264\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9607549773251707\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9745689026273008\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9863381407213946\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968127470220363\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069439730725671\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9429116282018957\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9611618009527564\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.41001517130893533\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9615279422175835\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9747594882959888\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9863887886044367\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968189256540168\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006944809898531\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9438117316612469\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9618763373371281\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9749360295382291\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9864349833837407\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.1324057351030859\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9446563158914979\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9622073705276999\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3500998509564475\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9454492139845904\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9625053003992146\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9750994899393965\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9864765586851143\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968245692685697\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069455630418984\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9461923173256536\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9627896198632934\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9752507202552833\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.06837360008162134\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3487448917801206\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9865145351741913\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968297230828607\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006946240870929\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9468892579595543\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.963060479182237\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9753905872119999\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9865492242419753\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968344286207966\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069468509170567\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9475433196026403\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9633180993980013\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9755199016907554\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9865809102512366\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968387239995056\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069473999585716\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481574794827784\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9635627597255859\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9756394216365523\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986609852902064\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968426441954537\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069478940959349\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9487344447473336\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.963794786495046\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9757498549102014\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9866362893872076\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968462212914059\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006948338819562\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9492766841356098\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.35539712619479186\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9497646995850584\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9640145434816514\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.36412843864345995\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.950225669431236\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9642123247695962\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9758518620685148\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986660436356336\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968494847054019\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069487390708263\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9506601226403024\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.22681761378142695\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9510511305284622\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.25347049247480374\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.951403037627806\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9644004266374195\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9759460590609406\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9866824917065372\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968524614028735\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006949099296964\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.30985414466140326\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9517383761021299\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9645790438207107\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9760330198337936\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986702636214768\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968551760929856\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006949423500488\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9520578638301672\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9647484084021852\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9761132788356763\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9867210350264968\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968576514102353\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069497152836597\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9523621698789668\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9649087821666986\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9761873334197319\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9867378390134603\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968599080822941\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069499778885143\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9526519223255733\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9650604499585822\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9762556461400912\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09606198435969114\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4115574486644411\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9867531860122615\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968619650850276\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069502142328834\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9529277146389156\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.965203713930593\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.976318646941296\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9867672019544531\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968638397855802\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069504269428156\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9531901108541527\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.965338888584722\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9763767352406573\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9867800018977803\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968655480743609\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069506183817545\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9534396497386249\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9654662965150749\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9764302819044718\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986791690967364\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968671044867186\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069507906767996\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9536768481197548\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9655862647721101\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.37675416756177116\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9539022035202183\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9656942362034417\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9764796311197936\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868023652148127\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.1682420987301246\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9541157125523372\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9657962960639571\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9765251021640807\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868119720375166\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968685223150499\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069509457423402\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9543179746074352\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9658926515718054\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9765669771793868\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868207585429548\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968698137120365\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069510853013268\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9545095496523004\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9659835171553841\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9766055345572007\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868287942461509\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968709897856642\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069512109044148\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9546909628854534\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9660691133610085\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.46465449640078166\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9661461499460705\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9766410317318496\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10081302006540256\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9766729791890335\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868361428103165\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968720606866349\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069513239471939\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9548703354415691\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9662221598911778\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9767024594083515\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868428625372617\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968730356887436\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006951425685695\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9550392957266387\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9662934873834867\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.38811732358825124\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.95519842140494\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9663576821265649\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9767296568587053\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868490068167212\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996873923262753\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006951517250346\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9553479897949759\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9664181499429203\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9767547428476901\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868546245380616\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996874731144262\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069515996585319\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9554885876598275\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9664750544905496\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9767778763921893\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868597604675374\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968754663960304\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069516738258992\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9556207592884092\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9665285588043214\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9767992050392565\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868644555939907\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968761354651914\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069517405765298\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9557450106811961\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9665788242227756\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.976818865639136\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868687474456456\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968767442357487\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069518006520974\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9558618132111313\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9666260094987725\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9768369850723413\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868726703804201\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968772980767314\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069518547201082\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9559716068303966\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9666702700710571\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9768536809327688\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868762558519746\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996877801886349\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006951903381318\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9560748028843916\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9667117574762956\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9768690621688374\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868795326535257\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968782601324646\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069519471764066\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9561717865861057\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9667506188833809\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9768832296846527\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868825271412871\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968786768896825\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069519865919865\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9562629191969498\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9667869967338234\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9768962769031748\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986885263439237\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968790558733209\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069520220660084\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9563485399539033\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9668210284738554\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769082902933418\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868877636267721\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968794004705237\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069520539926282\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9564289677774247\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.41454388138527776\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9565013528185939\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9668528463655107\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769193498630581\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16537667115904797\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9565696493269201\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9668825773654024\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769293034758026\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868900479106767\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968797137687415\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069520827265859\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.956634059553403\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9669103206729666\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3983441640120833\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9566947753446864\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9669352896497744\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769384878713794\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868921347827144\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968799985817993\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069521085871478\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9567518914855454\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9669586709840635\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769469604277302\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868940411640411\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996880257473747\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069521318616534\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9568056107644132\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4678132487124269\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9568539581153941\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9669805529680024\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769547744601973\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986895782537538\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996880492780676\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069521528087086\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9568996370476869\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670010203427617\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769619794853939\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868973730690711\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.21895544693481878\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868988045474509\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968807066306706\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069521716610583\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9569427743568516\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670201542775395\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769687631870522\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869001140491422\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968809009620483\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952188628173\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9569834921946428\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670380464053037\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769749981592121\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.12719997334150168\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4681048150888621\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.18745224287662432\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.976980609634156\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869013118394708\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968810775400325\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952203898576\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9570219095693037\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670553221185547\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.976985778542848\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986902407331987\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968812379719882\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952217641939\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9570581955021102\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670713819824412\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769905390144299\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869034091580151\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968813837213414\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069522300109657\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9570924427681609\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670863071466257\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769949226196304\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.16082235270114886\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5189977710866194\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869043252306264\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968815161202929\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069522411430896\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9571247428988607\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671001737713065\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769989585554993\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869051628034727\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968816363814295\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952251162001\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957155185812334\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671130532911703\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770026738174932\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986905928524887\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968817456083247\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069522601790215\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9571838595069265\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671250126699851\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770060933597077\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869066284876225\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968818448052154\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00695226829434\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0453175245353848\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2989619676925139\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9572108498105624\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671361146455977\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770092402440115\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869072682745765\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968819348858334\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069522755981264\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9572362401794203\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671464179651951\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770121357787934\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869078530008164\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968820166814646\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069522821715342\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9572601115400327\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671559776107761\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770147996479949\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869083873521998\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968820909483\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069522880876014\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9572825421694963\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.96716484501485\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770172500310632\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869088756208615\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968821583741426\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069522934120618\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9573036076090168\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671730682664402\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770195037144221\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869093217378154\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968822195845225\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069522982040762\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9573233806064927\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967180692307524\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5139399352991484\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671875539444994\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770215761950236\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869097293029017\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968822751482738\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523025168892\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9573426103863488\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671939345933568\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770234817765086\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869101016122906\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968823255826185\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523063984207\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9573605488724563\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671998658298955\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770252336584745\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869104416837409\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968823713578002\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523098917992\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9573772807023703\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967205377379095\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770268440193174\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986910752279789\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968824129013083\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523130358398\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9573928849926636\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672104971990979\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770283240930847\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869110359290396\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968824506017256\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523158654763\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0703830068834052\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3638476665375362\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.36365062580953667\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957407435716108\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672152515644035\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770296842407512\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869112949457065\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968824848122353\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523184121492\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574210020493731\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672196651477974\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977030934016301\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869115314475472\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968825158538145\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523207041549\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574336486940678\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672237611006315\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770320822279781\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869117473723201\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968825440181444\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00695232276696\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574454361736235\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672275611311382\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.97703313699504\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869119444928844\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2947641847461325\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869121219013923\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882569570259\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523246234844\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574564211082439\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672310855805333\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770341233637738\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869122840987088\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882592750958\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523262943565\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574666564698924\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672343552354936\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770350271531686\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869124323711828\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968826137790036\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523277981414\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957476191991217\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672373874001079\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770358552425988\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869125678981858\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968826328531192\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523291515479\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957485074144706\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672401983291143\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770366139402593\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869126917608261\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968826501538105\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523303696135\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574933463648176\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672428032762885\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770373090305552\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869128049499707\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968826658450212\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523314658726\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575010492526884\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672452165426846\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770379458175468\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869129083736308\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968826800756404\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523324525058\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575082207651453\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5158252376969336\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575146751263566\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672474515243532\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770385291647815\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913002863756\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.20049482599445945\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575207053146318\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672495207592312\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770390635318152\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869130879048689\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968826929808744\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.46421958487728915\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882704595585\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523333404757\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575263373383326\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672514359729578\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770395528812157\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869131668693449\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827151367337\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523341396487\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575315957658221\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672532081109024\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770400011131593\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869132389809471\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827247028855\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523348589042\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575365037922192\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967254847410015\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770404116609571\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913304828438\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827333836285\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523355062344\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575410833065888\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672563634234482\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770407876728767\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869133649505734\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827412603829\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523360888315\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575453549548513\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5590397040677705\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575491994382875\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672577650607181\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770411320356958\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869134198402939\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16330944039579087\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575527982354699\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672590606261802\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770414473963153\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869134692410424\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882748407139\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952336613169\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575561654139148\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672602578557974\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770417361115469\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869135144092449\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827548911288\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523370850726\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575593144002472\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672613639452607\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770420004269075\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.19817364411466265\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575622579908033\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672623855929985\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977042238310732\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869135557025421\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827607734381\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952337509786\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575650083654298\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672633286264611\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770424564942105\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869135934488583\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827661095631\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952337892028\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575675770629064\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672641989567419\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770426565962265\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869136279488192\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827709499175\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523382360457\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575699750533332\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967265002064094\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770428401035369\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869136594779792\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827753402942\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523385456616\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575722127523452\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672657430279348\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770430083815032\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869136882888704\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827793222853\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952338824316\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.4120852122910652\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575743000368762\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672664265549101\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40754832039353217\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575762462621247\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967267041729188\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977043162683951\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.22769091977471587\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575780587671018\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672676106619803\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977043301556154\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869137146128896\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827829336641\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952339075105\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575797463459277\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672681364498416\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770434291472148\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869137386620334\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882786208733\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952339300815\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.4556770859502055\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575813172198693\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672686222904316\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770435463600345\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869137606304946\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827891786405\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523395039541\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575827791046351\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672690711510319\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770436540264501\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869137806961306\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827918716678\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523396867792\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575841392381237\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672694857845473\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977043752912722\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869137990218126\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827943134921\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523398513218\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575854044069815\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672698687444521\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770438437246093\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869138157566671\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968827965274238\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523399994103\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09936562518228076\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.42226385492007373\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575865809719841\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672702223987432\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770439271120585\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.25425646786876377\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.13123318430113998\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4748385409442928\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575876748922613\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672705489429626\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770440021607627\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869138310372154\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882798534623\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523401326896\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575886917483885\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672708502625819\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770440712173708\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869138449884216\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882800354297\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5164890236246357\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828019920035\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523402526412\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575896367495452\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672711282868434\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770441347494875\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869138578867878\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828034778147\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523403605976\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575905147749882\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672713847983583\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770441932053308\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869138696424127\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828048257323\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523404577583\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575913303925269\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672716214458502\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770442469793965\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869138803559189\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828060484771\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952340545203\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575920878764134\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672718397522254\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770442964366928\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869138901191262\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828071576045\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5635315191707749\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828081558191\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523406239032\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575927912242423\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672720411242355\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044341914817\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869138991146397\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828090620035\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523406947334\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575934441731174\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672722268613788\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770443837356847\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913907300314\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828098845818\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523407584806\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.16511888142451098\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5221564378230021\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575940502150821\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672723981650737\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770444221848473\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139147488563\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828106312132\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6058697655061875\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828113031815\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523408158532\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575946126119163\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672725561448662\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770444575264994\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139215929856\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828119136328\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523408674883\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575951344090664\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967272701825503\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044490011555\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139278131367\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2295222805323608\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575956184488845\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672728361540966\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770445198639001\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139334112726\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828124681509\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00695234091396\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575960673832516\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672729600052131\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044547285226\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139385044923\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828129718179\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523409557846\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.4949113880261269\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575964836854426\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672730741859292\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770445724686482\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913943138253\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828134292588\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523409934267\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2003004806265371\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5647428459255608\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575968696613053\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672731794417325\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770445955924704\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139473539243\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828138446821\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6439741875261923\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828142185632\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523410273045\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575972274599063\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672732764612139\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770446168212619\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139512261697\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.99688281455841\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523410577945\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575975590835758\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672733658803974\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770446363105265\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139547448352\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828148672907\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523410852357\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575978663973775\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672734482870997\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770446541992126\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139579422135\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828151479999\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035274276943776956\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 3\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08575931838479095\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.5302224379968545\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575981511380627\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672735242241118\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770446706155704\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139608476442\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828154006383\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523411099326\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.5620024111598373\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575984149224435\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672735941926421\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770446856779301\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139634875429\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828156304578\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00695234113216\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575986592552707\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967273658655493\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770446994954038\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2654344438390069\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770447119311302\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913965886204\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828158394958\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523411521644\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2361799743105139\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6030708285992765\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575988855366374\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672737192711256\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770447233607513\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139680656936\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828160296105\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523411701684\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575990951908151\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672737749567274\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770447338631798\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139700460557\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828162024961\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523411863721\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2722659889107909\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6375660561632396\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575992893924496\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672738261135094\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770447435114213\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139718454973\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.25564698961647203\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575994692384421\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672738731097892\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770447523729835\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139734649948\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828163596973\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412009553\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957599635752467\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672739162837356\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770447605087196\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139749381053\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828165026222\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6782681676073327\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828166312546\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412140804\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.95759978988931\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672739559457253\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.97704476797672\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139762907889\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882816748323\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341225893\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575999325390059\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.27745808329884286\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576000609237321\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.29904691504047803\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576001764699856\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967273992380848\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770447748318362\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913977519794\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828168548541\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412365242\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957600284068691\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967274025851115\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770447811231121\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139786364451\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828169517846\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7091327497248261\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817039022\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412460923\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576003842210823\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672740565971916\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044786895809\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139796596638\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828171184829\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412547037\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576004774020961\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672740848401575\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770447921925348\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139805884272\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828171908503\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341262454\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576005640610621\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672741107832027\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770447970515356\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139814314787\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828172567482\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341269429\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957600644622493\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672741346129844\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448015080984\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139821967489\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828173167469\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412757067\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576007194869292\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672741565009877\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448055947667\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913982891432\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828173713672\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412813566\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957600789031834\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672741766047708\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448093415418\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139835220541\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828174210848\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412864414\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576008536125229\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672741950691064\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044812776071\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913984094536\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817466334\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412910177\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576009135631122\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672742120270268\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044815923823\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139846142495\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828175075114\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412951364\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576009691974766\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672742276007826\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448188082513\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139850860682\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828175449788\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523412988433\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576010208102065\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672742419027213\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044821450947\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139855144142\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828175790664\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413021795\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576010686775552\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672742550360929\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448238717793\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139859033004\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828176100755\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341305182\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576011130583729\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672742670957898\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448260890281\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139862563678\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828176382809\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413078842\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576011541950188\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672742781690246\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448281195057\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139865769209\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828176639334\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413103163\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576011923142503\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672742883359532\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448299786703\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139868679582\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828176872614\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7369108737033824\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828177082566\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413125052\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576012276280846\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672742976702462\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448316807311\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139871342798\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817727369\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413144752\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576012603346306\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967274306239614\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448332389516\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139873758613\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828177447652\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413162482\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.590604694816982\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576012906188893\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743141063088\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448346652667\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139875950069\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828177605973\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413178438\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576013186535249\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743213275393\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448359706457\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139877938053\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828177750041\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00695234131928\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576013445995988\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743279558793\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448371651679\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139879741502\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828177881124\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413205725\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957601368607271\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967274334039643\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.41583206113683613\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576013908164686\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743395150304\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044838258092\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139881377583\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178000378\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413217358\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576014113468097\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743445510784\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448392579208\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139882861863\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817810886\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413227828\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576014303226854\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743491825048\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448401724612\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139884208453\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178207528\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341323725\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576014478594849\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967274353441328\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448410088788\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139885430154\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178297263\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341324573\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576014640642279\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743573570741\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448417737494\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139886538567\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178378863\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341325336\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.30815842957987255\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6686119954892742\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576014790361554\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743609569678\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5583061035039734\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743641968722\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448424731063\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139887544218\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817845306\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341326023\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576014931880302\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743671820225\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448431124834\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913988845665\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178520517\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413266412\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576015062202474\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743699319561\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448436969559\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139889284516\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817858184\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413271977\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576015182214863\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743724647591\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044844231177\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139890035666\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178637582\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413276984\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576015292733489\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743747971697\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448447194124\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913989071722\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178688245\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7619111853020577\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178733842\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413281491\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576015394509337\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3184768636079497\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576015486107602\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743769446746\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448451655717\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139891340148\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178775325\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413285548\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957601557067207\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743789215987\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044845573282\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139891904891\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178813062\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413289199\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576015648737245\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743807411938\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448459458122\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139892416895\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178847386\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413292485\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576015720797302\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743824157097\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448462861583\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1961208967686093\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5648024789128847\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139892881097\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178878604\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413295443\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576015787309125\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743839564685\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448465970654\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139893301969\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178906992\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413298103\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576015848695116\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743853739311\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448468810483\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139893683565\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178932805\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413300498\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576015905345796\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743866777618\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448471404107\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139894029556\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178956274\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413302655\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.95760159576222\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743878768862\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448473772623\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139894343272\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178977609\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413304595\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016005858098\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743889795465\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448475935345\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139894627728\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828178997003\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003341080058472812\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10120096482383263\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341330634\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957601605036204\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743899933518\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448477909955\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139894885658\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2791592277921721\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016091419254\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743909253252\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044847971264\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139895117796\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817901463\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413307913\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016129293401\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743917819479\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448481358038\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2781654611534069\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016164228189\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743925691977\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448482838896\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139895328465\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.362992251235271\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139895518066\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179030651\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413309327\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016196448877\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967274393292383\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448484211295\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139895690294\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179045209\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7844114657443995\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179058312\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00695234133106\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016226163448\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3359638173186742\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016252906563\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743939568365\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448485463504\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139895848038\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817907023\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413311745\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016277633175\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743945672415\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448486606109\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139895991187\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179081071\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413312775\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016300491427\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743951279178\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4232874278058097\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016321618923\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743956325265\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448487648626\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896121094\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179090928\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413313703\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016341133232\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743960969953\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4299972578078859\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016359155934\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743965150171\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448488599752\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896238986\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179099892\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413314538\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016375790208\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967274396900653\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448489467437\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896345978\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3003202421503022\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016391142834\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743972563154\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448490258945\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896442269\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179108042\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413315289\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016405312303\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743975842474\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448490980835\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896529738\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179115452\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413315966\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016418389478\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.35170207565832623\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016430158936\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743978865329\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448491639196\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896609194\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179122188\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413316575\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957601644105071\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743981651076\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448492239587\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.33561843952827813\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448492779938\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896681371\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817912831\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413317123\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016451129096\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743984271183\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.97704484932734\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896746937\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179133874\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413317616\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016460459034\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743986678131\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448493724007\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896806497\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179138931\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341331806\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016469094265\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743988888994\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448494135449\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896860601\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179143526\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341331846\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016477084849\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743990919505\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448494511104\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913989690975\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179147701\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341331882\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016484477394\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743992784153\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448494854058\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896954398\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179151494\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413319144\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016491315286\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743994496289\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448495167138\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139896994956\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817915494\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413319434\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957601649763889\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743996068207\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448495452925\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.98691398970318\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996882817915807\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413319696\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016503485754\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743997511226\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044849571378\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897065269\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179160913\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413319932\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3435351741753234\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6965533593248557\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957601650889079\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672743998835768\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448495951864\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897095672\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179163496\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413320143\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016513886452\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744000051425\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044849616915\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897123291\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179165841\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8046617181437014\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179167951\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413320334\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016518502898\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744001167028\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448496367441\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897148589\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179169869\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413320505\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016522768144\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744002190702\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4360361048097545\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016526708209\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744003112008\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448496548407\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897171547\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179171612\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341332066\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016530345477\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5979382973114137\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016533619018\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3658665081640131\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016536565205\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.96727440039591\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044849671355\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897192382\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179173196\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00695234133208\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016539300636\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744004737831\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044849686424\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913989721129\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179174636\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.013025867570184962\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1907691501333253\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413320924\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016541839617\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744005453607\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497001734\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897228449\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179175944\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321038\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016544195562\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6329470313678084\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016546315913\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744006111418\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497127177\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897244023\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179177132\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341332114\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016548289352\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744006715867\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497241617\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897258157\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179178211\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341332123\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016550125288\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.96727440072712\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497346013\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.23242425250412396\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.606026716004452\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897270984\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179179191\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321313\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016551832608\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744007781335\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497441239\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897282626\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179180081\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321386\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.95760165534197\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744008249885\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497528095\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897293191\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.31936515507261926\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016554894469\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744008680177\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497607311\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.98691398973027\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179180891\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321453\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957601655626436\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744009075284\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497679547\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897311339\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179181626\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.030609426676365674\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.27138051691187515\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321513\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016557536376\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967274400943803\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497745414\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897319186\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179182293\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321566\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016558717104\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744009771023\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.44147106711143624\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016559812726\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744010070716\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497805472\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897326314\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.42439751109527446\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913989733273\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179182899\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321615\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016560828454\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744010346386\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497860865\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897338565\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179183449\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006952341332166\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016561769901\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744010599973\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448497911297\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897343869\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179183948\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00695234133217\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016562642309\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744010833194\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4463625331829498\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016563450565\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744011043093\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044849795721\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897348693\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179184401\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321735\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016564198774\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744011236547\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977044849799901\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986913989735308\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179184813\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321766\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016564891314\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744011414794\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448498037064\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897357069\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179185186\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321795\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016565532247\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744011578984\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448498071708\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869139897360695\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968828179185525\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069523413321821\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576016566125342\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672744011730184\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770448498103246\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22140\\3712494113.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Take action and observe the next state, reward, done flag, and info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mstep_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Extract the next state tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \"\"\"\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\wrappers\\order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\wrappers\\env_checker.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\envs\\toy_text\\frozen_lake.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"human\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"prob\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\envs\\toy_text\\frozen_lake.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# self.render_mode in {\"human\", \"rgb_array\"}:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_gui\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_render_gui\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\envs\\toy_text\\frozen_lake.py\u001b[0m in \u001b[0;36m_render_gui\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[0mpygame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[0mpygame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"render_fps\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"rgb_array\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             return np.transpose(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state_tuple = env.reset()  # State is a tuple\n",
    "    state = state_tuple[0]  # Extract the integer state value\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Choose action using epsilon-greedy policy\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.choice(custom_policy(state))  # Custom policy\n",
    "        else:\n",
    "            action = np.argmax(Q[state, :])\n",
    "\n",
    "        print(\"Episode:\", episode)\n",
    "        print(\"Action:\", action)\n",
    "\n",
    "\n",
    "        # Take action and observe the next state, reward, done flag, and info\n",
    "        step_result = env.step(action)\n",
    "\n",
    "        next_state = step_result[0]  # Extract the next state tuple\n",
    "        reward = step_result[1]  # Extract the reward\n",
    "        terminated = step_result[2]  # Extract the done flags\n",
    "        truncated = step_result[3] # Extract the done flags\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            if reward == 0:\n",
    "                reward = custom_rewards[\"F\"]\n",
    "            else:\n",
    "                reward = custom_rewards[\"G\"]\n",
    "        else:\n",
    "            reward = custom_rewards[\"S\"]\n",
    "\n",
    "        if next_state == state:\n",
    "            reward = -0.1\n",
    "\n",
    "        # Update Q-value using SARSA formula\n",
    "        next_action = np.argmax(Q[next_state, :])\n",
    "        Q[state, action] = Q[state, action] + learning_rate * (reward + discount_factor * Q[next_state, next_action] - Q[state, action])\n",
    "\n",
    "        print(\"Step Result:\", step_result)\n",
    "        print(\"State Tuple:\", state_tuple)\n",
    "        print(\"State:\", state)\n",
    "        print(\"New State:\", next_state)\n",
    "        print(\"Next Action:\", next_action)\n",
    "        print(\"Reward:\", reward)\n",
    "        print(\"Done:\", done)\n",
    "        print(\"New Q-Value\", Q[state, action])\n",
    "        print(\"--------NEXT--------\")\n",
    "\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
