{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=[\"SFFF\", \"FHHH\", \"FFFF\", \"HFHF\", \"FFGF\"]\n",
    "# env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x4\", is_slippery=False, render_mode='human')\n",
    "env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x4\", is_slippery=False)\n",
    "observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom rewards\n",
    "custom_rewards = {\n",
    "    'S': 0.0,  # Reward for frozen tiles (very small positive reward)\n",
    "    'F': -0.5,  # Reward for falling in a hole (negative reward)\n",
    "    'G': 1.0,   # Reward for reaching the goal (the \"gift\" state)\n",
    "}\n",
    "\n",
    "# Map custom rewards to the environment's reward table\n",
    "env.env.rewards = custom_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom policy to avoid edges\n",
    "def custom_policy(state):\n",
    "    if state % 4 == 0:  # Agent is at leftmost column\n",
    "        return [1, 2, 3]  # Avoid going left\n",
    "    elif state % 4 == 3:  # Agent is at rightmost column\n",
    "        return [0, 1, 3]  # Avoid going right\n",
    "    elif state < 4:  # Agent is at top row\n",
    "        return [0, 1, 2]  # Avoid going up\n",
    "    elif state > 15:  # Agent is at bottom row\n",
    "        return [0, 2, 3]  # Avoid going down\n",
    "    else:\n",
    "        return [0, 1, 2, 3]  # All actions are allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q-table with zeros\n",
    "Q = np.random.rand(env.observation_space.n, env.action_space.n) * 0.01\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.99\n",
    "# discount_factor = 0.0\n",
    "epsilon = 0.1\n",
    "num_episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0005023162941222275\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006922879399793843\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04130721677808821\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006949424631935277\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007222840057841756\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006969543334468083\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007190540842169921\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006984452544396097\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007162947559848143\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006995139098381453\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007139171574603092\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007002403174429014\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007118492331411255\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007006893597795827\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0008055539513412314\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04209768166116378\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007010934978825959\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007100725661173899\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0070128133213995785\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007084921613875067\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007012939229033253\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007070710436161852\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007011645639309951\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007057792310837353\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007009202514151854\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007045924128654651\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007005828751473479\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00703490876218506\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007001701843782453\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007024586368501017\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006996965709885808\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0070148273369296105\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006991737045253259\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0008467533065464525\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 3\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.008771383882939346\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0014975916295622196\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0024358093976833903\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004320543067169719\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0017755662302557998\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004064269817248071\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0020037861943888124\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 1\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04558082277963512\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006987031247083965\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0009604528091362997\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00220577028685749\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038762140939221554\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0023689384534700346\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037231175914234733\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002500633249673955\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035983685239988476\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026068084085824456\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003496605704048625\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002692291532425015\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034134819953538387\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027609970967225434\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033454725083939866\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028160991653812936\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003289719074927336\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028601714372609704\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 3\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.006745283500569036\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032439041397234383\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.0870334764802539\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0069827960287316\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007004641410081077\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006977975925456467\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00699499688569316\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006972683024594443\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006985792816558694\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006967008210974309\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006976947347789282\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.006890935371469941\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006961025177308017\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006968394105563847\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006954793676028036\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006960079268934238\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006948362156049722\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006951959195489736\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006941769900798234\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0069439984961197875\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006935048761834269\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006936168473929401\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006928224564569853\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006928445858428877\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006921318248097327\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006920811779147625\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006914346789423209\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0011475645005115057\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028953008033674936\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032061485052844764\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029231794250539076\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003174928417836366\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002945179395914317\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031490083362482467\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029624132816114617\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 3\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.015759003325223557\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003127386417502957\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002975783208783108\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003109250313422189\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002986020668933594\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030939413283043956\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00299371879354237\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030809253560346505\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029993585244355633\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003069769314350306\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030033298341126872\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030601220364924317\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003005948932314169\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030516987771422913\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003007472218019839\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003044268649012026\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030081075924700456\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003037644435765358\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030080236323638113\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030316743317928396\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030073570279749214\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030262352443830728\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030062186143713534\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030212273627675296\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030046982618482034\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030165697544137487\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003002868841350344\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003012196794266058\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.127475691817435\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006908072476616503\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006912629776417896\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006901615576820224\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006904626740881309\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0068950120664854515\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006896770261375237\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006888291115713055\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006889034055693306\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006881476375655387\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006881396811313859\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006874587022409921\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006873841245401055\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006867638603463633\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006866353342603849\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00686064372403505\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0068589217370229345\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006853612603596816\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006851537211076726\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00684655352713373\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006844192289155292\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006839473211046731\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0013300920657540393\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030007894398476494\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030080552693843693\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002998507967531937\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030041020312315944\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002996063271870671\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030003020920236316\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029934868517939436\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002996627081148869\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029908042476482874\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002993053993551162\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029880361682450237\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.09029244134638484\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006833100926568431\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08635921899085247\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006827365870537962\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006835682281423021\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0068213618293450455\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0014928984398348928\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029855448967820862\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029893175389774725\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029829328434626476\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029856961365825273\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002980223476638053\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002982168647111442\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029774358250382804\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029787179290790876\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029745853175132822\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002975330082604994\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029716844639398484\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.023888545314523307\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029719938362745397\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002968743407337043\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002968700049973453\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029657703715507103\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029654413117596277\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002962772024259842\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002962211610985389\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029597537713214116\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029590060732476702\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029567199954407897\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029558207454715413\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029536742496983934\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029526524216445284\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029506194144713624\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029494985015127402\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029475578246739875\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002946356876004191\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029444913729310034\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002943225834323941\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002941421593235973\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002940103988621908\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029383497287859446\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002936990212909526\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002935276786985393\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029338835935301274\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029322035840463364\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002930783388997702\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029291307811524754\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029276889974320266\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029260589137829985\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002924599930153341\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029229884154898795\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002921515790271505\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029199196371777706\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002918436255324954\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002916852862737164\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029153610632034377\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16387368562089802\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00681595819227142\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00682689391431559\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0068102248705615214\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006818416785069621\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006804225645227262\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006810193445440158\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006798012231803111\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00680217731184465\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00679162656249542\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006794330610347232\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006785102636670254\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0016323770292623828\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029137883217205877\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002912290000733432\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002910726199621139\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029092228944225815\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029076666462068603\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029061596029548026\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029046097822786996\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029031000111049135\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002901555705150216\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029000440248042937\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028985044930908196\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028969915671398553\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028954562089285834\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028939425751097997\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028924109029715953\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028908969969930077\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028893686153767433\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028878547902160046\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028863293780704534\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002884815919623379\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028832932163061226\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002881780356075347\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028802601499269696\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028787480753105824\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028772301943900203\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002875719057024136\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.19663188004401472\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006779231103427605\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006786041428551842\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006773126094511477\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006777976769053294\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.015531302350966312\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006766833185196605\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0067700955774824285\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0067603893288477055\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006762364563290109\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0067538244877286555\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006754756731246235\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006747162955349167\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0017539851155807566\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002874203361596408\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028726932841197667\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.22611425502481974\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006741167576207628\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006746656648166167\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006734969826755316\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006738752996198326\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006728609390703418\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006731010026258132\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006722118444232632\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006723398749611349\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006715523076020892\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0018631327368207253\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002871179660564624\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002869670742103688\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002868159097976427\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028666514185929854\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028651416786194895\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028636353029170163\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028621274057463253\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002860622385794201\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028591162813653187\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028576126590699473\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028561083064767116\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002854606115504147\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002853103481263951\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028516027485988634\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028501018052488436\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028486025524586127\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002847103277417362\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00284560552167707\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028441078963216556\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002842611651245207\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028411156601627656\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028396209364768004\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002838126566857692\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028366333729480317\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002835140614093778\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028336489564485126\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002832157799372803\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002830667682941569\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002829178120046738\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028276895485320392\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002826201573346736\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002824714549440162\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002823228156406638\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002821742681980403\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028202578662820344\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002818773942544284\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028172906999657152\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028158083275864614\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2526483925075443\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006709587244630326\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006715308011868616\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006703444013342287\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0019557312424352585\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 0\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0008279849466065073\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006707418168002641\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00669713401064032\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006699692618255769\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006690690178783609\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006692101684129769\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006684139227634095\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006684621299252567\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006677502813496689\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006677231947863483\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006670798494985505\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0066699178040807\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006664040508090944\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006662666033973633\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006657240394645239\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.1269060209823403\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006651120292544105\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006654860339538137\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00664483943690397\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006647213409837816\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006638429620787517\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006639696601311999\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006631916622238654\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0066322866867824255\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006625321342006248\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006624964830962802\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0066186607260709405\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006617715759747545\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006611948513678853\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006610527086626997\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0066051958438870404\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006603388766509114\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006598411747382738\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0065962926528490935\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006591603545276525\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00658923213854656\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0065847771724649815\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006582201864765937\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006577937439830311\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006575197484832544\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006571088246845702\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006568215472787015\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0065642327539670465\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006561252968151051\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006557373522417296\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0065543076500552576\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006550512627531037\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006547377635175305\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006543651750660288\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006540461394973143\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006536792253696601\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006533557688591792\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006529935239497528\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006526665508442868\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006523081600883619\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006519784036086059\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006516232060367777\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006512912606453864\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006509387202369932\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006506050678843101\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006502547499338406\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006499197813393293\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006495713332930501\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006492353652014083\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0064888850111868455\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006485517902920172\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006482062782457258\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0064786903280914234\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006475246846692583\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006471870733104847\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006468437364600704\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006465058958889832\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0064616344650707275\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006458254875042851\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006454838251192897\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006451458374406662\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006448048805139867\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0064446693686748425\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00644126619212469\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006437887784827703\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0064344904636101635\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006431113562242338\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006427721659911139\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0064243466503493074\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.02334182767153848\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006420959812304606\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16339814277467934\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006414874149458727\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006416984526110791\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006408668202597822\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006409744225556896\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.030373186752327447\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006402366060668173\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006402604043007356\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006395987254859084\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00639554637693767\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006389547620690005\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006388556953692213\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006383059997036534\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006381624198029609\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006376534792937812\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006374738722727491\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0063699804471940525\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006367892914726953\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006363403801032615\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006361080599556487\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006356810400285446\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006354296769229098\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006350204740410583\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006347537361606836\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006343590465168601\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006340799081497844\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006336970527720027\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006334079255592343\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006330347321251667\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0063273757148370234\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006323722784895365\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006320686699057962\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006317098489612567\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00631401077962381\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006310475707834068\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006307346796737002\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006303855469927624\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006300693808586137\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006297238609984889\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006294051050116027\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006290625802947887\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.1962410523877845\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005006245341655962\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 0\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0065782192315382276\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003379128393176132\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037932229126857358\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037588765253937554\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04262916146968401\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006284674276614585\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0062868286984892685\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004877749583504347\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037721096394451085\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0060734177189481035\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003787339475722228\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003769845283597098\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037818202112261177\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003767260956148774\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08751959744271996\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006278602890103564\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006279727514760594\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006272435625054506\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006272725890164931\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0062661919256753835\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006265806301790301\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006259887556985085\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.22579967103957913\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006254213625163816\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006258392820502489\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006248373151877181\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006251142480488081\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006242398942257783\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006244025727722794\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006236317595076561\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006237018596863094\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006230150676658351\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.25240242782619426\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006224600450081962\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006229552181734899\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0062188660710655215\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0020390698974883385\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028143266544002035\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028128458336134352\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.27652911624199633\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006213705129950725\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006221753771426531\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006208288240326878\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006214198930076239\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006202665110371738\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006206842882995417\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00619687604475111\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006199649323126236\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006190953723265497\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006192588809416896\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00618492464307122\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006185637468139257\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006178810288109885\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006178775939848211\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0061726280773438695\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0061719885255204325\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006166392133636006\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006165262494198354\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006160113907198042\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0061585875215911245\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0367260168002821\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006153802681115759\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006151955234862472\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006147465981255568\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002113781246525125\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028113657264879134\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028098864571743953\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002808407913099387\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002806930194853795\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002805453211079974\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028039770432653328\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028025016172552445\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002801026999047069\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027995531284353797\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027980800588574646\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027966077414187307\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027951362193721725\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002793665452994703\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.1305328980564596\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006141762951381396\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0061447942435629834\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006135921286355992\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006137771026555929\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006129968489349429\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006130860804345929\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006123926860044733\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006124043483055765\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006117814478862781\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006117302768157603\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006111646005024105\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00611062544583923\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006105433323659778\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006104000800297625\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0060991860705232655\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006097420141249666\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006092912057454656\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0060908764208127105\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006086617617369649\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006084363922851035\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006080307883994936\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00607787801108143\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0060739870186925045\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006071414924823845\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.042452090405403334\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0060676583943808145\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006064971613385161\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006061324744667864\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0060585456017687635\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006054988284776185\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006052134881784729\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006048650809595255\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006045737823756186\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006042313773187592\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00603935310492614\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00603597835325652\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006032979651405921\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006029645503420055\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002178976001719088\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027910173934130775\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00279193331938285\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002788317052690672\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027887833756609416\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002785574901612038\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002785676953354439\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027827994298329235\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027826064015724545\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027799975206053043\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002779565515955134\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002777174754624332\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027765492650674295\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027743356564035745\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027735535685446404\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027714838940491363\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002770575117201041\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027686224412471257\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027676112271644024\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002765753708611689\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027646597216005194\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027628796501889714\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027617188348091756\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027600018498161825\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027587871344600602\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027571215911461103\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002755863458537519\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027542399144267135\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002752946864212012\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027513576625410314\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027500365863823728\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002748475518338783\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002747132004059675\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027455940349068128\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002744232613109482\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027427136601139704\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002741338004149817\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2980217676030032\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006023945938567235\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006026052334183485\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006018130525794677\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0060192420228188095\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0060122224334742715\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006012527841450881\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0060062404464304815\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006005892861502411\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006000199795076172\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005999323355064711\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005994112827719961\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005992808189502517\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005987989555708714\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0059863383365674275\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005981838095458018\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005979906474361029\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005975665026873958\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005973506664585447\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005969475683980522\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005967134090840974\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005963274390575726\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005960784846423874\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005957064651314117\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005954455762261585\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0059508493066466025\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00594814426739344\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.047617747283504985\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005944630658453893\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005941848275841031\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0059384105719167656\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005935566094876688\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.05226806990853473\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005932190558117881\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005929296350642689\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0059259718410197195\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005923037927839372\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0059197554117738456\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005916789920821046\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005913542072757744\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005910551593941958\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005907332473282224\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005904322349402702\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005901127138544869\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005898101701178374\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005894926493107041\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005891889253878134\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005888730879930273\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005885684685603417\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058825405758119835\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005879487734048462\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005876355803901583\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005873298185229872\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005870176743849182\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2763449089341479\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058646155898020216\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005866565310097285\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058589439965214506\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00585994423474318\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058531840761088805\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005853415034803642\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058473537569435526\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005846961553260689\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005841467575022005\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058405706878617986\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005835537315618123\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005834231813321813\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00582957253357517\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005827936312813573\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005823580975186197\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058216771980756496\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005817568920277066\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005815448801375514\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005811541459585535\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00580924652573693\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005805502719674938\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005803066642411056\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005799456045306139\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005796906126655258\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005793404147314395\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005790762524573857\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005787349222515768\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0057846338451455325\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005781293050933598\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0057785184726734055\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005775237074634906\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005772415095794921\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005769182461655112\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0022326070538984623\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027398347565134053\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027384478446296624\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027369576174804014\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002735561864297256\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027340824802977895\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027326798434170116\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027312095367662947\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027298016032151736\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027283389418079674\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002726926998132645\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027254708204423024\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002724055909543168\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002722605273442846\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002721188240659693\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002719742381923871\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002718323912404187\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027168822110594983\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027154628600586585\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002714024813099356\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027126050305496287\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0013166555464295539\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005766322649919285\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00576313015783161\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005760240270552686\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005757080928833164\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0057541672554519\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005751035394239586\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005748103033936429\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005744994055175334\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005742047142005145\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00573895731671631\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005735999202159545\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005732925506058474\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005729958907043379\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0057268988872499205\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005723926006176783\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004762933459812641\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003764935061445282\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037763667611865888\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003762301864658226\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003771197969669094\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003759420277189644\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037662607801439594\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037563380667049316\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037615121707333518\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037530939649370403\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037569172561887835\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003749719376806026\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037524477488737017\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037462397662639197\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037480807108464594\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037426757800113272\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037437975419829348\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003739044158666505\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003739583159492625\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037353584755896244\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037354253326267353\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003731629735960709\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003731314143224172\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003727866862543831\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0012926065155411026\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006515579861915371\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04084819125725313\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0057208776731364295\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005717900295199611\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046556989332232155\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04801310496728881\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005714862035047548\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005711881607149357\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005708852110650579\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005705869805388829\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0057028480103190156\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005699864777871528\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005696849822296395\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005693866432491718\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0056908576168834355\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005687874693314007\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005684871449833179\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005681889497516091\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005678891365103954\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005675910792909773\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0056729173970916265\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005669938535930867\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.05647964409536918\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.06027006086352019\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005666949572439619\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005663972690009302\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005660987911506578\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005658013224247523\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005655032429556425\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005652060112348857\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00564908313772332\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00564611333174858\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005643140043794097\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005640172862909338\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005637203152842712\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005634238688749833\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005631272467744674\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005628310794181572\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005625347989594183\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005622389165733239\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005619429718042355\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005616473791246108\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005613517651571484\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0056105646596270745\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005607611787717417\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005604661760648391\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005601712123249866\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0055987650847852885\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005595818654318623\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005592874623084303\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005589931376572107\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005586990367056512\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005584050285253491\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002278034805005452\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027111702298138335\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027097503802462355\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027083184944768275\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027068988731748177\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027054696334734515\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027040504795712078\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002702623667603656\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0027012051747068487\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026997806131392682\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026983629379369514\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026969404826810996\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002695523751928685\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026941032858539297\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026926876020353556\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002691269029870037\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026898544757889536\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00268843771998614\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026870243624886863\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026856093598739057\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16674930909552688\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005578757303066737\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0055805883033544675\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005573359814792156\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005574292094683444\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005567878750686601\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005568082881533073\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005562331080889715\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0055619453703878476\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005556730564469141\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005555867159231508\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005551088356786146\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005549838190630186\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005545413501979919\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005543850308263179\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005539713332299983\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00553789689733456\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005533993791906106\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0055319725929998086\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005528259699422476\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005526073043942653\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0055225149608305515\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005520194720670612\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005516762742093887\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005514334760070846\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005511005609131512\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005508490839367781\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005505245641315771\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005502661073921264\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005499484523502399\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005496843934355875\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0054937236206533905\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0054910381793649736\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0054879640383451835\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0054852428012246495\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005482206671831905\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005479456981613543\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005476452245828455\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005473680055789206\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005470701346768741\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005467911483540391\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005464954448962366\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0054621508256336255\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005459211935803858\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005456397724714845\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005453474116970242\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0054506518898234145\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005447741242365736\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005444913083835281\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005442013513428855\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0054391811132812095\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005436291092300809\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005433455820090869\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005430574109259724\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005427737074898495\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005424862668748703\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005422024771614767\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005419156854263695\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005416318823025396\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00541345673231684\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005410619157222223\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005407762355650156\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005404925714709366\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0045591878592927335\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003724480276468641\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037269062762721504\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00372099597017272\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037225942496920345\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037174332038749595\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003718360711906452\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002270551275576682\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005402073765841368\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005399238446056725\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005396390995416847\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0053935573099973206\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005390714069564897\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005387882271884513\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005385043007524974\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005382213302441034\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005379377823714139\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005376550376744631\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.06371049637262048\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0053737185286404435\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0053708934734055715\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005368065129643551\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005365242573899726\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005362417631495269\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005359597662027785\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005356776036886493\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2978931419313062\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005351698601738594\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005353456057397127\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0053465208912470506\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005347416019890873\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005341262988091542\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005341459453722848\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0053359411752009495\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3172865516287487\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.06681118855901354\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0053311515435994165\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005335097511166905\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005326211042844998\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0053288826532918694\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005321149321236393\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005322788170765085\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005315990418018497\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005316792405072408\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004471294960547081\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003713807593966202\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0018083882703166141\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006310763108068153\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04513772578341746\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005310753824318816\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00531087779317273\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005305455343411035\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005305030092853149\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005300107788262393\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005299237754605811\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005294721547142129\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005293491412312301\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005289305042246834\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005287783470263507\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005283865101578238\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005282107768293401\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005278407260481461\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005276459310251726\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005272936006148235\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005270834043835229\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0052674549758731\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005265228682063143\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005261967117810041\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005259640558520023\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005256474821322519\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00525406750997895\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005250980022678184\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005248507781226195\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0052454842907517585\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005242959947888\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005239988896517495\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005237422853854432\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005234494869397335\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0052318955605393245\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005229003042950995\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00522637730573754\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0052235140919239115\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0052208674702642534\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005218028562287681\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005215365550904309\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005212546895598439\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0052098711384781235\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005207069448747929\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005204383900056356\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005201596509978716\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005198903564538613\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005196128311870166\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005193429910959898\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00519066504186818\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005187962759008858\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005185206850823239\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005182501961339473\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005179753859913523\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005177047397336964\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0051743061662585296\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005171598968062862\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004391832416295027\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003710544545048321\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037138685506755906\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037071630770603723\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003709490840237008\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037036863625377987\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037052067061045493\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037001331901883694\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003700999221322743\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003696518794080484\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036968546598044366\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036928555259930747\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036927618908973074\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036891534005926005\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003688711888466244\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036854205374914984\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003684697332831278\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.09239451836113301\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0051688638474709\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005166156592156195\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005163426965347273\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005160720202509956\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0051579955688610315\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005155289743576202\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005152569696588972\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00514986516918089\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005147149378678983\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00514444644075202\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0051417346384455345\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005139033525882926\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00513632549366339\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005133626397167309\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005130921957616615\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005128225031254623\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.06962210842930813\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0051255240399491605\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005122829408084128\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005120131747354573\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005117439510263818\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005114745084135234\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005112055322566824\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005109364052655826\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005106676831523068\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0051039886537110266\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005101304025088153\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005098618886823651\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005095936892374879\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005093254750486399\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005090575423435545\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005087896242357878\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00508521960908542\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.07215619585838388\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005082543359421547\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005079869440759612\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050771960981145945\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005074524910396995\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005071854454432438\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005069186010346107\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005066518424013459\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005063852733288829\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050611880022077066\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005058525072178509\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005055863184132608\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050532030201897865\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005050543964718136\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005047886570677903\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005045230338743435\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005042575717145713\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005039922300866517\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050372704532169275\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005034619845648341\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050319707726144206\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005029322967572335\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0023161066511324237\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002683063835772895\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026839452459813343\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026804680315477575\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002680917056506429\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002677832016987118\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002677930720537511\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00267516395662162\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026749788801893\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002672470470098199\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026720555687100916\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002669756924390678\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026691559473537596\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026670276707396324\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026662760920216073\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026642862367758082\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026634128202602516\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0016831550982754262\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00502667666914264\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005024031661060223\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050213881366733375\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005018745920484861\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005016105169134005\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050134657401806415\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005010827760498488\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050081911144519275\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00500555590477938\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005002922037579893\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050002895960218514\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004997658503828067\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3347406203564469\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004992921323451424\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0049945598474413575\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004988090616002976\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004988924833681517\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004983185112937149\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3504492822113753\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0049787701601779035\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004982930596170977\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00497420327318104\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004977083660598802\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004969514228262218\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0049713572031368815\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004964727168546547\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004965729472509301\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004959861669470313\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004960182830535932\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004954933602746339\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004954702974154226\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004949955836912974\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004949278304593188\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004944938805376402\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004943899415866133\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0049398909670095095\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004938558680013461\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004934819179629891\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004933249910795474\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0049297290028356535\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004927968090996657\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004924624943560757\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004922709151309506\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004919510655184323\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004917469791041803\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004914389098979029\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0049122473327365464\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0049092626750220445\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004907039604290074\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004904133328344557\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004901844843367178\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004899002635003452\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004896661619895802\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004893871871872791\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0048914887732216285\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004888742073234453\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0048863253611496765\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004883614076664825\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004881170618624526\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004878488560242171\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004876023924226048\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004873366072716333\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004870884773002361\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.07445811303134658\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004868247057971933\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004865752754441346\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004863131874864433\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004860627534608791\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00485802081330426\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004855508841665033\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004852914107298672\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004850396454121098\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004847811945526794\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.36458707788081085\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0048432199999321034\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004844835588702266\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004838536723220418\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004839367165430861\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004833780400276031\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004833974708515102\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004828965856391423\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004828644857446343\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004824105111639469\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0048233667777540165\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004819207911473169\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004818131683214459\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004814282156964084\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004812932448432457\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004809334253662489\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004807763294701797\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004804369394471718\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004802619535284318\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004799391789017693\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004797497368868637\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004794404849633919\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004792393712095532\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004789411342167985\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047873060637606095\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004784413508263487\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004782232394702633\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004779413164512699\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004777171058519127\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004774411782854823\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004772120719169842\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047694105557671545\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004767080292273806\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004764410449125546\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004762048897509854\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004759412245066467\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004757025820020449\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004754416576741845\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004752010479115847\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00474942395650013\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004747002402897775\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004744434798736997\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00474200120768296\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004739449438423911\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047370065813186315\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004734468146132064\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004732018269653843\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004729491140214588\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004727036065569703\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047245185966845295\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0023482603234599862\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.001982816158939284\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004722059800084501\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004719550657224442\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047170893351412705\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004714587435680984\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004712124557759561\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004709629023331082\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004707165375293382\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047046754931520185\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004702211711586093\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00469972690328384\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004697263503852584\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004694783299836861\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004692320700151175\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004689844719168141\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004687383257333703\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004684911189727364\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046824511393833415\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004679982733553578\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004677524316066811\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004675059367488835\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004672602761841525\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004670141104162262\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004667686454969437\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00466522795278801\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046627753767985065\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046603199198122615\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00465786951118007\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004317505807877183\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003681663519692645\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003680712287997722\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003677887684235155\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036767519399372303\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003674097357865425\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036728123843721844\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036702960481317286\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003668890454700007\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036664865983338565\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003664983582465058\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036626713131645114\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003661089684221839\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036588520605860225\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036572070697976715\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036550303544373897\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0022523149909836997\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006028401149420143\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037669421879635537\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00579848831108652\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003964298311964764\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, True, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: True\n",
      "New Q-Value 0.0056111050128623795\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004655417009437862\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004652968843996411\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00465051922404972\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004648073362777692\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00464562656455974\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004643183056391337\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046407390306865085\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004638297914790168\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004635856621182084\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004633417928808177\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004630979334015885\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004628543089994932\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004626107166523795\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004623673390481295\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004621240115529063\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004618808822870543\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004616378177440341\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004613949380150082\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004611521348331165\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004609095055619859\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004606669624004414\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.37731109398330287\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004602303072110339\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004603813554196797\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004597850306764788\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004598619379146831\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004593328594623846\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004593496972099908\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004247603232178766\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00365159081890362\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036529938538893626\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036480781285483047\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036488542032267085\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036445068818129183\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036447749642035164\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036408889150877748\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036407454703768546\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003637233825146306\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036367570720286535\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003633549392762512\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003632802754709277\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036298419262024793\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036288768299323946\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036261165397455386\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036249746843739633\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024982356788867746\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004588751935399352\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0023771986285547925\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026615354823039923\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026605635509823217\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002658777725620843\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002657726190720553\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026560148459400935\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026548990413965672\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026532483664443445\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026520807255349006\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026504795216278653\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002649270125622569\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002647709311901713\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.19934407903068743\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004584632942097308\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004588025936157551\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004580384215567175\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.38876270847554567\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004576560361690055\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004582302818349111\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004572552304537611\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004576755214663423\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004568395840335529\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0045713508813902985\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004564119993559616\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004566063672613671\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004559748297792408\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004560872386833752\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004555299834309709\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004555759831747038\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004550790074221695\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0045507120659202815\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004546231561325633\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004545717783899491\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004541634465799119\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004540767817623655\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004537007033163949\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00453585473214452\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004532355948329862\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004530972497814725\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004181828446395698\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036223773795240072\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036210925765094437\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036186278066460413\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036172274717164573\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036148705456813665\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036133769085672667\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003611107805061389\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036095388904116175\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036073413747060006\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036057117974663496\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036035727051845694\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003601894315532987\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003599802971903878\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003598085378198172\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035960331271551096\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035942841199667107\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003592263942316303\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035904898382593535\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.1323377904155928\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004527686630780533\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004526116224480525\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0045230034739260514\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004521281945951151\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0045183100391826105\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004516466445235115\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004513609213342626\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004511667112832523\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004508903336178783\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3990691615185642\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004504668046731324\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004506462538175672\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004500341033337583\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0045013500466585255\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004495940584623019\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004496313159870351\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004491481528987882\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004491338515253116\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004486975889099152\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004486415276748621\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00448243341258735\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004481534656919906\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004477862002363686\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00447668952946192\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0044732680655440475\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004471874115004589\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0044686567963750975\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0044670837263452645\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004464032405645769\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004462314561869669\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0044593983067062895\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004457563538046625\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004454757266302276\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004452828153605887\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004450111526879031\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004448106379406323\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004445462905752354\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0044433965691351735\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0044408128755215005\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004438697386898284\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0044361626292722806\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004434007748506412\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004431513133447187\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004429326773867042\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004426865170715306\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004424653748381154\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00442221937473351\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004419988091641656\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004119279732045442\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035884960420723487\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035867019625985806\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035847299321623734\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035829200296227976\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003580966021878793\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035791436628265184\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003577204642310739\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00357537255613263\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035734460611367954\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035716064605719093\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003569690494619735\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003567845173482072\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035659381173324864\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003564088529749781\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003562189070044466\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003560336394709205\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003558443466116231\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035565886583837913\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003554701396684603\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003552845230817188\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035509629348670444\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035491060382873067\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026862118290967144\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004417576258332683\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0044153293320524254\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004412936236372605\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004410677086248071\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004408299644273903\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004406031042406381\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004403666753044745\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004401390946717172\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004399037781465271\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004396756592410517\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004394412905967385\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004392127810860237\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00438979226864581\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004387504464370148\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.07657771229361598\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004385175983753873\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004382886440324766\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004380564142970638\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004378273646446383\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004375956819671766\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004373666006949249\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004371354072392565\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004369063459421188\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004366755947636006\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004364465952295034\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004362162482149614\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0043598734427983425\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004357573704771688\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004355285895290905\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0043529896379283185\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004350703279916718\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.07848899509009949\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004348410298847242\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004346125571510923\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004343835700542099\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004341552748713499\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004339265852610526\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, True, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: True\n",
      "New Q-Value 0.0043369847932505905\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0043347007618812815\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40834496925728087\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004330592180224962\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004332014939767803\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004326402441239478\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004327127287473731\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00432214779857543\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004322307190785325\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004317841430605634\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00431754277333675\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004313494022105409\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004312824404191511\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0043091142359098274\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004308144273127433\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00430470909535846\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004303496046255177\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004300284294401877\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004298874586775445\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0042958444490524585\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004294275728554094\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0042913933012740674\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002401601987577583\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026452161231481763\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026462195092519817\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002642670242249305\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002643221912309465\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026400821873430115\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026402678576254767\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026374604865136327\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026373496600277787\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026348120542050196\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026344610873912976\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026321424964362563\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002631597085799357\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002629456358286767\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002628753556689811\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002626757324570382\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002625927176153298\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00262404838255252\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026231152484106676\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002621331953889924\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026203155870047033\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002618610001614397\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026175264184640583\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.31736515382790936\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004287387268273516\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004289299495257763\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0042832891914766835\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004284415175688178\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004279117374722145\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004279606278216852\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004274886658793399\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.41669319622212586\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004271079014457527\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0042744824728264625\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004267144877821594\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004269481568448154\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0042631090653158015\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004264581209069604\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004258991698482113\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004259763266312372\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004254809091998826\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004255013039789019\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004250574473738057\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004250318608710184\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004246298568626559\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004245670306133195\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00424199007207109\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004241060292654914\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004237656033836817\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004236482210739268\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004233302169316323\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004231930904427657\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004058897089392735\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035472281391707833\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035453710202364838\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003543497056257117\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00354164012678229\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003539769723182852\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003537913316699163\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003536046169217784\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035341905557818073\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035323264173184044\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.12792098981845232\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004228933111923029\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00242068417897965\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002615884116880899\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026147463041888614\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026131555893075063\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026119740771114184\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.33477420143032494\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0042250009602690635\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004227012909051529\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004220975142238259\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004222188157227963\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004216874255580001\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004217439892807587\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004212713379409952\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004212754528088414\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0042085047397497095\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004208121044514794\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004204258249181703\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004203530506732303\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004199981944430031\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004198975668557646\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004195682341174235\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00419445065347813\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004191364721751146\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0041899506955836805\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004187033368438816\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0041854719295007555\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004182691752615509\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004181011220059616\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00417834268813986\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0041765660241795\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.08022643965496369\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004173988455719644\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004172134278877795\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004169630903756581\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004167714310461917\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004165271530116653\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004163304760897274\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004160911548433817\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004158904528102494\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004156551941872582\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00415451271753763\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0041521935067215495\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002437318164423128\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002610425464010786\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002609208790337344\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026076945878531045\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026064496755010672\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026049636469424\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026036961089982583\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002195831302081581\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0041501286029493\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004147836887741375\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004145751594540766\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004143482606826773\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00414138121316254\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004139131086247187\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004137017069384757\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.08179402171192884\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0041347826674915595\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004132658846527946\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00413043762654867\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00412830628690347\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004126096186297247\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0041239591806565504\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004121758526552521\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004119617356719595\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004117424792212509\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0041152806754766735\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004113095099863449\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004110949022815487\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0041087695431358375\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004106622305304387\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004104448197047388\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00410230044628164\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004100131121524532\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0040979833826844045\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004095818364257834\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0040936710624774894\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0040027076957679835\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003528978640608963\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003530140385623914\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035255646747248343\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003526157249859281\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00352209777498842\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035222292045972063\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035185886887447015\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16428224295661142\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004091509963017322\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004089363442568455\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004087205947529867\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004085060487117067\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00408290634100147\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004080762166164506\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004078611161351609\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004076468454521864\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004074320422214113\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004072179330868875\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004070034133748721\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.42420660049048636\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004066176474129867\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004067512868720844\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004062242600720243\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004062923599320064\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004058247776980905\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004058397769309167\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004054204378444422\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004053924225844248\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.08321325330726996\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00405012243895856\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004049493924716721\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004046010093609659\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004045099531512405\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0040418739378684215\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004040735098210138\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004037719318804383\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004036395800950758\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00403355057121807\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004032077727406271\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00395077720637691\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035154305111253547\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003518033904738896\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00351217281658197\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035139356231066216\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035088351616113286\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003509916741795481\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035054334028879483\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00350596297450184\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035019803970748357\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003502062736362065\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034984865682671966\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003498206632984311\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003494960368105924\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034943870461283666\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034914086488620397\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003490597797752872\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00348783696595337\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.19700737078095462\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0040293712091094835\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0040277777043674825\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004025184080930916\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004023493157942895\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004020991495474171\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004019222000200549\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004016795323946608\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004014962537251208\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004012597082739817\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004010713394717329\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004008398000542851\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004006473457299338\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004004199072761201\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004002241819772763\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0040000011056425845\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003998017747254103\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039958047520564826\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003993800642982284\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039916105405060805\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003989590022194157\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003987418898652694\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003985385490941358\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003983230172390619\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003981186728913894\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003979044641314032\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039769934755125936\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003974862531258376\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003972805518555914\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039706840244695734\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00396862268512281\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.08449883025812048\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039665092678497745\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003964444834127657\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003962338379643435\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003960271850299591\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003958171454858751\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003956103639300648\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003900995345368603\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003484622451335567\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003486515640659806\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034813252546273313\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025825828881587054\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005442460044460654\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004106672025169892\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005304774570506408\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004221177505133037\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005192193686463937\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004313086929579663\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050999699238459305\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004386675259082444\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005024253782110499\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004448989743932539\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005317667520479646\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04226004967295903\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00395400856966364\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003951940123767284\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003949849784950237\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003947781240100629\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039456951492251756\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003943626935863858\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00394154470095318\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003939477167671837\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039373984704573735\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039353318994799335\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00393325648146015\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003931191101196495\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003929118752332588\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003927054747557772\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003924985297107549\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003922922817215642\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003920856126301143\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003918795291997891\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00391673124757882\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003914672156308406\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003912610666295471\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003910553396640816\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039084943859333645\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003906439001184138\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039043824084572577\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039023289595029927\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003900274734602328\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038982946027441854\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038555470110398487\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003478357777589919\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034822214965752273\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16828673526460658\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00389617842681377\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00389418680672433\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038920850779981015\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003890084548773709\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038879949405268887\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038859875930085\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003883908218182041\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4309686643320108\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038802301680716787\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038815316203467463\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003876478781678839\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4370545217893828\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038731025339252827\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038768156091706744\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003869597025840651\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038722241538118314\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003865987514483957\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00386773450236456\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003862294478769653\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038633282055262996\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003858534523239791\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024514777490281126\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026022331970389874\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0026009475846052923\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025995036882110125\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025982036912776535\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002596775484826399\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002595464095147702\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025940488817633818\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025927285249275063\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025913241175548668\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025899967600726873\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002588601385046576\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00258726862118503\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025858808400392366\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002584543962230411\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025831626082961235\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002581822664228686\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002580446791225151\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025791046301371075\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025777334704862095\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025763897807015313\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025750227117270403\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002573678051092355\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025723145676124796\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002570969388176755\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025696090802807305\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025682637483068716\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025669062833350376\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025655610955263534\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025642062034586426\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002562861400116124\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025615088617242745\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025601646374152146\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025588142746559533\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025574707868646325\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025561224550899567\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002554779831232075\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.35044234427249893\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003855150563262916\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038586945390666144\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003814349729917266\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034752619279918746\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2264599858228635\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003851646266304219\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038541380655240706\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00384804130816068\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003849680348479571\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038443555318440894\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038453035112841786\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003840605026276814\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038409930577571654\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003836802836367092\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003836737232781791\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038329595387757804\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003832526503842414\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038290837087786014\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038283531406272543\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038251822988228396\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00382421087414799\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038212609454812067\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038200946203358305\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003817324218346333\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038160002559185346\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003813375821847635\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038120208535884904\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037769656877967347\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034724756633536346\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034777744375897143\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003469527766339653\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034734802426983685\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003466449533732826\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034693107222680815\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034632663418640835\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034652430178858176\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003459998766448371\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003461258593975625\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003456663490607121\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034573424201481675\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034532740411410776\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034534823082063176\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034498413855393955\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.25296733936058147\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003809428304168132\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038079521703422866\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038054727386152053\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003803898754430963\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00380151144144235\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003799858511690659\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037975462899554903\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003795829743227187\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037935788055394326\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003791811070652872\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037896102209801236\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037878013754646172\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037856415350531083\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003783799749888413\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037816735567867505\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00377980545702146\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037777069413532\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037758178985132806\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037737422191706947\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003772155711753829\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037408034161854615\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034467519954978812\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003449362524939976\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003443563685917151\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034453390773517764\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003440295885983262\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034413944623289416\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034369643491555008\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003437514486662442\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034335818484195323\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034336876409897317\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034301587400355623\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034299045921542793\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002791191125884942\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003769811412717254\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037681514704374546\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037658772670188367\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003764158172828574\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003761941199426982\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003760174534288988\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037580043583788935\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037561995123395996\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037540676742626247\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037522322608576396\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037501319006612685\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037482720929373414\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037461976477959386\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037443184507754052\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00374226540964311\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4425317935010176\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037387263953055643\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003740226143900225\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003706308789830436\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00342670342065528\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003426157771583724\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034232226979765404\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003422441041525029\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003419722091289864\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034187494244102227\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00341620607517749\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003415078883411772\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003412678277117506\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034114261445052276\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034091416377117732\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.27682395754452765\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00373513614402113\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037359820077682944\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037314847483880783\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003731800797081885\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003673182932980858\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034059586622466136\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034074734376171195\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003402702666346047\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003403593657823666\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033993881718359853\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003399773721053062\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.200640785628719\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036424040686945346\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00339602695303664\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003396003017298383\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003392628556445516\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033922729426566506\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003389200722123973\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003388576519881259\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00338574972537982\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033849080907057353\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033822806538217056\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003381263066363511\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033787976320095226\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033776377252961024\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033753040036128843\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033740290491241676\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033718024791148885\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033704345896441246\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003368295255578168\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003366852360981951\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003364784113757564\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033632807521457547\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033612704968442376\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003359718456118759\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003357755574315571\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033561644123641246\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003354240293708062\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00335261776020481\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033507254225975318\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033490778010214846\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033472115826389055\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028507736838703198\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005406776851478158\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.043501234957511264\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003727784552460377\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037276713880672737\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037240455646329993\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003723584760159213\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037202758994254615\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037195335981864124\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00371648213570337\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003715511969802405\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003712669607143471\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003711515063929368\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037088426377581314\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037075389786744863\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037050047328710924\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003703580549361276\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037011587339707496\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036996372090882523\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036973069442734117\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036957068756624948\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036934512305366574\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002459386097179207\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025534334128729363\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025520917559832884\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002550747155427988\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025494065487723302\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00254806368821365\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025467241990282485\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025453830150960815\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002544044697619936\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002542705138650847\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002541368036584376\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025400300604076155\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025386942089062926\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002537357781048577\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025360232083394725\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002534688300569327\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025333550292618886\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025320216184093213\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025306896665582227\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025293577335576533\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.22867937197233193\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003689981088173579\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036914443158254295\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036864359666229384\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036872570449385574\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036828308174095617\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036831315913682483\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003679177763214062\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036790570307896155\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036754866329408277\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003675024504371796\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036717653955795526\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003671026828096992\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036680205120031995\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036670581759756095\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003609537608506333\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033440491266761418\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033452308844602744\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033408220715700947\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033414491810996863\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003337543333341954\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033377210529905712\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033342233842538252\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033340370627326426\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033308707150389743\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033303895572482367\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033274922097026524\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033267723302839755\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003324093449430501\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033231803487491973\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003320678959013621\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003319609530816626\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033172524066631052\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003316056565994611\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003313816766030261\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.29829491391007923\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036642572202244647\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036631138231802704\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003660479766696865\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003659189937765233\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036566915938659366\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003655283411781437\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035766517074926956\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033107246894607013\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003312212653651759\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033075612732261553\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033084399543359725\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003304340701382801\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033047256883392724\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003301074474390109\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003301059492469966\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032977719167056247\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003297432962976826\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003294440588369768\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032938392849277505\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032910866187406385\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032902729316902986\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003287714977103914\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032867294212545564\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032843296920977236\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032832051186467755\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003280934029633982\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032796970757158622\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003277530637166454\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3176187746390757\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036528954922457053\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036513917243356183\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003649093723730361\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036475128305513624\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00364528812158191\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036436450715328353\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036414801715054694\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003639787101358593\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036376710773894233\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003635937827884287\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036338618146110253\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036320963647423496\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036300531732594153\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003628261992420797\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036262457931831326\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036244341267038472\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036224401924085004\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003620612293081904\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003618636790182759\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036167961060018065\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003614835925658662\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036129852520418336\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036110378730449372\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003609179476269099\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036072428538910842\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036053785711774064\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036034510470485392\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003601582367717471\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003599662596747715\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002463853903083494\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002526960237191152\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025277897633843244\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002524515400047085\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025249378116505533\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025220327033957813\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025221252681216803\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025195198346002496\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002519345204934937\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002516983026428783\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002516592004057893\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025144273321876364\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00251386110953868\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3645436728304555\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003543462069822905\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003274467583945679\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3350102492951724\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003513288153651237\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032717108360469814\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003275626740912927\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003268826799792663\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003271677920001108\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032658402338935064\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032678283111564543\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003262771213308645\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032640598301583645\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032596360151634584\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032603578126437103\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00325644783709884\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031009672237796255\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005453371691301503\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006080785148816908\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04252475527457283\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035962529914769733\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035974531771019442\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035927755568623686\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035933926395211244\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003589243872488723\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035893885189453956\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003585668948615445\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003585430892963785\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003582059712157315\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024663968186617205\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002511856848813202\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002511148826617319\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025092748977669963\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025084521588345197\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025066841717149143\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002505768675950844\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025040868534625567\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002503096406848553\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0025014847123943076\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002500433752690734\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024988791826712595\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024977794165061155\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002496271426638239\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00249513234609269\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024936623862375916\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024924916877209426\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024910528246982057\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024898567485939706\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002488443360339188\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002487226966408153\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024858344939796763\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024846018846713257\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00248322663116417\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002481981132689446\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002480620100184008\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024793644093387183\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024780151666901405\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00247675146990717\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024754120455419363\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024741421154251047\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002472810910414828\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024715361840136623\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002470211901590698\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002468933543869775\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024676151322747357\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024663340875779967\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024650206937174837\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002463737727498228\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024624286593680597\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002461144392025843\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024598390882418124\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002458554022559198\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002457252027650992\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024559665710407264\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024546675154189243\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002453381997963127\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024520855816753816\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002450800270752677\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024495062503123582\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002448221362458333\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002331205830276838\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003581511715170981\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035784234007435107\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035776244603274903\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003574765882241581\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035737638366366577\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003571091913844452\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003569925552443593\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035674053521519227\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035661061270622738\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035637093235158955\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00356230273738412\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003560006362165334\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035585130935000763\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003556298522205308\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003554735337848394\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0856968736786101\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003552587468431768\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035509679634382996\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035488745499689827\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003547209747541399\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035451608599786828\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035434596979251488\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035414472840754043\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003539717009256099\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003537734539584218\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035359810277493264\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035340232073729793\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003532251222504319\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003530313757663609\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002462258255576472\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024469295401644974\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024456452506887846\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024443554659662374\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024430719167505637\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024417840391279194\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024405013449491715\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024392152683650956\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.25508113561981194\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003526975252925176\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035281966502934796\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035235691960117128\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035242103356692913\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035201090996418013\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035202801029669004\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035166059198713444\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035163960787374733\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00351306853967922\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035125719980751984\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034843476741588985\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032535784768406833\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003256426300586567\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003250606832914685\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032525937469864642\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032475529305748766\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003248842112414731\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032444330066464474\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003245156768831256\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003241260226096097\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003241525854331644\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032380452630653197\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3506625764856595\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035095063135207427\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003508755923306232\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035059225185759854\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003504966660314631\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0035023219660895353\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003501199868926032\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.08678045643610623\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003498708556504259\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00349745202912735\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034950854517374406\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034937202859366217\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003491455214871422\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034900023236152304\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034878199234221877\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003486296263672504\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003484181261183547\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034826170570469842\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034564793877864754\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032351517963376203\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003237653296735904\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003232164293080713\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032338722320773045\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002857005958153619\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034805422237128435\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003478929031489857\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003476901975459055\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034752494239113176\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00347326147088037\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024575147415869694\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002436903374678554\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024377046445474312\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024345457970208944\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024349542139977566\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002432151684504583\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 3\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0312586303158852\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024322418093639347\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002429728455181154\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024295607454904757\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024272821234665957\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002426905601164621\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024248175656352336\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.27884272290254397\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034699850167595535\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003471252998179382\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034666405619033567\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003467325113989876\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003463241691998019\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034634535300986924\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034597994222779877\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003459628319894344\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003456322683719729\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034558569472957707\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034308157140228186\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003229101214748295\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032301660291296553\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032259775301573014\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032265212017022625\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032228053761100954\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003222926813766936\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032195945930620124\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032193739971033814\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029134813080265104\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034528202531300374\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034521004576260673\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034492961731220143\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00344837073300254\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003445755258377064\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003444663430281615\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034422014121372377\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034409750270550403\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003438637798601963\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034373026664111304\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034350669827164686\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034336440310589475\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034314910435196576\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003429997241261499\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034279116660525803\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003426648272823608\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003406474007333676\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.22975943095642018\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034243586784568594\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034229949547084763\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034207993111273127\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034193545910392326\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.087763751660694\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034172354845274653\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034157254449035286\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003413668755120168\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034121061071700725\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034101003842179883\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034084954344906463\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034065313938107635\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034048924990288474\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003402962611833543\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034016441758519967\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033845664713134473\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003216353159469046\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003215855560180479\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003213087543980009\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003212365671016452\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003209802991012637\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032088996000250577\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003206503752313854\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032054535115016236\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003203193274721129\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003202024294548853\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031998743524093527\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003198609425982494\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031965492503406843\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031952068591679724\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003193219804364245\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031918149338832353\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003189887502382261\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031884323032307558\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031865535501638797\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031850578743739043\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003183218924710508\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031816907604828542\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031798844175272597\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031783302417697674\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031765506697097406\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003174975733894055\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031732182003942778\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003171626762343683\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031698874298268748\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003168282941662175\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031665586980687424\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003164943958604763\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031632322801637396\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003161609558480497\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003159908398436935\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003158279534077704\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003156587232466934\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031549537166841598\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031532689271719723\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003151631968805769\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.25596621175135126\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033994291240595363\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033980232415486912\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033958905125669034\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033944140781379454\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00339234845504587\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003390815167373692\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033888043111112783\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033872252774363393\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003385259182466348\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003383643408756874\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033817139616866437\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033803511485412177\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003358283447972128\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003149953599366546\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00314831417826248\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003146641343077877\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003145000253400942\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031433322338567824\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3647496709570979\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033781973292235598\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003376757569280228\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033746765956599463\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00337317479532254\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003371153240830883\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033696014866325436\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033676284639244164\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033660365558978063\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033641032365658574\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033624791207280454\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003360578345861348\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003358928464895514\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003357054429299869\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033555056797552035\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033336449943267366\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031403540355577973\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031413952775810696\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031373167644825435\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3774280559813925\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033535440486656474\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024518202064261604\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002422599463587008\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002424052387943273\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002420320703634691\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00242125889880878\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002417993264253291\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002418514342088978\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002415626857694771\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024158099667918624\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002413229358637688\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024131386766178074\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002410807151759082\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024104947169801758\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002408365413564211\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002407873421225015\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024059083409090666\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024052710048525112\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024034393362985587\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024026843986608174\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.37723486853261645\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003350384706094848\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003351643197683073\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003310874854577835\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003134583220514815\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031375794886539295\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031317452678400726\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3888386025032576\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033471589120559874\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033478476102083085\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003343879934261011\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033441069626793177\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033405585301401622\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003340411560895262\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003337203421654777\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033367535435495587\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003333821680300706\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003333126535544373\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003330419039289528\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033295253668795986\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033270001466816556\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033259458447131227\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033235687706400893\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4474613380414889\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033204805322026797\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033220788329298757\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033173182834424697\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033182854596976925\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033140967156082943\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033145524885731443\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033108277404162063\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033108738503190354\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.08865959988402139\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032898301506362184\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031291911104328043\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031336114597213843\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003126499533901941\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003129773767605538\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003123697183504695\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031260424120119487\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031208056639434084\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031223979315411514\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031178424927716416\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003118824545171429\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031148218734664487\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031153094561274645\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003111755322276423\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003111842287420084\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031086521765033687\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.39910809437293615\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033075214775561703\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003307231091565193\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003304185207865507\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033036223179873586\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003300825296559705\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033000417905480334\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00329744690416799\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003296484855005861\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003294054214396771\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003292947736730555\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032906506188934187\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003289427374327948\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032872388670625438\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003286177821808139\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032686037010464302\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00310585934530762\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00310813813386353\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031029790860293473\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031045192499940823\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029475698250630514\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032838465847152953\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032826608515141393\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032804453505436656\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032791588560665483\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.08946887580591542\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032770375422398875\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032756696871416423\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032736250870429215\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032721916020447273\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003270209546941057\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032687231869874193\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003266792187758706\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003265442634692274\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032489382604586926\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2795523144667892\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032633917898173704\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003261974158414966\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032312393639297287\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031000285831758265\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003100970154729081\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003097021770176423\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003097478294503639\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030943153483129634\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003330754298840512\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005510032251904226\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006177688416085687\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 11\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0028860929255725308\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006694532063681642\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006222678248781601\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0066411240039428564\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006257881700293784\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006596541891877655\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006285151177560293\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006559117669268358\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006305988709061831\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006527498784538644\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006321612217824974\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006500588515649452\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006333009259091772\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006477497580734592\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006340980593675319\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006457504901434989\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006346175519549852\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006440025787726926\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0063491205205798325\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006424586140491637\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0063502424964305216\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006410801533589095\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00634988759861279\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006398360252492852\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006348336503748303\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006387009541114649\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006345816797943823\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0019784410382119883\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 15\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.0016093342852570441\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005923825323542626\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.001557057447924436\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.10739277530546532\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003259988052518715\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4518979281279131\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032569246889499253\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003258212286779512\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032537952364461043\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032545167865097252\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003250612874665957\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032508757824506827\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003247388289661979\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032472796448821503\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032441301455391138\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032437205648023076\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003240845466900631\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032401922095452395\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032375399489555467\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032366894435373146\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.09020147177037728\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032342182089701863\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032332081018716314\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003230883990158459\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032297799887135116\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003214452647019739\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.30077980691068334\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032275438100252507\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00322632882703466\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003224195982899157\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032228913466382106\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003220842627926424\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032194656321391057\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032174854627155533\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003216050129734035\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032141258792876674\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032126759288155855\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031993446018007484\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.31988455011018807\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.09086312613129008\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032107682083116437\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032092743885568796\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032074095519476105\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003205880495344005\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003204050765791906\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003202493471623003\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032006925429033926\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031991126862081385\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003197335444547659\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003195936533165599\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003185747361103657\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031146284890668776\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003543172061894979\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005587264889710242\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006343549062719791\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006376319944212443\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006340449830924843\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006366392483052758\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006336677703654582\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006357084327409285\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006332361281702644\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006348279661556919\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006327604840026514\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006339884574563852\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006322492928905684\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00633182291706913\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0063170941048049595\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0063240329417379075\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08723305441948348\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031939996168762873\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031925488419197916\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003190661990538718\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031891694947911455\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031873235714691694\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031857975788874785\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003175520845410912\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003153939674287793\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003741994079786795\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005653930717114909\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0063114639555565165\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006316464579164212\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006305647553338122\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006309077229028265\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006299681443678108\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006301837969049571\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006293595258246205\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006294720102710988\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006287413022589972\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006287701981676296\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006281154216516928\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006280766050943843\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0062748346339086755\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006273898074606417\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006268467079903844\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0023670556414215095\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01596332754642943\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.19736478240237243\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003183985174632113\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00318243235328731\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031806474601443454\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003179073216512869\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031773109625646847\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031757196801554858\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003173976114643609\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031725242758356177\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031702087886243124\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032090031207579065\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039275338128024915\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005709115886313899\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006262736281299495\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006266519158994425\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006256848049909993\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006259295200036072\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0062508334697225654\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006252198193534998\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006244717743910274\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006245205430828616\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.12770875869135548\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003170658406486974\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024445786800771016\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0024009611581361236\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002400111113450212\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3886569446645613\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031676724691460027\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003169122518325863\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003170879218716914\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032769286561495623\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031121464020120817\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003338061638002053\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004099982904267318\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005756431354329626\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006238521307171279\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006238298497155711\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006232260727672567\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006231462459479724\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006225949438393803\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0062246852079327385\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006219598330139763\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006217956921823301\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.1641368925360403\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003184259399007426\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003410153781724312\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00425987131791922\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0057965284535805\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006213216232386294\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006211269636647214\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08829667444696664\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032034386834973905\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034908656640258834\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0044077405030317676\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005831984015228693\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006206810303175739\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006204616892996891\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006200386345264857\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006197993451878423\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006193949062474335\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00619139506387554\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00618750226755058\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006184818281975493\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006181049050711096\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006178260309798342\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006174591916310022\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0061717188785332\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006168132893653806\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006165192147151607\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006161673626856434\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006158678621495233\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006155215447698819\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0061521770886678925\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006148759434707059\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006145686563837102\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006142306461056226\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006139206247097958\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0061358572334133015\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006132735488496079\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006129412323433083\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006126273759666346\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006122972193296743\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006119820630836089\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006116537216419841\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0061133757521780446\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006110107694243484\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006106938838690345\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006103683869849479\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006100509657936409\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006097265939000236\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006094088020103791\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006090854059090488\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00608767376994337\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006084448356405833\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006081266780233211\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006078048932008338\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006074866946478715\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006071655866508896\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006068474182615224\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006065269223936914\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006062088417523456\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006058889054878044\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006055709592204037\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.12861256998747647\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.09145967308849483\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032286905158862137\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00357814540742344\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004544332870236231\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.046130596690091896\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003260057859632513\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.33707881898974235\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003288288469004182\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003670219820834483\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004667266000720248\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005848615630138751\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0060525153990184394\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006049337657486459\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006046148287207755\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00604297257217138\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005515421642482233\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005862322747558444\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006039787743131946\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006036614301524305\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006033433784669658\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00603026281605417\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006027086424992055\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006023918090522966\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006020745673454623\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006017580103142677\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006014411536320286\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003710719504375872\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.033906108249621356\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.27833958878958887\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003322811384366378\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003765257172822339\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00478090935265651\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005871517214898307\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006008710812899382\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006010684463305448\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006002897493476683\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006003902868829095\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005996994128143095\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005997215000632352\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.19692221299625662\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031646483515456627\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003181168593545548\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031631192071521056\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031920100612432647\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0033632907060391517\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038620414814530997\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004884098621665791\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00496227838854877\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004585370973814218\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005878067912094643\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0059910190003913885\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005990604381607864\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005984986934131428\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00598405764992609\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0059789099480609675\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005977563969791516\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005972797786264231\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005971114553652524\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005966658348449408\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005964702274783762\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00596049803880806\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005958321353147384\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005954322048888845\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005951967100672641\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005948134586966552\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005945635714715065\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005545808201531379\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058791264449948675\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005941939064026688\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005939324110582201\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005935738244571657\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005933029785736574\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005929534368902411\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0059267507096842555\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005923329252270911\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00592048523469065\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005917124365278194\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005914232023384126\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005910920899065403\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0059079899900531885\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005904719818174128\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0059017582530471084\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00589852190340838\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005895536096179827\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005892327786589345\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005889322937434189\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005886137978736395\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005883118303585674\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005879952892917737\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005876921809625962\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2264290014104513\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034093037420990934\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003959363096852703\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0049777222775537035\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058733291368942364\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005572686965930771\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005868111559603669\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058737728627789336\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00587073314207848\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00586759815756681\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005864552045469746\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005861428994311634\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005858378311359623\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005855265547705073\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005852211769446463\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005849107958109766\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005846052280354683\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005842956338053903\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058398997297865515\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2529851109832265\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034603503144776016\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00405622129264525\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005060893094199097\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005859753081110638\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005836810777497382\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005833754023780138\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005830671348101877\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00582761508486421\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005824538106693246\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00582148284894042\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005818411098069023\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005815357262755211\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005812290357274887\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005809238281849904\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058061759114505385\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005803125868898517\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0058000677813264375\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005797019992359982\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005793965982437432\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005790920625385289\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005787870526106832\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005784827744931336\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005781781420244351\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005778741331042394\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005775698669993113\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005772661366267472\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005769622278254282\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005766587835187899\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005763552246112456\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005760520724034242\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0057574885731806\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005754460020375697\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0057514312578797345\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005748405712868221\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005745380297665715\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005742357791050304\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005739335689213123\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005736316245177373\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005733297428564371\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005730281066087509\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005727265511250597\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005724252245092567\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005721239932389701\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0066963522706507995\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05807111671482852\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.3512169145380836\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003515881191001721\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004151627579706435\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00513491933980914\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005840180526306154\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00581205481394516\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.011775757598353743\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.08703447958261595\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.4168065077117289\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003575304202292486\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004244821836376897\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005199605277932535\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00583155590025611\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0063966493347876645\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01921459531719735\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.11959487588781552\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.47583714156800966\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036380111438645505\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004335100575254528\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005256968784264637\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005881668594374477\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007659229337711436\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.02913302849837135\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1547432653142669\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.5289647120386624\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037033849864282938\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004422030427371274\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005313557096681246\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006051765439370462\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.009777476225279056\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04153930891464664\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1916364452746678\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.5767795254622498\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037708275000952205\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00450586953720559\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005381326165510797\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006414559041736042\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.012912120185301168\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.056357386105374094\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.22957397376796376\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.6198128575434785\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038398258342690517\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0045880338738706\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005478234894091586\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007051403035907253\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2768856095987242\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003910058604355336\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004671575740998607\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005628500305237245\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007624562630661344\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.017200289391203084\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0734494708978651\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26797804928797175\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.6585428564165843\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039815387422786645\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0047616396971172335\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005820481975148993\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.008564935017324315\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.02275175807097142\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0926343506875878\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.30637598714441644\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.6933998554023795\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004054787198065404\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0048617034429452605\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006086362344349202\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.009960865564618055\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.02964738298194547\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.11370213834612625\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3443849741148104\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.7247711544895952\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004130617119110444\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004978082970741305\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006463851800811469\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0019173437349762922\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006803592311627509\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01189986992336885\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03793915638001742\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.13642603694887986\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3816988209977993\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.7530053236680893\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004210385621302789\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005153830312518298\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007301320202878274\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01446585941265369\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.047651418399954786\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.16057161653277402\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4180764659411602\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.778416075928734\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.09189687760313636\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004299576260111822\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005361277981351417\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.008003308264443162\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.017736763892983846\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.29839605835267213\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00440038515425443\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005617477701396149\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.008958917063404247\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.020680577925280986\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05878286659670394\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.18590402500767148\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.45333201086398883\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8012857529633142\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004516476931267206\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005942662720533554\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01011040257166664\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.02443202392582658\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07130907841279302\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.21219349158243922\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.48732609932095805\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8218684622944364\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046531528474733075\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006349326303075197\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.011518132683156808\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.02904842029611043\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.08518532623817521\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.23921942625697015\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5199584671560115\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8403929006924464\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004816420866730421\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006854688808400201\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.013242113024156059\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03457692556407873\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10034951681379774\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.015086429185149285\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.31775546223122525\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005013392972088999\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007480189116951631\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.015341017352584247\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04105383517223683\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.11399728833185802\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.024863517811488302\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.12628028269811226\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2667733718797183\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5511615176089625\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8570648952506554\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0052525923974583106\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.008250930923162307\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.017871245299377267\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04945019964212626\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.14006281824439315\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2946610249350337\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03348170814286645\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3197599126848176\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.061789768684376745\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.34234891165962317\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5808947904778812\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8720696903530435\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005544175319105548\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.009195091115484427\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.02097969053401004\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05837139868410856\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.15994907867425653\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3656226047509711\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6091402107750443\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8855740059451928\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005900071807627951\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.010352571366802978\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.024660489950335783\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0683692176044491\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.18015080867717703\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.38936522514260336\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.635898016286114\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8977278899781271\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006334969192178651\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.011758702735205923\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.028962993498142665\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07936722590304471\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.20068288509857707\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4133826062406683\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6611832757653372\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.908666385607768\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0068655838437461725\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.013450168818001455\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03392404951272983\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09129810893749937\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.22153947460654552\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.43750148991736987\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6850229203639725\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9185110316744449\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007510592172353699\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.015463632837961563\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.039570157346269286\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10410070602979744\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2426981746477106\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.46156861004166616\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7074532204633452\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.927371213134454\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.008290432606076524\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.017834715131446067\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.045919111508592306\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.11771775471694106\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26412364957706447\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4854496178633707\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7285176485173217\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9353453764484623\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.009227026143482033\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.020597235657652098\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05298125807471024\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.13209422055337633\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.28577079678783174\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5090279032802485\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7482650759339873\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9425221234310697\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.010343449859241387\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.023782656641283203\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.060760460102023475\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.14717610738003403\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3075874795337932\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5322033554696883\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7667482585602644\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9489811957154164\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.011663587880804287\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.02741967652725521\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0692548487224445\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.16290965711587616\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.329516863771913\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5548910975201857\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7840225710800642\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9547943607713284\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.013211777068922124\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03153393889805169\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0784574199046718\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.17924086091770794\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3514993960492201\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5770202223050935\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8001449556884194\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9600262093216492\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01501245931293703\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.036147829578809035\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.08835652314505771\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19611521503480994\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3734744584525023\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5985325506877377\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8151730548424208\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9647348730169379\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01708984850994542\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04128034241228885\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09893627711899812\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.21347766491812667\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.39538173512533814\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6193814280483636\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.11692955319272708\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6381454176729269\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8291645017868555\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9689726703426977\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.019467617557767474\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.046946999605840777\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.11017693823399285\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2312726902037225\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4190199579624241\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6564181615825329\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.842176345972097\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9727866879358816\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.022168608762968965\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05315981653042199\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1220552407407621\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.24962839702163023\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.44210336016285245\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6741518036755172\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8542645934805396\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9762193037697471\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.025214569723183845\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05992730371071524\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.13456292797182728\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2684337899755896\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4646340527104434\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6913088180625389\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8654838452056907\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.979308658020226\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.02862591581822627\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.06725630320885462\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.14768158038222792\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.28758918219636453\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4866102204275904\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7078608369316484\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8758870178291239\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.982089076845657\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03242169825408025\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07515114934580971\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.16138475138144523\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.30700467579905955\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5080274212410645\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7237875680035668\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8855251346539316\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.984591453788545\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03661949221390738\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.08361312479799182\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1756397391474076\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.326598922922019\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5288796483493111\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7390757995339493\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8944471751136044\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9868435930371441\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04123524234751783\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09264014649378599\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19040905860194673\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004920002276101501\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.036460127245712674\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.34629811581639885\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.549160187668241\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7537184899168012\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9026999733129212\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9888705183608834\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04628309261565086\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10222662864600011\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.20565166620757555\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.36603516281391485\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5688622994031802\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08754198059182877\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.051775219590039785\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.11236348073595008\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.22132398070539555\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3857490141734382\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5865941999646256\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7677139382831003\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9103281572993565\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9906947511522487\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.057721682223894864\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.12303820675218924\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.23738073503802637\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4052469385525923\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.60393845985819\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7810650320274266\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9173741219334934\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9923365606644775\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.06413029646997212\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.13423507884573493\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2537621084509304\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.42451215222329386\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6208700520430862\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7937785668960998\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9238780292459273\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9938141892254834\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07100653962870267\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.14593401969780354\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2704126006759434\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.44352707215323\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6373671249614915\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8058646351018366\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9298778310546575\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9951440549303887\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031628162824999784\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.009902456478360503\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07835335361591494\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.15811146519494157\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.28728052075151883\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.46227371030909464\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6534110113404241\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.817336076866064\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9354093093873003\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9963409340648035\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.08617105330862267\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.17074109022984776\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3043175659969673\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.48073402940088716\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.668986181816122\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8282079908088004\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9405061309209858\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9974181252857768\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09445731591051533\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.18379442024056275\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3214784783079584\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.49889025846059454\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6840801547245811\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.838497298689098\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9451999122321791\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9983875973846528\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1032072319232795\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19724134756899436\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.02232782517114132\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.012870328802961416\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.112413402140282\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.20934358216458282\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3387207660647614\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5167251679322686\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6986833718223436\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8482223601311739\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9495202931500418\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9992601222736411\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1218970765605475\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.22194257978853593\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3560044810835799\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5342223049494538\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7127890482930955\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8574026331399107\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9534950159401281\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0000453946737307\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1316796843035578\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.024619584668717498\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.14048403127226708\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.23499276543695674\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4083506370556469\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1496999119232991\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.24673793252053547\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.37329204116521786\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5513661902355249\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7263930041446371\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8660583764039923\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9571500084188146\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0007521398338113\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1591569760505022\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2590200513438385\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.39054808988201306\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5681424786222915\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3351789257219231\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.16888426352849198\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.27178230710777396\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4077393862774186\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5832411381703815\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7394934829941686\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8742103895970557\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9605094694204804\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0013882104778837\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value -0.07598764775350202\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1789022855793124\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03986895247419767\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.18791850542505079\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.284970275638461\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4247063203285445\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.598126879169766\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7520909632648602\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8818797881099777\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19254269689634218\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8887822467716074\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9635959553157429\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.001960674057549\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19733871217075336\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2985191737871408\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.41666892547008655\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.20715823915860496\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.35255366098134117\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2159958134476714\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.31071318212095267\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.44145024933349686\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6127711966160105\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7648713093687634\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8953000216707052\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9664304665158661\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0024758912792477\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2251568371328786\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.32334543859287357\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.45796957286513224\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.627216336581917\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7770188805772869\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9014466356887054\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.969032533100925\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0029395867787767\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2346523518402852\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3363498824472343\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4742670329002288\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6414195721008767\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.78856020945274\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9072361928968264\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9714202988819314\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0033569127283526\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2444857550185329\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.06008614697361266\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2533358178789558\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3496673304596335\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4903408672481927\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6553450756266104\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7995205716042518\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.912683183196455\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9736106033538452\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.003732506082971\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26261930180656395\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3632443432712412\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5061859430104079\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6689631046527703\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8099241495802757\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10255965683878676\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8192873697586972\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9178023146088402\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9756190611206748\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0040705401021275\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2723185616097604\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3770323173021475\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5217946960699913\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6831762437936043\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8282210619291026\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.922608370198903\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9774601384787179\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0043747707193684\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.28241290486169696\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.39098676048286185\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.537249674598559\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6968525045452251\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8367371843858837\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9271160868884057\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26507291980866016\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9311730319089583\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9791472269320636\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0046485782748853\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2928793036633306\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.405075802219833\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5525131050886803\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7100042353449051\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8452495961062823\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9349913041843367\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9806927134880709\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0048950050748504\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.303693877716761\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4192670194016291\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5675522138789579\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7226835218249366\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8532887756099033\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385807524012221\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9821080476416739\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.005116789194819\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.31483192486584616\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.433527986635483\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5823426611517308\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7348907584278234\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.860879392536634\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9419513738776256\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3318188138416791\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9449849332063888\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9834038050077936\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0053163949027908\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.32626800305617437\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.44782711142595605\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5968625801209123\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7466287424461678\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8683449616704031\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.12805748337735912\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3379760867817266\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.46213379571533075\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6110925676109917\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.757932019406921\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8750639738907953\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9478434165815215\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.04532599986452481\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.34992972387937166\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.47641858033728585\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6250185807711778\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7687701508814176\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8813940747432863\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9504160516191409\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9845897476023905\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0054960400399653\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.36210219094482576\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4906535617999039\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6386249676313204\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7791511491928612\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8873458563792527\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9528488314698634\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.985674880806108\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0056577206634225\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.37446667446853366\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5048120774154142\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6518984346382816\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7890832740551211\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8929433050568438\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9551457615226818\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986667507071176\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.005803233224534\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3869964026858063\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5188688147030627\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6648278353059104\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7985763338502365\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8982084049419049\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9573112685704601\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9875752764532872\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0059341945295341\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3996647750728289\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5327998889280415\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6774041088264927\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8076413325544615\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.90316138003619\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9593500940822896\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9884052340663824\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0060520597040343\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4124454865694221\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5465829068090602\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6896201898667351\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8162901759225981\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9078209013467177\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9612672028466325\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9891638645704435\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.09503546786841478\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0061581383610845\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.42531264568657684\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.560197014924961\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7014708982963989\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8245354275636634\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9122042642938625\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16452143588433643\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4382408855954903\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5736229323638083\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7129528157955617\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8323901069723895\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9161492909462928\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9630677051544432\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9898571338111465\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0062536091524297\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4512054673399583\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5868429678911882\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7240641548062721\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8398498760788335\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9198780646619534\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9647567908863024\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9904905277361223\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0063395328646403\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4641823744271901\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5998410224278903\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7348028770574494\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8469328168724836\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9234011804935021\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9663396740435483\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9910690887161095\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00641686420563\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.47714839820483224\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6126024050137887\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7451689382220803\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8536562520540919\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9267286901744631\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9678215464220883\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9915974494008559\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0064864624125205\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4900811964807141\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6251138893963958\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7551640133532274\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8600367671759546\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9298701542528036\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9692075392705641\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9920798642396098\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0065491007987222\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5029593518828859\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6373637377787257\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7647912519683241\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8660902357293867\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9328346852153091\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9705026919032291\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9925202387947223\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0066054753463036\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5157624267346911\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6493416979457172\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.774055060108701\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8718318459927636\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9356309831921978\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9717119263535837\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9929221569745341\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006656212439127\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.528471012157848\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6610389791019069\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7829609068511144\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8772761287295149\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9382673655819829\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9728400272587042\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9932889063085543\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0067018758226678\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5410667698731519\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6724482109699765\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7915151529102249\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8824369850491797\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9407517917223963\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9738916262573807\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3950522034569919\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9748380653561894\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9936235013841429\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0067429728678547\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5535324657718644\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6835633900110911\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7997248991390712\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8873277139247789\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9431855810204195\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9757229854576006\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9939287055596462\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.1751994753954909\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006779960208523\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.565851994805776\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6943798160247501\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8075978529037172\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8919703150533226\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.94546359847868\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9765496287622455\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9942070510643254\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068132488151242\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5780103971116486\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.704894021859743\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8151431288036244\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8963741797973797\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9475956518782743\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9773211639413891\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4523017783414902\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9780155456026184\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9944608575905901\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068432085610655\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5899938655645983\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7151037894253276\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.42415538504308226\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6017897541612459\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7242925802343536\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8223698597232025\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9005487313535908\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0941697426733432\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9043058277541809\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9496596257051061\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.978665615943825\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9946922494790765\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068701723324125\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6133157441883224\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7332779383235153\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8296591506985462\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9078915479235683\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9515815591130341\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.979273587047871\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9949031715920778\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0068944397266248\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6245786856635182\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7420864004103198\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8365744988731248\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9113089674834018\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9533714883194699\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9798416423306996\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9950954039658059\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006916280381416\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.635587370737788\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7506986357577272\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8431366367666692\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9145618480786892\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9550386620782622\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9803719230902445\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9952705753269855\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.006935936970728\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6463477986040242\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7590992992218547\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8493645960497925\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9176544908165682\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9565916162563701\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9808665177385916\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9954301755543891\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069536279011089\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6568638493665855\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7672764643085987\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8552759310356536\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.920591611744292\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9580382398868537\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9813274533446169\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9955755671611599\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069695497384517\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6671378343964782\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7752211350502686\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8608869074947731\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9233782363186613\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9593858337792853\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9817566891591101\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9957079958691506\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00698387939206\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6771709433268069\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7829268253872242\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8662126621408432\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9260196102309445\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9606411626281087\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.982156111834245\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9958286003420495\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0069967760803076\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6869636047074614\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7903891964004452\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8712673373396225\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9285211243080328\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9618105014368881\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.18752293079716\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9628629063647896\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9825275320846834\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9959384211397949\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.24737220868789228\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070083830997305\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6965157746803594\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7976057431570234\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8760641949121555\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9309924396073437\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.35086004286355116\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7058271657848688\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8045755241376245\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8806260269420669\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9332166233767235\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9638468414046942\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9828726825690547\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9960384089526888\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09875558064602895\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9961283979842932\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007018829417211\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7148974260960067\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8112999483911266\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8849518699621559\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9353157983381158\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9647665528385612\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9832021257125942\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9962104222981678\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070282311029437\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7237263783771276\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8177801886782674\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8890529470014138\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9372961072353219\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9656269080002519\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.264367701609469\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9664012276457735\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9835067449488535\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9962851749475424\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070366926201029\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7323139792185633\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8240184115635807\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8929399669175693\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9392402180487213\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671282726311327\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9837883027737748\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.0899924095918927\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7406604040415015\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.830017627132062\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8966307518126357\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9410618952343313\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9678104873426231\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.984041704816204\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9963532900221783\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070443079855462\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7487661087234254\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8357823088483067\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10283749123000956\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.840970522392927\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.900132804259571\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9427689439578179\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.968449567385165\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9842765100467793\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5045149750019724\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.984487834754297\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9964153475105295\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070511618144453\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038268778456076705\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.08304005559414357\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7571455795679827\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8459866177753319\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9034536492854378\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9443685567331674\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9690689062873239\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9846841706824098\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9964718777791066\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070573302604544\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7651836967709422\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8508298672770571\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9066007714734776\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9458695227822957\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.96964574855615\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9848664695143003\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.996523365696981\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070628818618625\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7728974839542766\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8555003569252257\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9095817770815772\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9472774996111251\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9701829541824508\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9850356357668715\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9965702544316073\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.31233421312342746\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00706787830313\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7803022708944463\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.36648101877378014\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.786966579140599\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8599989171637793\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9124040718349209\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9485978621140752\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.970683186705126\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9851925273789135\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9966129489404564\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070723751002706\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7934098140257533\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8643270285590585\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9150748530007222\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9498357113864752\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16489687597393532\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7996372084505248\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8684867361502242\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.917601103127911\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9509497757316351\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9711489282451258\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9853379565861273\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9966518191813375\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007076422217697\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8056536744843446\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8724805717448649\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9199850206125517\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.951998542054739\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9715824931226398\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9854726910264671\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9966872030627557\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007080064623381\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8114638836386517\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8763110316110211\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9222343742147157\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9529853546684064\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9719860402219961\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9855974550270332\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967194091541949\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070833427884966\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8170722874042776\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8799811314971758\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9243564869054163\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9539134371835434\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9723615842474728\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9857129310305952\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967487191748365\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070862931371005\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.011665155564867117\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.15562620648775272\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8224831906820702\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8834943105510944\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9263582684960454\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9547858903056888\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9727110059947545\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9858197611258445\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967753902779258\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007088948450844\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8277008083584215\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8868543480770934\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.928246244786704\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09362198759536236\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9299454234482968\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9556056908686006\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9730360617467376\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9859185486507747\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9967996571467668\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070913382332134\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8327293079822116\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8902335101907655\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9315558444994586\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9563756918946675\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9733383918884906\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9860098598432271\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968217339171782\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070934890373457\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.025905634450667923\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.22250378732921638\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8375894946928761\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8934341877771353\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9330814535470848\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9570986235021613\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.973619528824121\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986094225516705\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.551686805827929\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9861701546228352\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968418159401576\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070954247610648\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.842280529813525\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8964658329005832\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9345260719190903\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577770945055332\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9738884212493696\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9862404789386273\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968600813974873\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007097166912412\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.04534294595119355\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2836391810478337\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8468025942893302\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8993373307305148\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.935893397083229\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9584143387586674\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9741373865393568\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9863055791031158\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968766927820674\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0070987348486244\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8511567306027181\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.902057043968703\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9371870769120142\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9590125061501971\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9743679002166296\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9863658137782289\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9968917982538744\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071001459912157\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8553447048953479\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9046328601861221\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9384106073296823\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9595736776566237\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9745813257590112\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9864215204275395\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5941738557674625\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9864716564119191\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969055328816173\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071014160195477\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8593688875642391\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9070722242931484\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9395673406847198\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.09070026091165578\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.863232149012837\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9093821685916208\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9406084007042536\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9600998611411035\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9747838871678901\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9865181385260073\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969180197793908\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071025590450466\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8669377688021237\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9115641834021798\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9415974468867975\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9605934798566143\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9749707941651758\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9865612086315663\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969293711469113\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071035877679957\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8704888460787271\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3790156407869752\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8736848156276702\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.14057232902339076\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.876561188221719\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9136259123037548\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9425364567039225\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.008037554645816906\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1279128690269462\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9610562404933052\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9751432744031834\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9866010955119539\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969396892212518\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071045136186498\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8793540347176189\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9155744302870676\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9434273788423675\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9614898006098898\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9753024554185484\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9866380151936623\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969490671473729\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071053468842386\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8820604998442767\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9174162977637552\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9442721312185098\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9618957636353371\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.17998044900590726\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9622611303582397\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9754493733808661\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.19733899314061604\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8846786633384608\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9191576089780121\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9451087700021246\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9626045052871215\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9755815995469521\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986672171321886\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969575897741751\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071060968232683\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8872074002934379\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9208076163104213\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9458957390253371\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9629266331135576\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9757039845531236\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9867037555773408\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969653343822612\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071067717683952\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8896466142788259\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9223705328428875\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9466359018010456\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.963228664272961\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3649730482910164\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8919966356023892\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9238504338369022\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9473319493839643\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9635004923164242\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.975817257899968\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9867329481234506\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969723713491062\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071073792190093\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8942581649920036\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9252512534422245\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9479853031848938\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9637563516168786\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3776747531757351\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8964322225835835\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9265766731133065\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4308931986587784\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8985200909634424\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9277695508172803\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9485986516764754\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9639866249872875\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9759220939741928\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986759918074667\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969787647568775\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071079259245619\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.900517267398009\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9289038622515233\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9491734623825693\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9642042497920038\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9760191164661656\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9867848239781312\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969845729477214\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071084179595593\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9024270230211089\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9299816488022453\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9497123368737207\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9644097173429538\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.976108902393384\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868078143021425\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6324504438066284\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868285055937527\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969898490309456\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007108860791057\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9042525039504203\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9310050052725192\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9502176652033011\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9646035269456035\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9761940342078271\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.22687479467126767\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.06888893027980973\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.34479626083414194\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9059967490773577\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.931976053600394\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9506916478505857\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1783782619730341\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9511182322331418\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.964786383637618\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9762706528408259\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3345817260797639\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9763396096105248\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.39778117482322944\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9764016707032538\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986847650088441\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969946413461657\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071092593394049\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9076627034760609\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9329391532314357\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9515202609899518\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9649715106734784\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.976459420991684\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868653545728673\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9969989938861502\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007109618032918\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.909257409298367\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9338457437462974\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.951900414447631\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9651438422843073\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9765131489952295\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868817195103095\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970029466827941\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071099408570798\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9107823969994137\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9346993104019831\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9522596133890143\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9653042598064042\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9765631243272271\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9868968392808751\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970065361593656\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071102313988254\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9122393890292686\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9355030810872972\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9525987737709469\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9654535831341593\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.1975527513617483\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9136302551539841\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9362600515818912\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.952918801124134\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9655879741291389\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.976609598983311\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869108024325648\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970097954519128\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071104928863965\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9149569747451929\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9369730077349914\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9532201304505054\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9657135270155728\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9766528085258038\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869236919390477\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970127547024747\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071107282252105\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9162216050364378\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9376444998760922\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.18538054759474176\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9382488428030831\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9535037565799965\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9658308023580701\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9766929731751892\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869355854606879\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970154413265231\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007110940030143\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9174860799702993\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9388208304241944\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9537706303554458\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9659403264666068\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9767302988182784\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869465556059449\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970178802568549\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071111306545824\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9186807341852646\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9393620397869641\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9540216596400953\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9660425934029556\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9767649779414391\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986956670190779\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997020094165973\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071113022165779\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9198095027056477\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9398739801126371\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9542577104229784\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9661380668788625\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9767971904961823\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869659924941324\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970221036688169\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071114566223738\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9208760764662339\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.21768182769120883\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9218359928507616\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9403580954332482\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.954479608001688\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9662271820500983\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9768271047034832\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.986974581507932\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6669158829952508\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869823116203518\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970239275075502\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00711159558759\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.922747845013577\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9408157670820905\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.954688138224479\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9663103472107333\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9768556430835498\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869894492815641\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970255827199666\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071117206562847\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9236138214533463\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9412483160581049\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9548840487758936\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9663880211549314\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9768820342540696\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9869960370426843\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970270847929421\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00711183321811\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.924436022597764\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9416570052811079\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9550680579926425\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9664605404305912\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769064384958884\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.45471679475199944\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769284023135253\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5059610271058385\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769481697493985\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870021147329172\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970284478022408\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071119345237527\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9252164638608174\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9420430424942686\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9552408456960068\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9665323551927225\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769665621330175\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870077195920474\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970296845398682\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112025698831\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9259570786816682\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9424075819687464\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26014084345017346\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9427356674957764\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9554034642904856\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.966598809324619\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769836701593284\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870128864022896\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970308066300656\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071121077564016\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9266922018955832\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9430470437109568\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9555563999845743\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9666603117379305\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9769995788972222\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870176476184371\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970318246349428\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071121816082151\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9273846390334096\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.943342422938334\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.955700130848172\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9667172388749625\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770143681217253\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870220334954527\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970327481506618\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.370804897790298\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071122480748473\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9280370750009638\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9436224935984696\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.955835124411976\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9667699374315171\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770281126256025\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870260722128229\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970335858950055\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.18758634758503162\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970343398649149\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071123078948163\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9286519943671159\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9438879215554082\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9559618357764986\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9668187268383001\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770408825121117\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870298646381672\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970350243600101\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071123617327884\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9292316991643897\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9441393511417407\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9560807061558405\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9668639015231691\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770527508600791\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870333455859915\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6979405959087389\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870364784390334\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970356457355551\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071124101869633\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9297783250109831\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9443774059369949\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9561921617910502\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9669057337060001\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770640871395355\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870393595229501\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997036209770509\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071124537957206\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9302938556976473\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9446026893606094\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9562966132488392\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9669445049622141\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977074575018354\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870420083379354\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970367217192344\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071124930436022\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9307801363745829\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9448157851361836\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4369572309129049\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9312388854656067\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9450075713342003\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9563944579152145\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9669804373928097\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770842763419743\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870444429543461\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970371863586276\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071125283666955\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9316707464811319\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9451898655343866\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4424148599416188\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.932077468520923\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9453539303145542\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9564860754255812\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670137370113842\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9770932485602571\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870466801084157\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970376080310677\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.4234285483195711\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071125601574795\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9324597607699716\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9455106587502313\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.44732672606746127\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9328193399092474\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9456517143423407\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9565718278471501\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670445949177112\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771015450349646\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870487352926498\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970379906835514\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.4707898369432045\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071125887691852\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9331569256382144\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9457871538649745\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9566520599592885\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670731883844016\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771092153254405\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870506228410564\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970383379033456\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071126145197202\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9334741613070254\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9459169924144466\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9567270996134154\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9670996818631801\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771163054541611\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987052356009382\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970386529504633\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071126376952018\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9337725274253531\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.39029680059885075\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.934041056931848\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9460412760347301\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9567972581565287\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967124227916824\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771228581536737\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870539470505397\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997038938787242\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071126585531351\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9342950375661015\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.288408853641132\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9345236201369297\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9461600769887535\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.45174740558071946\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9347411057451234\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9462669978473744\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9568628309046414\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671469680823552\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771289130963098\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870554072854227\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970391981052782\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071126773252752\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9349474279575011\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9463697183221965\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9569240976543304\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671680336706544\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771345071079357\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987056747169303\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970394333499526\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071126942202013\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9351432872756484\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9464682321577556\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9569813232222921\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9671875465072746\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771396743669032\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987057976354018\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970396467427572\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112709425635\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9353293135317013\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9465625599409869\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9570347580042831\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672056196188705\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2577357604475847\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672218854193069\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771444465892607\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870591037461492\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970398403016194\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112723110525\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.935506075612689\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9466527449893123\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.32784538085909803\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9467339115328051\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4557260171426519\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.014226218507504398\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9356821252931677\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9468069614219485\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9570862488603661\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967236997089713\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771488532012034\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870601375613947\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970400158593995\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071127354269263\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9358478019446239\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9468778039169299\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957134086686211\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672510338476609\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771529214996612\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870610853753358\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970401750807253\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071127465116874\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9360039243379376\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9469462981071718\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9571785303685083\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672640696913613\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771566768018533\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987061954170794\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970403194773099\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071127564879723\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9361512154167538\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9470123428029369\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9572198202311022\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.1308129587110633\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9362903158125692\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9470758707255224\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9572569811074367\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672761737256086\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771601425845765\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870627503819682\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7258657486056799\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870634669720251\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970404504218882\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071127654666288\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.09549633792219832\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.936421795433139\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9471367247826064\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9572916241955283\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672874104689209\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771634115563493\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870641248665895\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970405691608956\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071127735474195\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9365461516433031\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.947194923099703\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9573239154123986\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9672978471661073\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771664187625068\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2534570160488541\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9366638338658434\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3522976878297373\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9367697478661297\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9472504984155602\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9573540107406033\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673075379069848\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771691252480484\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870647287268591\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970406768260005\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071127808201312\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9368705724226571\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9473034956373239\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9573820559193345\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673165275158431\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771716208672027\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870652828599473\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970407744445935\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071127873655716\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9369665612484865\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9473539696096056\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574081865514694\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673248652301119\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771739217836172\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870657912439673\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970408629493257\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112793256468\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9370579481149889\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9474019831172406\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.45930676754839106\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9371449496320968\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.947445195274112\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574325295541035\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16691438673053005\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9372275290010242\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.947486496172557\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574544382564742\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.25532842516312165\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574741560886079\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673325969636788\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771760429384082\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870662575515539\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970409431867835\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071127985582748\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.937305939222005\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9475277880080735\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9574926675791513\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673397655182133\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771779981421712\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.98706668517189\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970410159253743\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112803329901\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9373805963126037\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9475667832976021\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575100376075393\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967346410782467\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771798001599712\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987067077231313\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970410818624971\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128076243645\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.09613486707440881\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4031173137856755\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9374516482278059\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9476035986909883\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575263285142496\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673525699200574\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771814607898741\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870674366125689\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970411416310594\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128114893817\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9375192396754332\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9476383453448002\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4625294429135563\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.937583511897025\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9476696173332309\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575416000849103\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673582775462491\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771829909355311\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870677659727869\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970411958054022\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128149678972\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9376444528233124\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9476992740083139\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575559095534979\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673635658942418\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771844006732838\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987068067760243\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970412449066838\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128180985611\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9377022356678043\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9477273816532787\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957569311621678\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673684649714727\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771856993142195\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870683442299805\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970412894077729\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128209161586\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.16877922546109111\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9377570228846984\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.947754005338497\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957581858491686\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673730027064331\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771868954615657\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987068597458352\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970413297376953\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128234519964\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.1264299944317498\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4556435276726931\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9378089671247398\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9477792087953242\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9575935999104542\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673772050864848\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977187997063786\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870688293565486\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970413662856734\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128257342503\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9378582120830029\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9478030543069267\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576045832229708\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673810962871512\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771890114637057\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870690416831754\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970413994047969\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112827788279\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9379048932510884\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9478256026153081\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576148534331017\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967384698793343\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771899454439695\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870692360559328\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970414294153568\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128296369047\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.937949138584895\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9478469128436544\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576244532703325\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673880335129617\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.97719080526911\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870694139624598\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970414566078747\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128313006679\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9379910690979273\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40044984442953874\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9380288065596564\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9478670424330519\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576334232610825\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673911198833074\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771915967244825\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870695767703934\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970414812458533\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128327980547\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.15889570422817142\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5029440267548297\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9380647631045629\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.40993633059411533\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9380971239949787\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9478860470925938\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576418018034216\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673939759707004\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771923251523033\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870697257366936\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970415035682755\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112834145703\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9381281302576476\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9479039807618732\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576496252441788\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673966185637084\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771929954850056\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870698620162836\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970415237918725\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128353585863\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9381578113273084\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9479208955848596\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576569279575681\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9673990632603531\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771936122761171\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870699866700505\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970415421131853\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128364501813\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9381861988574787\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9479368418941728\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576637424245862\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.19940567194805012\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9382133263192539\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.46182581684030993\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9382377410348517\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9479518682047896\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576698754449026\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674013245496533\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771941797288404\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870701006722509\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970415587104348\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128374326168\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9382612018836407\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.947965999053356\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.465429850742205\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9382837156015589\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9479787168170657\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957675619030828\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674034158878432\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771947017225092\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870702049173589\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970415737452203\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128383168089\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.2347913907595363\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9383052370062925\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9479907314194111\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576809953006417\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674053497695873\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771951818370768\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870703002263997\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7509991334675254\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870703860045366\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970415873640623\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128391125816\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938325795716185\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480020768122336\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576860253977666\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674071377944992\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771956318678182\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870704645531251\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970415996998017\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128398287772\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9383454217489776\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480127856453892\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576907294996454\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674087915699633\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771960446717958\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987070536468093\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416108728705\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128404733531\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9383641453529734\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480228893013152\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576951269151073\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3246074002114051\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9576990845890229\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674103208354747\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771964233149574\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870706022976978\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416209924454\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128410534715\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9383819968585063\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480328097454969\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577027978928325\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967411734660108\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771967706109337\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870706625461801\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416301574946\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128415755781\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9383990453374599\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480421057623376\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577062798349\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674130414845796\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771970891419122\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987070717677154\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416384577274\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112842045474\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.19279759245408243\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5455511295677553\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9384153092741854\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480508168897589\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577095429583834\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967414249161171\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771973812777592\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870707681167536\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7736192261643315\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870708135123933\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416459744567\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128424683802\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9384308092188529\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948058979953663\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957712599329501\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674153649915521\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771976536877103\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870708551126253\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416527813806\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128428489957\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9384455673123803\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480666292919173\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577154605307145\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674163962074802\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771979029750891\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870708932267194\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416589452931\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128431915497\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938459606881042\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480737969552663\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577181377021836\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967417348981266\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771981311070255\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5521075393748501\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771983364257681\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870709281396315\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416645267272\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128434998484\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9384729520915092\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480805128922558\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577206414811106\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.38696100369689457\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577228948821448\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674182493892904\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771985246690148\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870709601138143\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416695805394\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128437773171\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9384856276586916\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480870281963626\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.95772501208347\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674190783925939\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771986972533809\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870709893909063\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416741564398\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128440270392\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9384976806842623\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480931015729899\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577269996359898\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674198415814192\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771988554777425\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870710161933032\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416782994728\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112844251789\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385091296715621\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40958758387715793\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385194337601319\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9480987643796539\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577288639889514\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674205441155739\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771990005331053\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870710407256207\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416820504526\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128444540638\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385292680577044\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481040454765947\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957730611457498\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674211907567939\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771991335116312\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870710631760534\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416854463597\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112844636111\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385386417541168\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481089714632275\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577322481966708\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967421785898766\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771992554148974\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870710837176377\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416885206987\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128447999536\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385475657535647\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481135668883751\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577337801809815\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674223335949643\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771993671614538\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870711025094232\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416913038243\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128449474118\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385560523001574\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481178544374548\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577352131887849\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674228375844518\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771994695937414\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870711196975595\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416938232356\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128450801243\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385641146594497\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481218550993991\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577365527907671\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967423301315787\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771995634844256\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870711354163039\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416961038443\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128451995655\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385717668483452\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4178115493800152\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385786538183511\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481255883157451\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577378043419533\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674237279691664\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.22694303921077996\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385852216797748\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948129072114024\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577389729767055\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.01989717321490289\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.21089653119319907\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674241119572079\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771996495421971\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071149788954\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970416981682169\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128453070626\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385914776510856\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5085637914437364\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9385971080252654\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481323232273154\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577400627627985\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674244660661646\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771997284170838\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870711629287121\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417000367944\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128454038099\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386024972222431\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481353571181009\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957741078627069\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674247925728394\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977199800705318\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870711749394836\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417017280921\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128454908824\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386076478547107\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481381881903707\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577420252290733\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967425093585382\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977199866953795\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870711859166164\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.13019217834652377\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386125637000864\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481408298690118\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577429069711187\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674253710552695\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9771999276641605\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870711957960359\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417032588803\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128455692477\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386172494871099\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481432946722514\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577437280084785\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674256267884944\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977199983281552\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712048390614\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417046443478\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128456397767\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386217107109518\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481455942778657\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577444922596916\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674258624545187\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772000342324638\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712131149457\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417058982509\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128457032525\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386259534733653\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5506313816932259\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.29423622107744585\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.3477365683635644\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386297719595375\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481477395837886\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577452034167198\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674260795980807\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200080907597\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071220687378\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417070330478\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128457603808\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386334209823788\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948149740763665\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577458649552578\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674262796481248\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772001236648877\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712276149118\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417080600208\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128458117964\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.3958876202044635\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386369032197437\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948151607317869\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577464801448964\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674264639261362\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772001628322753\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712339513628\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417089893866\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128458580705\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386402220222383\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481533481204268\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577470520590943\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674266336539178\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772001987102327\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712397461757\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7939773562827698\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712449615074\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041709830397\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128458997172\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386433812839368\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481549714622345\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577475835849227\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674267899608391\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772002320903986\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071249738566\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417105914293\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128459371992\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386463853303043\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481564850909184\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577480774325535\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674269339417046\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.327737450863055\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674270635244836\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772002626054768\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712541132609\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417112800691\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128459709329\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386492388212748\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481578962476493\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957748548978222\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674271831699774\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200290502142\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712581186617\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417119031846\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128460012932\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.22752739503588196\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.583922291254286\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386519466676646\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481592129717284\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577489852142276\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674272936126918\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772003160056753\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712617852108\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417124669941\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128460286176\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386545140850993\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481604412107641\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3889287264530539\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481615466258962\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577493887604613\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674273955359844\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772003393218436\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712651409221\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417129771278\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128460532095\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386570557925531\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481625814505923\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577497620424776\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674274895752485\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.25339429827490845\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386594457769064\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481635497477383\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577501073061795\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674275742105861\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772003606386105\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712682115655\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417134386828\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128460753422\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386616926242418\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.42521311833258674\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386637147868437\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481644553962763\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577504264224096\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.96742765249275\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772003801276944\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712710208386\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417138562734\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128460952616\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386656243923908\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481653020724672\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577507213769509\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674277248761167\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200397945988\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712735905258\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041714234077\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846113189\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386674268583259\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481660932815386\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577509940019914\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674277917851579\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772004142368512\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712759406468\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041714575875\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128461293237\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386691274073656\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481668323595819\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577512459885229\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674278536160904\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772004291312901\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712780895937\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417148850905\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846143845\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386707310702277\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481675224764875\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577514788976635\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674279107384791\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772004427490308\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712800542583\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417151648221\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846156914\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386722426883772\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481681666397075\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577516941710066\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674279634967853\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772004551994993\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712818501498\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417154178743\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128461686762\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386736669168706\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481687676986664\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577518931400877\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674280122118571\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772004665827142\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712834915044\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417156467859\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128461792622\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386750082273515\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481693283496685\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577520770350527\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674280571823601\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772004769901017\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712849913857\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417158538543\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128461887897\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386762709112335\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481698511411718\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577522469926011\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674280986861442\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772004865052387\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712863617788\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041716041159\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128461973644\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386774590830862\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481703384793221\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577524040632692\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674281369815484\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2772004314326241\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386785766842305\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481707926336536\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577525492181156\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674281714474122\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772004952045309\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712876136756\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417162105821\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462050816\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386796274865391\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481712157428817\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577526832695978\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674282033279196\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005031578317\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712887571557\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041716363827\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462120271\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386806150964304\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481716098122837\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577528070721021\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674282328077529\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005104290069\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071289801459\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041716502435\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462182781\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386815429582035\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481719767311934\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577529214128594\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674282600594493\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005170764506\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712907550542\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417166278011\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846223904\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386824143587713\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481723182779471\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4439049133172652\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481726256700255\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577530270174589\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428285244073\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005231535559\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712916257011\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417167411875\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462289674\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386832628642267\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481729127777514\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4933835403505361\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481731711747047\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577531245548763\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674283085118677\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005287091446\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712924205085\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417168437364\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462335244\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386840805240998\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5884979674957892\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386848164179856\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948173413388167\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577532146420635\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674283300028862\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005337878605\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712931459875\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417169364817\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462376255\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386855027016155\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481736402989146\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577532978481429\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674283498475957\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.38910628757198196\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386861428210466\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481738527559893\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577533746982406\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674283677078344\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005384305272\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712938081004\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417170203585\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462413166\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386867399617849\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481740515755162\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577534456314921\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674283842416731\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005426744764\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712944123059\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417170962129\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462446386\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386872970715825\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481742375354822\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577535111082686\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428399542279\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200546553847\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712949636004\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417171648108\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462476284\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938687816880437\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481744113816526\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577535715521274\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674284136968819\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005500998587\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712954665566\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717226845\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462503192\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938688301919177\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948174573827148\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577536273529059\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674284267870797\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005533410619\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712959253586\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417172829421\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846252741\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386887545361469\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481747255523709\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577536788695362\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674284388891369\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005563035663\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071296343834\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417173336692\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462549206\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386891769122169\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481748672052179\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577537264326071\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674284500742762\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005590112492\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712967254838\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417173795394\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462568821\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386895710743117\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481749994015243\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577537703466997\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674284604089622\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005614859472\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712970735098\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417174210168\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462586476\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386899389076314\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481751227256952\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957753810892517\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674284699551748\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3993946685286041\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386902821667121\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481752377314848\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577538483288276\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674284785467662\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.97720056374763\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712973908395\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417174585212\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462602366\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386906024854579\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481753449428902\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577538828720746\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674284865031049\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.97720056581456\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712976801492\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417174924325\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462616665\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386909013862582\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481754448529366\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577539147486746\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.03878621248153931\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.08591672425153216\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26258296236646805\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6184604613660969\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386911802880731\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481755379277617\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577539434376144\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674284938684359\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.29862595127456815\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386914405141141\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481756245353093\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577539699868282\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285004972337\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005677034388\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712979438852\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417175230942\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462629535\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386916832916984\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481757051104744\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577539945373714\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285066501508\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.31790891913231784\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386919097684655\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481757800586268\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577540172419992\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285121877761\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005694295395\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071298184283\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417175508172\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846264112\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938692121017423\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948175849759722\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577540382243891\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428517342523\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005710068296\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712984033856\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417175758826\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462651544\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386923180418932\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481759145679644\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577540576188599\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285221379468\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005724480818\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712986030594\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.16637197022569175\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386925017799324\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948175974815435\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577540755486307\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285265965122\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005737649765\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712987827659\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417175985445\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462660925\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386926731086672\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176030813206\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577540921268223\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285307395937\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005749679726\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712989467452\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417176190333\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846266937\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386928328483078\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481760828524408\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577541074573598\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285345874636\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005760669031\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712990963549\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417176375567\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846267697\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386929817658687\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481761312054754\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577541216357827\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285381593406\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005770707519\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5936396425673696\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005779742159\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712992328375\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717654303\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846268381\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.29755225180506484\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6495450204243082\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.33210198364656485\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6775211235766984\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386931205786239\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481761761268703\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577541347499792\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428541562854\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005788008452\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712993573298\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417176694425\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462689964\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386932499573216\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481762178544313\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577541468897038\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285447078522\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005795571364\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712994708717\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417176831289\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462695504\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386933705291781\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481762566110689\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577541581268109\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285476132235\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200580249039\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712995744143\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417176955015\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846270049\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386934828807562\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481762926045163\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4680402177879888\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3659663765160015\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7026996660242234\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386935875605277\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481763249986189\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577541685278389\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285502965561\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005808820021\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712996688276\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177066863\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462704977\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386936849793381\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481763551830131\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577541781544141\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285527742187\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005814610158\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712997549067\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717716797\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462709016\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386937756445226\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481763833019988\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577541870636204\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285550614374\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005819906501\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712998333789\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177259365\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846271265\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.4392295419728249\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386938600269682\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481764094910974\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577541953083406\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285571723681\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005824750896\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712999049087\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177341981\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462715921\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.93869393856389\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481764338775134\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754202937571\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285591201651\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005829181666\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870712999701035\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717741666\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462718866\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386940116613749\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481764565805816\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542099967102\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2286478286438182\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386940796967149\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481764777121977\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542163499355\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285609170471\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005833233902\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300029518\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177484161\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462721515\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694143020551\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481764973596215\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542222457296\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428562574358\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005836939734\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713000836594\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177545174\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00711284627239\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386942019570984\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481765156259866\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754227716018\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285641026257\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005840328584\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713001329907\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177600323\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462726047\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386942568083613\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481765326072737\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542327905761\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.44308257237347215\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542373576785\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428565511616\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005843427386\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713001779349\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177650169\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.26753484288526513\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177695031\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.5134150250298719\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462727978\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386943078556452\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481765488449565\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542416075606\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.05578634782151209\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.28558230605952917\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285668103856\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005846260803\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713002193222\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177735598\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462729717\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386943554057314\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481765638796094\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542455610327\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428568007329\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005848851851\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713002569724\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177772279\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462731282\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386943996892396\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481765778021907\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542492376551\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285691102295\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005851221068\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713002912208\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177805448\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846273269\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386944409227326\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481765906964994\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542526558023\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285701262951\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200585338727\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713003223727\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717783544\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462733958\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386944793094127\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766026397739\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542558327252\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285710621996\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005855367691\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713003507062\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8122996793892128\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713003762065\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177862558\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00711284627351\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694515039809\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766137032362\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542587846104\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285719241198\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005857203366\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713003994251\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177887078\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462736125\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386945482924486\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766239525891\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542615266372\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.25496576967000945\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.93869457923451\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766334484673\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542639944614\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285727180212\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005858878461\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713004205647\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177909247\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846273705\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386946080224573\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766422390722\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542662940993\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285734491158\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005860406974\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713004398097\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177929289\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462737882\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386946348018798\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.43187453038990115\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386946589033599\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766503782808\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542684361519\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285741222333\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005861801688\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713004573287\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717794741\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846273863\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386946814004737\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766579156318\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542704306378\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285747418466\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005863074275\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713004732752\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177963794\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462739303\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386947023940739\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766648967017\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542722870168\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285753120972\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005864235389\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713004877892\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177978605\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.5517776943080038\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846273991\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.93869472197944\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766713634462\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542740142128\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285758368179\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005865294762\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005009986\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417177991996\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462740455\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386947402464773\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766773545086\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542756206364\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285763195543\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005866261274\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005130195\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178004102\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462740946\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386947572799259\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766829055007\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542771142087\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285767635854\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005867143037\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005239582\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178015045\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462741388\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386947731595778\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766880492573\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542785023828\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428577171943\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005867947452\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005339113\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178024938\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462741785\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386947879604965\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766928160674\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5379146789042731\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481766971061966\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542797921669\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285775474285\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005868681279\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005429671\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178033881\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462742143\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948021779603\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767010950014\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542809901456\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285778926304\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005869350688\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005512058\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178041965\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462742465\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948153685695\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767048035257\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542821025015\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285782099391\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005869961313\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005587007\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178049272\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.33948848865942644\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178055849\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462742756\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948276072615\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767082513207\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542831350353\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285785015622\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005870518296\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005655836\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178061797\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462743015\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948389634161\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767114565571\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542840931864\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428578769537\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005871026394\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300571837\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178067176\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846274325\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948495012737\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767144361268\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754284982052\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285790157446\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005871489873\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005775184\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717807204\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462743462\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3989370058007995\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7253604895224272\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948592803228\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4378698012414841\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948680814671\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767172057373\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542858064054\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285792419199\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005871912629\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005826797\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178076438\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462743653\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948762766884\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767197799976\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542865707149\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428579449663\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587229822\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2773810152886819\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948839072393\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767221724986\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542872791601\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428579640449\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005872645251\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005873685\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178080416\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462743824\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948910115928\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767243958856\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542879356485\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285798155922\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005872962221\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005916277\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178084013\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462743977\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386948976256262\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767264619263\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542885438273\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285799763589\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587325171\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713005954967\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178087265\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462744117\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949037827943\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767283815725\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754289107104\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428580123915\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005873516081\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300599011\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178090206\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846274424\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949095142906\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767301650186\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542896286612\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285802593326\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40865421138956404\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949148491983\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767318217542\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754290111469\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285803812086\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005873757493\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006022029\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178092865\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462744354\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949198146322\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767333606143\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542905580617\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428580493287\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005873977925\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300605102\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717809527\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462744454\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949244358698\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767347898009\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754290971091\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285805963397\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005874179184\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300607735\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178097444\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462744545\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949287364731\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767361169589\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542913530195\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285806910797\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005874362923\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006101262\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178099409\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462744627\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949327384047\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767373492119\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542917061345\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285807781647\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005874530656\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006122976\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178101186\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00711284627447\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949364621362\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767384931981\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542920325594\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285808582017\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005874683765\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006142696\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178102793\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462744767\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949399267492\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767395551016\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542923342653\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285809317508\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005874823515\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006160603\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178104245\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462744827\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949431500293\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767405406837\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542926130821\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285809993285\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005874951063\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006176863\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178105558\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846274488\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.43085399368343985\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7457552399420373\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.46159836306935753\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7641105153196864\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949461485541\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767414553104\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542928707075\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285810614112\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875067467\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6310185364738006\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875172229\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006191627\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178106745\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846274493\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949489377744\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767423039794\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542931087164\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285811194752\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875267977\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006205032\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.19893378291694294\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949515320909\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767430913444\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542933286728\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285811726806\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875355477\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006217097\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178107819\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462744974\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694953944925\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767438217485\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542935319009\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285812214317\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.416987799964428\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949561887856\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6225789714089001\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949582082602\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767444992318\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5779927087192698\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767451089669\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542937196325\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285812653077\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875435422\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006228061\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178108789\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745014\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.4782373886381601\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694960153222\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767456763138\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542938929348\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285813055876\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875508458\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006238025\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178109666\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846274505\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949619598548\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176746204083\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542940528945\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285813425626\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875575177\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.29891261460452695\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949636380735\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767466949113\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542942005187\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285813765006\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875635223\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300624708\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717811046\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846274508\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949651970623\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767471512714\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542943367404\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285814076392\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875690162\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6646595409957531\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875739607\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006255308\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178111177\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846274511\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949666453319\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767475754815\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542944624227\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285814366974\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3907391353389825\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285814628498\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875784922\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006262783\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178111826\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.58630409665838\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745134\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949679907715\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767479697132\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542945810025\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285814868355\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875826445\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006269576\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178112412\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745156\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694969240696\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767483362611\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754294690099\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285815088338\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875864489\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006275746\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178112941\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745176\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949704019162\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767486769548\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542947904636\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285815290089\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3352635902042925\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949714807431\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767489935152\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542948827891\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285815471665\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875899339\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006281353\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717811342\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745196\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949724830268\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767492875598\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542949676796\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285815638533\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875931259\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006286447\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.228239414339069\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.5133444520501638\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949734141925\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176749560604\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542950457332\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285815791874\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875960491\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006291031\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178113853\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745214\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949742792731\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767498140712\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542951174994\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285815932775\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005875987254\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.98707130062952\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178114244\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846274523\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949750829388\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767500492965\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295183484\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816062236\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876011753\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300629899\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178114597\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745242\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949758295252\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767502675318\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542952441517\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816181176\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876034178\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006302436\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178114916\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745254\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949765230583\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.44326554500790877\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949771472382\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767504699496\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542952999302\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816290442\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876054701\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006305569\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178115205\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745265\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.49108546777907075\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7806302665252943\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949777290393\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767506576477\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542953512125\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816390813\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876073483\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006308418\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178115466\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745276\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949782712425\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176750831653\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542953983603\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816483006\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876090668\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006311007\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178115701\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745285\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949787764519\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767509929253\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542954417061\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816567681\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876106391\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006313361\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178115915\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745293\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949792471063\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767511423617\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542954815556\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816645446\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876120775\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.98707130063155\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178116107\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.00711284627453\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949796854895\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767512807995\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542955181899\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816716858\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876133932\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006317444\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178116281\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745307\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949800937398\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767514090204\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542955518679\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.07848036133925426\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.35279950503907315\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816782431\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876145966\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006319212\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178116439\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745313\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949804738588\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767515277533\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542955828271\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816842638\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876156972\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006320818\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178116581\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745318\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949808277205\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767516376778\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542956112866\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816897914\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876167036\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006322278\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717811671\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745322\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949811570786\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767517394274\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542956374473\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816948659\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876176237\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3182910539887875\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949814635741\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176751833592\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542956614943\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285816995241\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587618452\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006323605\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178116825\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745327\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949817487423\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767519207207\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542956835977\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817037984\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876192105\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006324809\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178116929\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745331\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949820140195\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767520013248\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295703914\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817077204\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587619905\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006325904\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.25461448261898245\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949822607487\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767520758798\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295722587\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581711319\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587620541\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.33573164943462197\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949824901859\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767521448279\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542957397489\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817146207\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876211133\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300632689\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117024\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745333\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949827035053\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767522085802\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542957555214\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817176488\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876216382\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006327786\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117109\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745336\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949829018042\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767522675189\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542957700165\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817204261\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876221195\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006328601\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117187\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.40424676985684393\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117257\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745338\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949830861081\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767523219986\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295783337\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817229733\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.35088279416906976\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949832573752\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767523723491\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542957955777\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817252658\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876225607\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006329349\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117319\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846274534\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.5449408101876275\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949834165003\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767524188764\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958068213\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817273727\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876229651\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006330029\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117376\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745342\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694983564319\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767524618641\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295817149\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817293089\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587623336\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006330646\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117427\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745345\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949837016116\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767525015754\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958266356\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817310883\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876236758\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006331207\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117473\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745347\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949838291064\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767525382547\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958353498\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817327233\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876239871\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6949364450709525\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876242673\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006331716\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117515\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007112846274535\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694983947483\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767525721289\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958433544\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817342534\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876245246\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7221856587386852\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587624756\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006332179\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117553\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745351\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949840573754\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767526034081\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.95775429585071\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817356789\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587624969\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006332599\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117588\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745353\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949841593752\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767526322875\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958574713\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581736983\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876251648\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.351428185335873\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949842540342\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767526589484\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958636854\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581738176\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876253411\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300633298\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117619\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949843418667\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767526835584\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958693963\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817392672\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876255035\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006333326\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117648\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949844233523\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767527062728\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6140629363652638\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767527267158\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958746441\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817402652\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876256531\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300633364\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117673\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949845009619\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752745634\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958794659\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817411784\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876257908\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006333925\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117696\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949845726835\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767527631377\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295883896\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817420138\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876259175\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006334185\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117716\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.5733775326415604\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949846389658\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767527793297\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958879658\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817427783\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876260342\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006334421\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117735\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949847002228\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767527943054\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958917042\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817434779\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876261416\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006334635\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117752\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949847568368\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767528081535\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958951382\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817441182\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.42448802968180555\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949848091602\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767528209568\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542958982921\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817446944\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876262403\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006334829\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117768\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949848575189\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752832792\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959011877\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817452227\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876263311\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006335006\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117781\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4625292229345256\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117793\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949849022134\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767528437304\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295903846\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817457072\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876264146\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006335167\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117804\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949849435213\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767528538381\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959062864\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817461515\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876264913\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006335312\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117814\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949849816991\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767528631766\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959085267\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581746559\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876265618\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006335444\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117823\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949850169837\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752871803\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959105834\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817469327\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876266265\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3655550676469989\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949850495938\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767528797704\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959124714\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817472754\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.43123823642744535\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949850797317\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767528871281\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959142046\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581747584\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4373134224985212\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949851075842\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767528939216\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295915795\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817478616\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876266848\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006335564\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117831\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949851333241\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529001931\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6465261412658565\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529058375\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959172538\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817481173\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876267384\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006335673\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117837\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949851576696\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529110618\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959185921\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817483527\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876267877\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006335772\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117844\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949851800978\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529158963\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959198198\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817485694\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876268332\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006335861\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717811785\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949852007617\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529203688\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959209462\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817487689\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876268749\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006335942\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117855\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.5989705829122798\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985219802\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529245057\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959219797\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.10555947620419708\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.41329498412829396\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817489526\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876269132\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336015\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717811786\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949852373478\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752928331\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295922928\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817491217\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876269484\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336082\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117864\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949852535178\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529318678\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959237983\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817492775\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876269807\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336141\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117867\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949852684209\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752935137\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295924597\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2786519165935816\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949852821573\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529381584\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959253158\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817494208\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876270105\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.37826926172701225\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949852948193\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529409488\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959259768\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817495527\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876270372\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336196\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117871\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853064913\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529435257\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959265849\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817496742\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876270619\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336246\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117874\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853172513\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752945905\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959271441\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817497859\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876270845\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336291\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117876\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853271708\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529481018\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959276585\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.13591973201247848\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4677409153086934\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817498887\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876271054\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336332\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117879\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853363158\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529501298\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959281317\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817499833\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4474406513983326\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817500684\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876271246\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336369\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117881\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985344747\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529520019\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959285753\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817501469\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876271421\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336402\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117883\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853525205\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529537306\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959289823\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817502193\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876271583\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336432\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117885\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853596878\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529553268\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959293558\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581750286\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876271732\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300633646\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117887\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853662964\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529568004\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959296985\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817503475\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876271869\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336485\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117889\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853723899\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529581605\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295930013\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817504042\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876271994\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336507\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.997041717811789\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853780089\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529594157\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959303018\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817504565\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.49847201585179457\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817505036\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272108\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336527\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117891\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5192593173871678\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7954980434251878\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853831902\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752960574\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959305715\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.16863410942679127\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5167422533711239\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817505471\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272214\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336546\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117892\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985387968\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529616432\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6757430256824735\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.448121714397691\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853923738\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.452492266848495\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949853963391\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529626054\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959308185\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817505873\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587627231\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336562\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117893\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854000032\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529634959\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959310448\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817506245\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272399\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336578\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117894\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854033889\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529643197\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959312522\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817506588\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587627248\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336591\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117895\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854065176\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529650816\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959314421\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817506905\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272555\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336603\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985409409\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529657863\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7020382216578389\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529664205\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959316163\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817507197\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272623\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336614\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854121437\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529670084\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295931776\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2999694488247965\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854146631\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529675534\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959319196\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817507466\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272685\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336624\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854169846\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.45642576405421853\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854190739\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529680581\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959320515\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817507715\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272742\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336633\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5460876919475446\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8088790426391573\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854210043\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529685254\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959321728\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817507945\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272795\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336642\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5715579479740667\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.820921941931921\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854227878\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752968958\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959322841\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817508157\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272842\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300633665\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.2783520440709046\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854244359\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529693583\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959323865\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817508352\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.36494007773736925\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854259588\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529697287\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959324805\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817508529\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5444002438599496\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817508688\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272887\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336657\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854273661\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529700714\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959325684\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817508834\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3775916329488388\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854286666\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529703886\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295932649\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817508966\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272927\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336662\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854298684\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.653251877825567\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854309501\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752970682\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959327229\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581750909\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272963\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336668\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854319526\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529709534\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959327906\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817509204\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876272997\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336673\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.29971584937763446\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854328818\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529712043\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959328527\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581750931\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273028\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336678\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854337429\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529714362\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959329096\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817509409\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273056\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336682\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854345408\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529716506\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959329618\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.96742858175095\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273081\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336685\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854352801\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529718488\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.725703898036268\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529720271\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959330096\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817509585\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273104\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336689\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854359827\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6808574936011726\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854366151\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529721923\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959330536\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817509664\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273127\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336692\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854372006\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529723454\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959330939\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817509737\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273147\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336694\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854377428\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529724872\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959331309\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.20292818156785342\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5608434576273579\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817509805\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273164\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336697\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854382447\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529726184\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959331649\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817509868\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273181\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336699\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854387094\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529727398\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295933196\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817509926\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273197\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336701\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854391398\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529728523\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959332247\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2381588657161765\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6005345414579704\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2737958987488979\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6362565169055215\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3094057040476548\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6684062948083176\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581750998\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587627321\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336702\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854395381\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529729563\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295933251\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581751003\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273222\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336703\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854399069\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529730526\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959332752\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510075\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273233\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336704\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854402484\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529731415\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959332974\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510118\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273243\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336705\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854405646\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529732238\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959333178\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510156\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273253\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336707\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854408573\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529732998\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959333366\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510193\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.44278108996248944\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854411283\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529733702\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959333538\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510226\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273262\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336708\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854413791\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529734353\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959333697\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510256\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587627327\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336709\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854416112\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529734954\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959333842\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510284\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273278\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.987071300633671\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854418262\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529735509\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959333977\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510311\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273284\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336711\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854420251\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529736022\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.95775429593341\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510335\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587627329\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336712\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854422092\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529736496\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334213\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510357\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273295\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5149834307044402\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854423796\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529736933\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334318\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510377\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273301\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854425373\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529737337\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334413\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510396\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273305\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854426831\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752973771\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334501\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510414\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587627331\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7467099510399224\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273313\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854428182\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529738054\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334582\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510431\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273316\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985442943\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529738373\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334656\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510446\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587627332\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854430586\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529738667\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334725\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510461\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273322\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3189432741536914\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854431655\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529738938\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334788\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3446373568289127\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6973410949208394\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510473\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273324\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854432645\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529739188\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334846\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510485\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273326\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985443356\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529739419\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334899\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510496\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273329\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854434405\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529739632\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334948\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510506\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273331\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854435188\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529739829\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7470030067770655\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529740005\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959334994\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510515\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273332\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985443593\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529740169\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335035\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510524\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273333\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854436614\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529740321\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335074\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510532\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273334\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854437244\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529740461\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335109\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510538\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273335\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854437825\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529740591\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335141\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510545\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273336\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3362479564521426\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5956734254279202\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8317605512976634\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.6220043281799863\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854438361\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529740711\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335171\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510551\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273337\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.6427346989209275\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854438855\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529740822\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335199\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510556\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273339\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854439312\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7057025478000045\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854439721\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529740924\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335225\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510561\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.977200587627334\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854440101\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741019\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335248\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510565\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273341\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854440452\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741106\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335269\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581751057\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854440776\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741187\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335288\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510573\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.6613920325877984\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6184503774635969\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8415152997268607\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854441076\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741262\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335306\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510576\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3518221705207487\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6399153543901964\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8502945733131413\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854441353\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741331\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335322\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581751058\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985444161\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741394\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4703895481291943\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854441846\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741452\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335338\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510583\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854442065\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741505\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335352\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510585\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5621922176973634\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6601029817091778\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8581959195408035\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854442267\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741554\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7661722046438004\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741598\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335364\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510587\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7687818141110363\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854442459\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741639\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335377\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.967428581751059\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854442636\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741678\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335388\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510592\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.44770199068006084\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854442798\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741714\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335398\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510593\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854442947\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741747\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335407\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510594\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.45213080132587513\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854443085\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741778\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335414\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510595\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854443213\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741806\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335422\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4935919904335456\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7834244827238642\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741832\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335429\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510596\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854443333\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741857\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335434\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510597\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854443444\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741879\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295933544\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510598\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6046801259909942\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6790540795727996\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8653071311457132\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6968140775989453\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.871707221590132\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854443546\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.94817675297419\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335446\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.96742858175106\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.6173778587737211\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854443639\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741919\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295933545\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510601\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.38971203639902424\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854443725\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741937\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335454\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510602\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3658389631824942\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854443803\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741953\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335459\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510603\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854443877\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741969\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335462\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854443944\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4599659115393698\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444004\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741982\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335466\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985444406\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529741996\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335469\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.37921038954318453\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7233824150221104\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444111\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742008\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4725039454362792\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444159\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742019\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335472\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444203\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742029\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335474\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40001053360383504\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444244\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742038\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335477\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444282\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742047\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335479\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444316\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742055\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335481\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.412904209676055\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7468196031132543\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444349\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7280630965790031\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444377\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742062\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335483\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7886464908750388\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444404\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742069\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335484\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7134316847764739\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8774673029901184\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.6781836328880182\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444429\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742076\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335485\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444451\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742081\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335487\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444472\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742087\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335488\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444491\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742091\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335489\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3191552278328899\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444508\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742096\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957754295933549\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444525\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.46315204427600587\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985444454\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.94817675297421\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335491\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8287897702130249\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444554\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742103\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444567\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.46601956373897835\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444578\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742107\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985444459\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752974211\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.93869498544446\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742112\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5857356490673096\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40927918108816475\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444608\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742114\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.336422428940174\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444617\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742117\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444625\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742119\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444633\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742121\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7989515329959248\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742122\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985444464\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742123\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444646\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742124\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.642919243455262\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444652\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742126\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444657\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742127\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444662\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742128\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444666\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742129\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444671\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.948176752974213\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.45611673090710797\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444674\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444677\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3889780326391614\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985444468\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444684\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.806524699962641\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444686\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444688\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4686003312556536\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.6932960731582188\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7068972694013994\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.938694985444469\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8129258782407794\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444693\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444695\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444696\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444697\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444698\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444699\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4176209638240615\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.93869498544447\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4251285682863686\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444702\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444703\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4455489294166617\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7679130723952838\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.645344244677528\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4770174306421286\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7868971947491105\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.39922579236045175\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5072185098580777\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8039829048675544\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3519629099367297\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5390504666876125\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3784540765780651\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3659493428336298\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40844877610961305\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4318854123024449\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7289577792948483\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8826513762501091\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8255027889611486\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7434444876141243\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8873170421841008\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.47092302202066133\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.47440690301265565\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6773344491731029\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8436308519544559\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.47611956483139445\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8368220086094809\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.47766096046825934\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4167494614838583\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.719138346020262\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8470093062929799\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7481875904801054\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7569444260289379\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8915161415246933\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.42422007832067893\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7083081343191598\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7301553149772384\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5799630953162725\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8569878255217438\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.37853713244083986\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.47301344370916826\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.856177874208129\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.389866143087329\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6167844610820666\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4748948232288245\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.736184450950611\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.6705139919909543\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644295853317632\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40006225266916917\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.822615088141483\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.45970406753021753\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40923875129282533\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.38980767863407895\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7662996349910974\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6499236902712814\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4765880647965151\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8718561253430339\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7695100814369887\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8952953309312265\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7400705870385171\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6229375137539336\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8690091017323028\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8785400113531776\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.41749760005411585\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6564191919718952\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.43094363347381753\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.6931667645730379\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4629326704910161\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7826004750509903\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6865527023680607\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4000259204844914\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.879828250321806\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7811933110554813\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8986966013971064\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8370964375024408\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4369948331116423\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8895654840523589\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.47904821654143775\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6797489965415746\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8845555087623069\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7972712311048938\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4379665719169137\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7136728617246095\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7920449434882467\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9017577448163984\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.748994331893668\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4802967470072983\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.42493056393927736\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8899694564305234\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.47811198220743667\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8983289944098565\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4316202314359227\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7570257022633038\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.44244091278568454\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.810474911553407\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.764253935595976\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.770759345595381\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4814204244265728\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8948420093319182\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4376409321829035\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.44343961556993555\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7766142145948455\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4824317341039199\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4833419128135322\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8223582239570689\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.48416107365218336\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8330532051203646\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7065917721848385\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4483653548576552\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4848983184069694\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.730750270263776\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7135542598969131\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7319030056884008\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8426786881673307\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7524929185348198\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8021144658762455\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9045127738937611\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4855618386862768\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7818835966943635\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7866260405839297\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7908942400845393\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8114497839041033\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9069923000633875\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8501296519273028\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8513416229096002\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7612731359189171\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.40922233814986264\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8200970432199683\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.45589085920569483\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.44734238449232255\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8618595449096786\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4430595628551862\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8278795766042468\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9092238736160513\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.48615900693765346\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8351047824318112\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9112322898134487\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.794735619635088\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.48669645836389247\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4174991140486967\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.7981928612305818\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8418063008801615\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9130398643911064\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8480166173668648\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9146666815109983\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8591382641776428\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8992273069431734\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8724164485938168\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7838529523903925\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.8013043786665262\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.8041047443588761\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7380810051455036\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4249482123576474\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8537669570997672\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9161308169189011\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9062161537316042\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4517537090282968\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8041747872147205\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.431652400835703\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8590872122647617\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9174485387860135\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.8066250734819911\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4557239011106736\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.47948350787726607\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5360909664541578\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.819360043974154\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8640058963781009\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9186344884664147\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4871801646475076\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8224644385566156\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8819176619095412\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.48071788098011253\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.8088933696927946\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5635985141621832\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8331994691700936\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8685501210984659\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9197018431787758\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.8109348362825177\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7600483342243082\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9133145971211772\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8661552413188811\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7798189303952323\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.43768617046595304\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8724705207459955\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8727455914633181\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9206624624199008\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.8127721562132685\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8766166160965565\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9215270197369133\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9031740747933031\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9067261658584199\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4479363304602407\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4658384131557348\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7976124669490641\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.909923047817025\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.48182881677267436\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.45279852021660294\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8801861294408553\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9223051213222245\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8389251247643211\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8537397423512562\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.45678836903965586\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.8144257441509442\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7720613019787592\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.88347572350767\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9230054127490046\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4523254213047897\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.919703196171793\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.48282865898598\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4603792329804035\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 1\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.48372851697795505\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4592970739848128\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.462512929571538\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.8159139732948523\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9128002415797696\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8865056870190544\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9236356750331067\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8781542722303985\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8904687538936932\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.1\n",
      "Done: False\n",
      "New Q-Value 0.8172533795243696\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9386949854444704\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9481767529742131\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577542959335492\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5897254101938041\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8456549518464392\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9674285817510604\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9772005876273342\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9870713006336713\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9970417178117896\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 3\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0071128462745356\n",
      "--------NEXT--------\n"
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state_tuple = env.reset()  # State is a tuple\n",
    "    state = state_tuple[0]  # Extract the integer state value\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Choose action using epsilon-greedy policy\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.choice(custom_policy(state))  # Custom policy\n",
    "        else:\n",
    "            action = np.argmax(Q[state, :])\n",
    "\n",
    "        print(\"Episode:\", episode)\n",
    "        print(\"Action:\", action)\n",
    "\n",
    "\n",
    "        # Take action and observe the next state, reward, done flag, and info\n",
    "        step_result = env.step(action)\n",
    "\n",
    "        next_state = step_result[0]  # Extract the next state tuple\n",
    "        reward = step_result[1]  # Extract the reward\n",
    "        terminated = step_result[2]  # Extract the done flags\n",
    "        truncated = step_result[3] # Extract the done flags\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            if reward == 0:\n",
    "                reward = custom_rewards[\"F\"]\n",
    "            else:\n",
    "                reward = custom_rewards[\"G\"]\n",
    "        else:\n",
    "            reward = custom_rewards[\"S\"]\n",
    "\n",
    "        if next_state == state:\n",
    "            reward = -0.1\n",
    "\n",
    "        # Update Q-value using SARSA formula\n",
    "        next_action = np.argmax(Q[next_state, :])\n",
    "        Q[state, action] = Q[state, action] + learning_rate * (reward + discount_factor * Q[next_state, next_action] - Q[state, action])\n",
    "\n",
    "        print(\"Step Result:\", step_result)\n",
    "        print(\"State Tuple:\", state_tuple)\n",
    "        print(\"State:\", state)\n",
    "        print(\"New State:\", next_state)\n",
    "        print(\"Next Action:\", next_action)\n",
    "        print(\"Reward:\", reward)\n",
    "        print(\"Done:\", done)\n",
    "        print(\"New Q-Value\", Q[state, action])\n",
    "        print(\"--------NEXT--------\")\n",
    "\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
