{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=[\"SFFF\", \"FHHH\", \"FFFF\", \"HFHF\", \"FFGF\"]\n",
    "# env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x4\", is_slippery=False, render_mode='human')\n",
    "env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x4\", is_slippery=False)\n",
    "observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom rewards\n",
    "custom_rewards = {\n",
    "    'S': 0.0,  # Reward for frozen tiles (very small positive reward)\n",
    "    'F': -0.75,  # Reward for falling in a hole (negative reward)\n",
    "    'G': 1.0,   # Reward for reaching the goal (the \"gift\" state)\n",
    "}\n",
    "\n",
    "# Map custom rewards to the environment's reward table\n",
    "env.env.rewards = custom_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom policy to avoid edges\n",
    "def custom_policy(state):\n",
    "    if state % 4 == 0:  # Agent is at leftmost column\n",
    "        return [1, 2, 3]  # Avoid going left\n",
    "    elif state % 4 == 3:  # Agent is at rightmost column\n",
    "        return [0, 1, 3]  # Avoid going right\n",
    "    elif state < 4:  # Agent is at top row\n",
    "        return [0, 1, 2]  # Avoid going up\n",
    "    elif state > 15:  # Agent is at bottom row\n",
    "        return [0, 2, 3]  # Avoid going down\n",
    "    else:\n",
    "        return [0, 1, 2, 3]  # All actions are allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q-table with zeros\n",
    "Q = np.random.rand(env.observation_space.n, env.action_space.n) * 0.01\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.8\n",
    "discount_factor = 0.95\n",
    "epsilon = 1.0\n",
    "max_exploration_rate = 1.0\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.001\n",
    "num_episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.008039227544714466\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.00833733050311713\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.024800959274712344\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 3\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.059287262033389285\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.00856234507087417\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02306470467339521\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.007056794398674175\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 6\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6073566830862006\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.011350356419489206\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6101847581939424\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.011879517125964677\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.023091283539809125\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.012498045677217897\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.024709020286299024\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.009250121767437804\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 3\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.06892179779606643\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.042695899116356587\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.0321550064332636\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 1\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6112470192722382\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.025529701678696313\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01451167735878541\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02778314063827097\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6090417693363621\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03980892090372385\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03213481512841617\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01813947216255249\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.013174650646975851\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6111407827304822\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.036212961869223126\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.029640628924212143\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01756146758577051\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.04506422522212647\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.03502780751104288\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.008335755367813561\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.06191020065361406\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.012590472798434489\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6088006718247242\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.027794165029645095\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01323310852402499\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.007804699290476498\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6102112056743254\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03161599548418801\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.016505960359682072\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.029296006721949985\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 1\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.04430305573608021\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.07323276353269856\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.012105666732145158\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 2\n",
      "Reward: -0.16\n",
      "Done: False\n",
      "New Q-Value -0.13576470852539083\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.03127171544425676\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 2\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.060021787913045556\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 3\n",
      "Reward: -0.16\n",
      "Done: False\n",
      "New Q-Value -0.1263164620947818\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 2\n",
      "Reward: -0.32\n",
      "Done: False\n",
      "New Q-Value -0.31362091639652373\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 3\n",
      "Next Action: 3\n",
      "Reward: -0.64\n",
      "Done: False\n",
      "New Q-Value -0.6332638036109905\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: -0.32\n",
      "Done: False\n",
      "New Q-Value -0.3054179068137602\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 2\n",
      "Next Action: 3\n",
      "Reward: -0.64\n",
      "Done: False\n",
      "New Q-Value -0.540124166453072\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (3, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 3\n",
      "Next Action: 0\n",
      "Reward: -1.28\n",
      "Done: False\n",
      "New Q-Value -1.2623719522673091\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (2, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 3\n",
      "New State: 2\n",
      "Next Action: 0\n",
      "Reward: -1.28\n",
      "Done: False\n",
      "New Q-Value -1.1187539037221732\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 2\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.09038978669899642\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.16\n",
      "Done: False\n",
      "New Q-Value -0.1501421164864594\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.044646413275944714\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.32\n",
      "Done: False\n",
      "New Q-Value -0.29625447318655557\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.06845113367579853\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.04202144779143188\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.055720659474847056\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.04304331266992836\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 3\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.11023324288764429\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.10279395971010145\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.16\n",
      "Done: False\n",
      "New Q-Value -0.1662165640675749\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.16\n",
      "Done: False\n",
      "New Q-Value -0.16911720718743195\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.061723849419071615\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.09067181501274013\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.029340735581746883\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.015488827357624246\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.008996098658211578\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 11\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02387706325223572\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.007596436228872027\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.008316403200070932\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.024652073620201054\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 15\n",
      "Next Action: 3\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02615415067969582\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 3\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.059077669540555953\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 3\n",
      "Step Result: (7, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 7\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6110933438565455\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07291577155205371\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 3\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.10199914068997157\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 3\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.1619191750623727\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 3\n",
      "Reward: -0.16\n",
      "Done: False\n",
      "New Q-Value -0.28344240805987775\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.32\n",
      "Done: False\n",
      "New Q-Value -0.4155679015048719\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.09217114263837015\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 0\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 4\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.08549183309585318\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.050643728925941954\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.031436906443159586\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.015511954493576199\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.04298041930071267\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01750776868114976\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6086429955599633\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07292346251138991\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05002079468198967\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03407646670374983\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.016301774994791452\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6083244115827137\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.06860049646059013\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.051902273631247796\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03520464233679147\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.016923454834895026\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.010888288144858907\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 17\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.026319909733360815\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.7919423122767622\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.06916582725186635\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05313598290221108\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03590275414187851\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.027659789957071773\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5836984997013674\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9499140478895542\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07021651245605369\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05391328972826988\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03648645502604952\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.019089472292671144\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 3\n",
      "Step Result: (6, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 6\n",
      "Next Action: 3\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6091472033262206\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07101740268469585\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05451236376545161\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03780528994763997\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.02665492943877503\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.01594888042050856\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.04363421772191973\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.040963067618044455\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.013922210415235212\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 15\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.027456324003529434\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.6086334017649782\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07163287699868238\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.055634493113296705\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.04381880436299702\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.052462917277468796\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.03477349343918765\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.02510490851510095\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.012999987108699887\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.7927527679424424\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07260879016584197\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.060429189938537076\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.04578520123997395\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4220789017816249\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8226743763363347\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9815083950121126\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07644794238645657\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.0628825909300876\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.2956229251060401\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6936483063719392\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8944812554764725\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9878272644366243\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.07908035758415789\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.1960969048945729\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5702972978638818\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8025354154365069\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9136449720671289\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9890910383215267\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.11721757620304384\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4566453273554648\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7079863753045216\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8388772618583193\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.918438183537786\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9893437930985071\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.354493964030762\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6133987107025294\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.763143994073227\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8497884718603812\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9195889194624225\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9893943440539031\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5210818129400747\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6866691776361583\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7824680374285351\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8528452731635172\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9198574853734508\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894044542449824\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6100849375914952\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7160095439729183\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7886560150899801\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.853660743516526\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199188823008767\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894064762831982\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6501842409377169\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7265804802629684\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7905133680905557\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8538704992519714\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199326984354059\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894068806908414\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6662380131873994\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.730106255801416\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7910442530496095\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539229506613027\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199357690121206\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069615723701\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6721283570465559\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7312148834779864\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.791190293112512\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539357745814722\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199364445974254\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069777486758\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6741489828525808\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7315475994611063\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912292473044212\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539388528103377\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199365920084787\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.989406980983937\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.674805972160957\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316437478435813\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912393775967408\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539395804885113\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366239494878\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069816309892\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750104427933131\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316706765422392\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912419566906167\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397502993129\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366308294493\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817603997\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750718027307644\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316780223933165\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912426015656011\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397894902441\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366323037935\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817862817\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750896575650734\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316799816685201\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.5020301374905465\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7156803735235607\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912427603257056\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397984489319\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366326183328\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817914581\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6629350153909208\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7284805725522484\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912427988863293\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398004797192\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366326851747\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817924934\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6702322382178929\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7310406416640599\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428081418524\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398009366765\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366326993299\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927005\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6736373353082641\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7315526625206198\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428103402446\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.853939801038826\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327023183\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927419\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6747074905773238\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316550683627098\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428108575567\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010615271\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327029475\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927501\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6749993500711241\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.731675549924285\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428109782719\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010665454\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327030796\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927518\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750732879566813\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316796463283436\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110062288\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010676496\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031072\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927521\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750911888008774\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316804656304026\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110126594\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010678914\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.919936632703113\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750953916392815\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806294957016\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110141293\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679441\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031142\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750963567445895\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806622698785\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110144634\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679555\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031144\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750965746740255\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806688249679\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145389\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.853939801067958\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966232417807\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806701360431\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145558\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679586\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966339517489\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.731680670398271\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145596\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966362930357\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704507195\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145605\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636801154\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704612099\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369107503\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704633081\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369342641\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704637278\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369392859\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638117\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940354\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638285\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369405803\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638318\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406282\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638324\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406383\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406405\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.5603316913266408\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7752428110145607\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406409\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7195206704638327\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7880428110145608\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.665855036940641\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7268166704638327\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7906028110145608\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.669551676940641\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7302214704638327\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7911148110145607\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.672878652940641\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7312915504638327\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912172110145608\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6743573089406409\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7315833904638327\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912376910145608\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.674874838540641\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316573232638327\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912417870145607\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750345333886411\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316752227838327\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912426062145608\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675080075993441\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316794252798327\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912427700545608\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750923784113609\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316803902974327\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428028225608\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675095572308321\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806082046328\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428093761608\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750963766971851\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806567668086\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428106868807\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750965744822115\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806674753911\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428109490247\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966221777395\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.731680669816337\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110014535\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966334959639\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806703243721\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110119393\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966361457156\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704339482\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110140365\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966367589437\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704574573\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110144559\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966368994563\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.731680670462478\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145397\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369313746\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704635458\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145565\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369385697\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.731680670463772\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145598\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369401806\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638198\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145605\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369405391\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638299\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406185\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638321\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940636\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638326\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406399\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406408\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.127273756230918\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4833832173397275\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7340596223951581\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.3259164939320093\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5937500875428326\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05292043846927637\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.041101266759536674\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 11\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.054921980722146296\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.030900971905632103\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5838921062145163\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9500761390226903\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6244833370506221\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7156806704638327\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.662936636940641\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7284806704638327\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.670232636940641\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4728180121328667\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6556918369406409\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7310406704638327\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.670729276940641\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7315526704638327\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.674125884940641\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316550704638327\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.674883030540641\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316755504638327\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675050024460641\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316796464638327\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6671749337006287\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.9039366327031145\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675086536204641\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316804656638327\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8417798010679588\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9167366327031146\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675094461145441\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806295038327\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7820012110145608\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8490758010679588\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9192966327031146\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750961706520011\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7246570462718327\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7856978510145608\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8524806010679588\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9198086327031145\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.008359688490363129\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 16\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02263351487338559\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 16\n",
      "Next Action: 0\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.0570312151051223\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7209265403738113\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6697585892969931\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7260617760254326\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7890248270145608\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8535506810679587\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199110327031146\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6697586676387274\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7288712237361527\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7905034830145607\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8538425210679588\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199315127031146\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6718938635672215\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7305568918382966\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7910210126145607\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539164538679588\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199356087031145\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6736020105105497\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7312873479547254\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7911807074625608\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539343533879588\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199364279031146\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6744987865477012\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7315548072624912\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912262500673608\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539385558839587\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199365917431146\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6748814108290335\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316429115036924\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912385524852807\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539395209015588\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366245111146\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750248949086128\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316698821895519\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912417463822408\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397388087588\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366310647146\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675074089445782\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316777036884133\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912425507711048\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397873709348\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366323754345\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750898726923505\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316798793237224\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912427485561313\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397980795171\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366326375785\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675094682824499\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316804647674042\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912427962516593\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.853939800420463\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366326900074\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096089788127\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806181047418\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428075698836\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398009284982\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327004931\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750964877172292\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806573740599\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428102196354\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010380743\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327025903\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750965971477313\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806672417348\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428108328635\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010615834\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327030097\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966265332646\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806696813232\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.791242810973376\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.853939801066604\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327030936\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966342644585\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806702760303\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110052943\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010676719\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031103\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966362626747\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704192297\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110124894\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010678981\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031137\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966367711495\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704533378\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110141004\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679459\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031143\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966368987666\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704613839\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110144589\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.853939801067956\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636930405\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704632656\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145382\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679582\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369381628\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704637021\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145557\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679586\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369400461\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638027\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145596\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369404993\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638258\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145605\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406074\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638311\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940633\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638323\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406391\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638326\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406406\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406409\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7586433903280932\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6083981649515062\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8379398010679587\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7790828110145608\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8507398010679588\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7224390704638327\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7863788110145608\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8532998010679588\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.668073020940641\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7261357104638327\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7897836110145607\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8538118010679587\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6694777441406411\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7294626864638327\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7908536910145608\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539142010679588\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.672287190540641\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7309413424638327\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7911455310145608\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539346810679588\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.673972858380641\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7314588720638326\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912194638145608\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539387770679587\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.674703314444641\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316185669118327\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912373633345607\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539395962679588\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.674970773741921\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316641095166327\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912415658305608\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397601079588\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675058877981025\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316764119345528\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912425308481608\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397928759588\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675085848666465\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316796058315127\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912427487553608\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397994295588\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750936701652427\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316804102203768\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912427973175368\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398007402788\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750958458005348\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806080054032\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428080261191\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010024227\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750964312442135\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806557009311\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.791242810367065\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010548516\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750965845815503\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806670191556\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428108751002\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010653373\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966238508682\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806696689072\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428109846763\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010674345\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966337185431\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806702821353\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110081854\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010678539\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966361581314\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.731680670422648\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.791242811013206\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679378\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966367528387\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704545662\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110142739\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679545\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636896038\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704617613\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145001\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679579\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369301461\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704633723\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.791242811014548\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679585\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369381921\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704637309\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.791242811014558\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369400738\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638101\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145602\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369405105\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638277\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145606\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406111\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638316\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406342\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638324\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406395\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406407\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406409\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.05782105043110314\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.04770499200018773\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.42157780634190595\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8228362869001479\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9815408132387399\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7314988981877891\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7635601439146803\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4403849624629116\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5851504365674695\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7338684174878501\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.06382000400636331\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.29485813441981096\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6936711393124936\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8945382754414718\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9878337480819498\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.19532818135778365\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5701616927614572\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8025833171980172\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9136613036305762\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9890923350505917\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5004333653189547\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6158234615834537\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.4563885227702642\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7079956596227845\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8388992541988413\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9184424353645649\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9893440524443201\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7586051493466317\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6814108746363943\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7752428110145607\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7195206704638327\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7880428110145608\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6658550369406411\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7268166704638327\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7906028110145608\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6695516769406411\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7302214704638327\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7911148110145607\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.672878652940641\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7312915504638327\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912172110145608\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6743573089406409\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7315833904638327\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912376910145608\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.674874838540641\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316573232638327\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912417870145607\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750345333886411\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316752227838327\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912426062145608\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675080075993441\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316794252798327\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912427700545608\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750923784113609\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316803902974327\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428028225608\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675095572308321\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806082046328\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428093761608\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750963766971851\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806567668086\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428106868807\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750965744822115\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806674753911\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428109490247\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966221777395\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.731680669816337\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110014535\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966334959639\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806703243721\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110119393\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966361457156\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704339482\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110140365\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966367589437\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704574573\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110144559\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966368994563\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.731680670462478\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145397\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369313746\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704635458\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145565\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369385697\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.731680670463772\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145598\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369401806\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638198\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145605\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369405391\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638299\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406185\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638321\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940636\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638326\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406399\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406408\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.530232232986024\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8641346142372539\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7645434946319977\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7386738818019498\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.8379398010679587\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7790828110145608\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8507398010679588\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7224390704638327\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7863788110145608\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8532998010679588\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.668073020940641\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7261357104638327\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7897836110145607\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8538118010679587\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6694777441406411\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7294626864638327\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7908536910145608\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539142010679588\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.672287190540641\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7309413424638327\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7911455310145608\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539346810679588\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.673972858380641\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7314588720638326\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912194638145608\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539387770679587\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7307262980844994\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.674703314444641\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316185669118327\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912373633345607\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539395962679588\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.674970773741921\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316641095166327\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912415658305608\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397601079588\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675058877981025\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316764119345528\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912425308481608\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397928759588\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675085848666465\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316796058315127\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912427487553608\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539397994295588\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750936701652427\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316804102203768\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912427973175368\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398007402788\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750958458005348\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806080054032\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428080261191\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010024227\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750964312442135\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806557009311\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.791242810367065\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010548516\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750965845815503\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806670191556\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428108751002\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010653373\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966238508682\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806696689072\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428109846763\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010674345\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966337185431\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806702821353\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110081854\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010678539\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966361581314\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.731680670422648\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.791242811013206\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679378\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966367528387\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704545662\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110142739\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679545\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636896038\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704617613\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145001\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679579\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369301461\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704633723\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.791242811014548\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679585\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7552066753848565\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369381921\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704637309\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.791242811014558\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369400738\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638101\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145602\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369405105\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638277\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145606\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406111\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638316\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406342\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638324\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406395\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406407\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406409\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.6489739769626373\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value 0.7156806704638327\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.662936636940641\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7284806704638327\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.670232636940641\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7310406704638327\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6736374369406409\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7315526704638327\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.674707516940641\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316550704638327\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6749993569406411\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316755504638327\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750732897406411\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316796464638327\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750911892606409\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316804656638327\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675095391756641\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806295038327\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750963567742411\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806622718327\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096574681441\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806688254327\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096623243617\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806701361527\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966339521994\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806703982967\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966362931453\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704507255\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966368011805\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704612112\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369107566\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704633084\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369342657\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704637279\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369392863\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638117\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369403542\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638285\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369405804\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638318\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406282\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638324\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406383\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406405\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6141035313883806\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6750966369406409\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5521125038672158\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6202381363915779\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.7559903239580745\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 2\n",
      "Reward: -0.77\n",
      "Done: True\n",
      "New Q-Value -0.760102750844928\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5658034844310423\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6211210713532027\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.675096636940641\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7316806704638327\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7912428110145607\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.8539398010679587\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.9199366327031145\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 2\n",
      "Reward: 0.98\n",
      "Done: True\n",
      "New Q-Value 0.9894069817927522\n",
      "--------NEXT--------\n"
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state_tuple = env.reset()  # State is a tuple\n",
    "    state = state_tuple[0]  # Extract the integer state value\n",
    "    done = False\n",
    "\n",
    "    # Reset state visits count for the new episode\n",
    "    state_visits = {s: 0 for s in range(env.observation_space.n)}\n",
    "\n",
    "    while not done:\n",
    "        # Choose action using epsilon-greedy policy\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.choice(custom_policy(state))  # Custom policy\n",
    "        else:\n",
    "            action = np.argmax(Q[state, :])\n",
    "\n",
    "        print(\"Episode:\", episode)\n",
    "        print(\"Action:\", action)\n",
    "\n",
    "        # Take action and observe the next state, reward, done flag, and info\n",
    "        step_result = env.step(action)\n",
    "\n",
    "        next_state = step_result[0]  # Extract the next state tuple\n",
    "        reward = step_result[1]  # Extract the reward\n",
    "        terminated = step_result[2]  # Extract the done flags\n",
    "        truncated = step_result[3] # Extract the done flags\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Update state visits count\n",
    "        state_visits[next_state] += 1\n",
    "\n",
    "        # Calculate penalty for visiting the same state\n",
    "        visit_penalty = -0.01 * (2 ** state_visits[next_state])\n",
    "\n",
    "        # Check if the agent stayed in the same state\n",
    "        if next_state == state:\n",
    "            reward = visit_penalty\n",
    "        else:\n",
    "            # Check for falling into the ice\n",
    "            if terminated and reward == 0:\n",
    "                reward = custom_rewards[\"F\"]  # Penalty for falling into the ice\n",
    "            elif not terminated:\n",
    "                reward = custom_rewards[\"S\"]  # Reward for a safe move\n",
    "            reward += visit_penalty  # Add penalty for repeated visits\n",
    "\n",
    "        # Update Q-value using SARSA formula\n",
    "        next_action = np.argmax(Q[next_state, :])\n",
    "        Q[state, action] = Q[state, action] + learning_rate * (reward + discount_factor * Q[next_state, next_action] - Q[state, action])\n",
    "\n",
    "        # Decay the exploration rate\n",
    "        epsilon = max(min_exploration_rate, epsilon * exploration_decay_rate)\n",
    "\n",
    "        print(\"Step Result:\", step_result)\n",
    "        print(\"State Tuple:\", state_tuple)\n",
    "        print(\"State:\", state)\n",
    "        print(\"New State:\", next_state)\n",
    "        print(\"Next Action:\", next_action)\n",
    "        print(\"Reward:\", reward)\n",
    "        print(\"Done:\", done)\n",
    "        print(\"New Q-Value\", Q[state, action])\n",
    "        print(\"--------NEXT--------\")\n",
    "\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
