{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc=[\"SFFF\", \"FHHH\", \"FFFF\", \"HFHF\", \"FFGF\"]\n",
    "# env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x4\", is_slippery=False, render_mode='human')\n",
    "env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x4\", is_slippery=False)\n",
    "observation, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom rewards\n",
    "custom_rewards = {\n",
    "    'S': 0.0,  # Reward for frozen tiles (very small positive reward)\n",
    "    'F': -0.5,  # Reward for falling in a hole (negative reward)\n",
    "    'G': 1.0,   # Reward for reaching the goal (the \"gift\" state)\n",
    "}\n",
    "\n",
    "# Map custom rewards to the environment's reward table\n",
    "env.env.rewards = custom_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom policy to avoid edges\n",
    "def custom_policy(state):\n",
    "    if state % 4 == 0:  # Agent is at leftmost column\n",
    "        return [1, 2, 3]  # Avoid going left\n",
    "    elif state % 4 == 3:  # Agent is at rightmost column\n",
    "        return [0, 1, 3]  # Avoid going right\n",
    "    elif state < 4:  # Agent is at top row\n",
    "        return [0, 1, 2]  # Avoid going up\n",
    "    elif state > 15:  # Agent is at bottom row\n",
    "        return [0, 2, 3]  # Avoid going down\n",
    "    else:\n",
    "        return [0, 1, 2, 3]  # All actions are allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Q-table with zeros\n",
    "Q = np.random.rand(env.observation_space.n, env.action_space.n) * 0.01\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.8       # Alpha - how much we update our Q-value with the new information we gain\n",
    "discount_factor = 0.95    # Gamma - how much importance we give to future rewards\n",
    "epsilon = 1.0\n",
    "max_exploration_rate = 1.0\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.001\n",
    "num_episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 3\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value -0.007398352801754663\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 0\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.024726372473177178\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003680622102293343\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003631541168520147\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00349609570853398\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003383340972189854\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032705582805710853\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031622924876719954\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030574539467449332\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0029561234970605483\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028581446471150035\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.002763414631219512\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0028134134405725505\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007774012348025786\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007798793872820127\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007481885812948454\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00724599199240485\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007003331076817377\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006771730016862177\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006547181028178729\n",
      "--------NEXT--------\n",
      "Episode: 0\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.394527032661186\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005538540269530344\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006455951018451\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006260868777395195\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0060494504745105485\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005849756116107056\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005655704743143471\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005468286828010449\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005287038937916636\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005111806958418733\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004942381075981564\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004778571009429735\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004620190182362911\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004467058740481759\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004319002679238719\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004175853784317778\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004037449411929254\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003903632309929788\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00387660587695356\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 8\n",
      "Next Action: 0\n",
      "Reward: -10.24\n",
      "Done: False\n",
      "New Q-Value -8.1881232219016\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037269469284706633\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036078008410284157\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034873180248757287\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003371921867111237\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0032601242239796856\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0031520787836468085\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030476047203675115\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0030219566129532785\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007781917594560855\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007796511250197782\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00794067564021439\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005891406896384345\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007033593292875957\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007594215736602492\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007359739087860772\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007112244854094685\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006877253906684115\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006649161939898863\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006428813855659959\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006215730918281341\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006009718269025811\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005810532068115885\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005679412895057264\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006523812281862596\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006364815992790764\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0061420226108934994\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005940900382837212\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005743488813134981\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0056041844483355144\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005478460213866698\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005500934076994039\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005407877943361987\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0052844666522057935\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005276401941288809\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005210174052353918\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0050977702443488005\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005066958805820654\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005015012668046739\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0049163401961758715\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004870442741293457\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0048248013888796525\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00473942108270301\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004684804522618201\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004640937603807227\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004566920300630217\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004508335653730435\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0044640734834171325\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0043990469492404104\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004339719156961174\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004294362978143108\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004236090378106138\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004177995949138574\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004131659694780996\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004078301282989286\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004022494996966544\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003976984843547247\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00784277130505108\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 17\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02313756942754308\n",
      "--------NEXT--------\n",
      "Episode: 1\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8077093380875913\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00340439507975056\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036614875202852287\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003904007974465166\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 0\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037827063171913832\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038033100759889407\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.00675590316054827\n",
      "--------NEXT--------\n",
      "Episode: 2\n",
      "Action: 2\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 14\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3931921602242531\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0034636095313668857\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0036228131618086406\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005895148417214472\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007311686823948475\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6154276512075796\n",
      "--------NEXT--------\n",
      "Episode: 3\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.9681332042549037\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.003446059909247944\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0052048754294447275\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006735911669643735\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.46918735228255015\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8588667654752427\n",
      "--------NEXT--------\n",
      "Episode: 4\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0002179774883662\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004644917308227582\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006160267954818184\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.3579295700686669\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7465762122176944\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9319390159862068\n",
      "--------NEXT--------\n",
      "Episode: 5\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0066349321350587\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005610787107307336\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.2732585268431505\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6389838352991811\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.857588894593056\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.951430351619886\n",
      "--------NEXT--------\n",
      "Episode: 6\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.007918323064397\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.20879863782225583\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5402794201960077\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7795643269505588\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8946048461497246\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9563039958529189\n",
      "--------NEXT--------\n",
      "Episode: 7\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0081750012502648\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.452372086913417\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7005247725216261\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8358125484639024\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9057120060781633\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957473800120785\n",
      "--------NEXT--------\n",
      "Episode: 8\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082263368874385\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6228732444991193\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.775322491336891\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8555036343121846\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9088224893074293\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9577467760586102\n",
      "--------NEXT--------\n",
      "Episode: 9\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082366040148731\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.713819742315861\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8052472603446384\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8618058187360831\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9096520476660297\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578091742630256\n",
      "--------NEXT--------\n",
      "Episode: 10\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082386574403601\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7547518663250974\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8160218743083508\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8636967199733991\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9098653819731053\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578232145072788\n",
      "--------NEXT--------\n",
      "Episode: 11\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082390681254574\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.771126997739366\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8196138820414535\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8642370342942398\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099187194201529\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578263346768033\n",
      "--------NEXT--------\n",
      "Episode: 12\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391502624768\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7771319498993778\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8207429224719129\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8643856336181641\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099317582384011\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957827021134843\n",
      "--------NEXT--------\n",
      "Episode: 13\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391666898807\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7791910110585294\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8210816660441873\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644252629848176\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099348877101608\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578271709112779\n",
      "--------NEXT--------\n",
      "Episode: 14\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391699753614\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7798602684052882\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8211795330772989\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644355672566857\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099356274346033\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272033635302\n",
      "--------NEXT--------\n",
      "Episode: 15\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391706324576\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7800684988198048\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212069377305409\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644381903016356\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358000432036\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272103533738\n",
      "--------NEXT--------\n",
      "Episode: 16\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.008239170763877\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801309724391721\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212144121753512\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644388460931618\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358398772048\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272118512212\n",
      "--------NEXT--------\n",
      "Episode: 17\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707901608\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801491477411012\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212164054658732\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.864439007525308\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358489823691\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272121707664\n",
      "--------NEXT--------\n",
      "Episode: 18\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707954175\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801542977022838\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212169268124087\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.864439046731662\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358510462562\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122386705\n",
      "--------NEXT--------\n",
      "Episode: 19\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707964689\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801557239178873\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212170608785448\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390561414871\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358515106408\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122530503\n",
      "--------NEXT--------\n",
      "Episode: 20\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707966791\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801561110512716\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212170948432391\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390583763845\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516144465\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122560861\n",
      "--------NEXT--------\n",
      "Episode: 21\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967213\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.780156214291116\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171033347\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390589022561\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516375148\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122567254\n",
      "--------NEXT--------\n",
      "Episode: 22\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967298\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562413925951\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171054326546\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590249624\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516426143\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568597\n",
      "--------NEXT--------\n",
      "Episode: 23\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967313\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562484073365\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171059455023\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590533793\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516437362\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568877\n",
      "--------NEXT--------\n",
      "Episode: 24\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562502000491\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171060696687\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590599154\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516439819\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568937\n",
      "--------NEXT--------\n",
      "Episode: 25\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.780156250652958\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171060994694\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590614093\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440356\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568948\n",
      "--------NEXT--------\n",
      "Episode: 26\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562507661883\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061065648\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590617488\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440471\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.957827212256895\n",
      "--------NEXT--------\n",
      "Episode: 27\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562507942269\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.821217106108242\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618255\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440496\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 28\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508011092\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061086357\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618427\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440502\n",
      "--------NEXT--------\n",
      "Episode: 29\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3955216153555849\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.780156250802785\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087276\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618467\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 30\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508031898\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.821217106108749\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618476\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 31\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508032872\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.821217106108754\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006911488826103196\n",
      "--------NEXT--------\n",
      "Episode: 32\n",
      "Action: 1\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 14\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.39173774357560703\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033105\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087551\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 33\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.780156250803316\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087553\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 34\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033172\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 35\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033175\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 36\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 37\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 38\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 39\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 40\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 41\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 42\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 43\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 44\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 45\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 46\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0023134649722078107\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 1\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 16\n",
      "Next Action: 1\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02967998403397676\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 16\n",
      "Next Action: 0\n",
      "Reward: -0.08\n",
      "Done: False\n",
      "New Q-Value -0.06302680303291487\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7664573960723737\n",
      "--------NEXT--------\n",
      "Episode: 47\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 48\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 49\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 50\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 51\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 52\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 53\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 54\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 55\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 56\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 57\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 58\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 59\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 60\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 61\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 62\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 63\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 64\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 65\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 66\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 67\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 68\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 69\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 70\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 71\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 72\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 73\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 74\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 75\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 76\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 77\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 78\n",
      "Action: 3\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3958744532404639\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 79\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 80\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 81\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 82\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 83\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 84\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 85\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 86\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 87\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 88\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5934714335367652\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 89\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 90\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 91\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 92\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 93\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 94\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 95\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 96\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 97\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 98\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 99\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 100\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 101\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 102\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 103\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.005808960306315956\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007910011948938173\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006414769357090814\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 2\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 15\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.026139272198438118\n",
      "--------NEXT--------\n",
      "Episode: 104\n",
      "Action: 0\n",
      "Step Result: (14, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 14\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.39229474361566724\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 105\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 106\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 107\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 108\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 109\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 110\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 111\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 112\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 113\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 114\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 115\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 116\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 117\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 118\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 119\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 120\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 121\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 122\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 123\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 124\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 125\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 126\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 127\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 128\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 129\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 130\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7288627741343545\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 131\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 132\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 133\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 134\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 135\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 136\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 137\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 138\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 139\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 140\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 141\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 142\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 143\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 144\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 145\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 146\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 147\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 148\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 149\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 150\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 151\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 152\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 153\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 154\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 155\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 156\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 157\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 158\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 159\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 160\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 161\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 162\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 163\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0046744461894104436\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 3\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 1\n",
      "Next Action: 3\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02630233354414407\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5937885059757699\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 164\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 165\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 166\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 167\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 168\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 169\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 170\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 171\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 172\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 173\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 174\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 175\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 176\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 177\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.4522141537794672\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7116764518056753\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 178\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 179\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 180\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 181\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 182\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 183\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 184\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 185\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 186\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 187\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 188\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 189\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 190\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 191\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 192\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6923775791884345\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 193\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 194\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 195\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 196\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 197\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 198\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 199\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 200\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 201\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 202\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 203\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 204\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 205\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 206\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 207\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 208\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 209\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 210\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 211\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 212\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 213\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 214\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 215\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 216\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 217\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 3\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8737212361421112\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 218\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 219\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 220\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 221\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 222\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 223\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 224\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 225\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 226\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 227\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 228\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 229\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 230\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 231\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 232\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 233\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 234\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 235\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 236\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 237\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 238\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 239\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 240\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 241\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 242\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 243\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 244\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 245\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 246\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 247\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 248\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 249\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 250\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7116130373178744\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 251\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 252\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 253\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 254\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 255\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 256\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 257\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 258\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 259\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 260\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7352413580740962\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 261\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 262\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 263\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 264\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 265\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 266\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 267\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 268\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 269\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 270\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 271\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 272\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 273\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 274\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 275\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 276\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 277\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 278\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 279\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 280\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 281\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 282\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 3\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6247345215867276\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 283\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 284\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 285\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 286\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 287\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 288\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 289\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 290\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 291\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 292\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 293\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 294\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 295\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 296\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 297\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 298\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4744649933299435\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 299\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 300\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 301\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 302\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 303\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 304\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 305\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 306\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 307\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 308\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 309\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 310\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 311\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 312\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 313\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.3960023230135236\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 314\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 315\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 316\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 317\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 318\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 319\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 320\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 321\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 322\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 323\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 324\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 325\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 326\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 327\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 328\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 329\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 330\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 331\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 332\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 333\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 334\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 335\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 336\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 337\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 338\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 339\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 340\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 341\n",
      "Action: 0\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 12\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4746639098688233\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 342\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 343\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 344\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 345\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 346\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 347\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 348\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 349\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 350\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 351\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 352\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 353\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 354\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 355\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 356\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 357\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 358\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 359\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 360\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 361\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 362\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 363\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 364\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 365\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 366\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 367\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 368\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 369\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 370\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 371\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 372\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 373\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 374\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 375\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 376\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 377\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 378\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 379\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 380\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 381\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 382\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 383\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 384\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 385\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 386\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 387\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 388\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 389\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 390\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 391\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 392\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 393\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 0\n",
      "Step Result: (16, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 16\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.5829703140094455\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 2\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 16\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9195532490199909\n",
      "--------NEXT--------\n",
      "Episode: 394\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 395\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 396\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 397\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 398\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 399\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 400\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 401\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 402\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 403\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 404\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 405\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 406\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 407\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 408\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 409\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 410\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 411\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 412\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 413\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 414\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 415\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 416\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 417\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 418\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 419\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 420\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 421\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 422\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 423\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7399670222253406\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 424\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 425\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 426\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 427\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 428\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 429\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 430\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 431\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 432\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 433\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 434\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 435\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 436\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 437\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 438\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 439\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 440\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 441\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 442\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 443\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 444\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 445\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 446\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 447\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 448\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 449\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 450\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 451\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 452\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 453\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 454\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 455\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 456\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 457\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 458\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 459\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 460\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 461\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 462\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 463\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 464\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 465\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 466\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 467\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 468\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 469\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 470\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 471\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 472\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 473\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 474\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 475\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 476\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 477\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 478\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 479\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 480\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 481\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 482\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 483\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 484\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8300267630871652\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 485\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 486\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 487\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 488\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 489\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 490\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 491\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 492\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 493\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 494\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 495\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 496\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 497\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 498\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 499\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 500\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 501\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 502\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 503\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 504\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 505\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 506\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 507\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 508\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 509\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 510\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 511\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 512\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 513\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 514\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 515\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 516\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 517\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 518\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 519\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 520\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 521\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 522\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 523\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 524\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 525\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 526\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 527\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 528\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 529\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 530\n",
      "Action: 1\n",
      "Step Result: (12, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 12\n",
      "Next Action: 2\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.49045258546369497\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 531\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 532\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 533\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 534\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 535\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 536\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 537\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 538\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 539\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 540\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 541\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 542\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 543\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 544\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 545\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 546\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 547\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 548\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 549\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 550\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 551\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 552\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 553\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 554\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 555\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 556\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 557\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 558\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 559\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 560\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 561\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 562\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 563\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 564\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 565\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 566\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (10, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 10\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0071734011424562025\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 10\n",
      "New State: 11\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.006472785612707105\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 11\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.025822168560522774\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004878946291379058\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004654312976174636\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004513067120168535\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004360793606563013\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004216816565021596\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.004076939310729015\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 3\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0039418371891583705\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 3\n",
      "Step Result: (11, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 11\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0038111841259061644\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (15, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 11\n",
      "New State: 15\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.0037552635338075433\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 1\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 15\n",
      "New State: 19\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.007499778364378509\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 2\n",
      "Step Result: (19, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 19\n",
      "Next Action: 2\n",
      "Reward: -0.04\n",
      "Done: False\n",
      "New Q-Value -0.02351282159933658\n",
      "--------NEXT--------\n",
      "Episode: 567\n",
      "Action: 0\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 19\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 0.8071020560380807\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 568\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 569\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 570\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 571\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 572\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 573\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 574\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 575\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 576\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 577\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 578\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.5754390800501704\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 579\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 580\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 581\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 582\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 583\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 584\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 585\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 586\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 587\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 588\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 589\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 590\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 591\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 592\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 593\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 594\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 595\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 596\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 597\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 598\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 599\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 600\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 601\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 602\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 603\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 604\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 605\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 606\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 607\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 608\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 609\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 610\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 611\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 612\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 613\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 614\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 615\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 616\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 617\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 618\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 619\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 620\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 621\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 622\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 623\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 624\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 625\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 626\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 627\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 628\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 629\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 630\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 631\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 632\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 633\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 634\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 635\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 636\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 637\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 638\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 639\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 640\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 641\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 642\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 643\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 644\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 645\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 646\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 647\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 648\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 649\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 650\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 651\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 652\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 653\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 654\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 655\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 656\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 657\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 658\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 659\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 660\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 661\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 662\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 663\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 664\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 665\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 666\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 667\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 668\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 669\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 670\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 671\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 672\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 673\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 674\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 675\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 676\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 677\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 678\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 679\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 680\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 681\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 682\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 683\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 684\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 685\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 686\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 687\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 688\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 689\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 690\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 691\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 692\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 693\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 694\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 695\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 696\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 697\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 698\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 699\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 700\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 701\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 702\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 703\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 704\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 705\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 706\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 707\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 708\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 709\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 710\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 711\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 712\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 713\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 714\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 715\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 716\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 717\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 718\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 719\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 720\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 721\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 722\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 723\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 724\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 725\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 726\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 727\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 728\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 729\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 730\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 731\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 732\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 733\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 734\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 735\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 736\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 737\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 738\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 739\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 740\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 741\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 742\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 743\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 744\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 745\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 746\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 747\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 748\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 749\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 750\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 751\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 752\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 753\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 754\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 755\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 756\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 757\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 758\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 759\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 760\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 761\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 762\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 763\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 764\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 765\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 766\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 767\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 768\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 769\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 770\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 771\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 772\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 773\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 774\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 775\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 776\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 777\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 778\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 779\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 780\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 781\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 782\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 783\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 784\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 785\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 786\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 787\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 788\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 789\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 790\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 791\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 792\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.47529231205085976\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 793\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 794\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 795\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 796\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 797\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 798\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 799\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 800\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 801\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 802\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 803\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 804\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 805\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 806\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 807\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 808\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 809\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 810\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 811\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 812\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 813\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6313169341282067\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7352540409716564\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 814\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 815\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 816\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 817\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 818\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 819\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 820\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 821\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 822\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 823\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 824\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 825\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 826\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 827\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 828\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 829\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 830\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 831\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 832\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 833\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 834\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 835\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 836\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 837\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 838\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 839\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 840\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 841\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 842\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 843\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 844\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 845\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 846\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.49115030985832697\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 847\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 848\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 849\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 850\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 851\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 852\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 853\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 854\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 855\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 856\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 857\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 858\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 859\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 860\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 861\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 862\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 863\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 864\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 865\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 866\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 867\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 868\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 869\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 870\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 871\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 872\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 873\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 874\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 875\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 876\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 877\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 878\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 879\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 880\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 881\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (1, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 1\n",
      "Next Action: 0\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.6850564579641001\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 0\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 1\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7399695588048526\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 882\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 883\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 884\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 885\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 886\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 887\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 888\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 889\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 890\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 891\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 892\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 893\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 894\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 895\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 896\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 897\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 898\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 899\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 900\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 901\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 902\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 903\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 904\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 905\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 906\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 907\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 908\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 909\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 910\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 911\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 912\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 913\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 914\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 915\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 916\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 917\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 918\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 919\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 920\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 921\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 922\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 923\n",
      "Action: 2\n",
      "Step Result: (5, 0.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 5\n",
      "Next Action: 0\n",
      "Reward: -0.5\n",
      "Done: True\n",
      "New Q-Value -0.4943219094198204\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 924\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 925\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 3\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8575565998669112\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 926\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 927\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 928\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 929\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 930\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 931\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 932\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 933\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 934\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 935\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 936\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 937\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 938\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 939\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 940\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 941\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 942\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 943\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 944\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 945\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 946\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 947\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 948\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 949\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 950\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 951\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 952\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 953\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 954\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 955\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 956\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 957\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 958\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 959\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 960\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 961\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 962\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 963\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 964\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 965\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 966\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 967\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 968\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 969\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 970\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 971\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 972\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 973\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 974\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 975\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 976\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.6920065666205555\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 977\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 978\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 979\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 980\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 981\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 982\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 983\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 984\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 985\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 986\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 987\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 988\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 989\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 990\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 991\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 992\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 3\n",
      "Step Result: (0, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 0\n",
      "Next Action: 1\n",
      "Reward: -0.02\n",
      "Done: False\n",
      "New Q-Value 0.7153200639346324\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 993\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 994\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 995\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 996\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 997\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 998\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (4, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 0\n",
      "New State: 4\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.7801562508033176\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (8, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 4\n",
      "New State: 8\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8212171061087554\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 2\n",
      "Step Result: (9, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 8\n",
      "New State: 9\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.8644390590618478\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (13, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 9\n",
      "New State: 13\n",
      "Next Action: 1\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9099358516440503\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 1\n",
      "Step Result: (17, 0.0, False, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 13\n",
      "New State: 17\n",
      "Next Action: 2\n",
      "Reward: 0.0\n",
      "Done: False\n",
      "New Q-Value 0.9578272122568952\n",
      "--------NEXT--------\n",
      "Episode: 999\n",
      "Action: 2\n",
      "Step Result: (18, 1.0, True, False, {'prob': 1.0})\n",
      "State Tuple: (0, {'prob': 1})\n",
      "State: 17\n",
      "New State: 18\n",
      "Next Action: 1\n",
      "Reward: 1.0\n",
      "Done: True\n",
      "New Q-Value 1.0082391707967318\n",
      "--------NEXT--------\n"
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state_tuple = env.reset()  # State is a tuple\n",
    "    state = state_tuple[0]  # Extract the integer state value\n",
    "    done = False\n",
    "\n",
    "    # Reset state visits count for the new episode\n",
    "    state_visits = {s: 0 for s in range(env.observation_space.n)}\n",
    "\n",
    "    while not done:\n",
    "        # Choose action using epsilon-greedy policy\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.choice(custom_policy(state))  # Custom policy\n",
    "        else:\n",
    "            action = np.argmax(Q[state, :])\n",
    "\n",
    "        print(\"Episode:\", episode)\n",
    "        print(\"Action:\", action)\n",
    "\n",
    "        # Take action and observe the next state, reward, done flag, and info\n",
    "        step_result = env.step(action)\n",
    "\n",
    "        next_state = step_result[0]  # Extract the next state tuple\n",
    "        reward = step_result[1]  # Extract the reward\n",
    "        terminated = step_result[2]  # Extract the done flags\n",
    "        truncated = step_result[3] # Extract the done flags\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            if reward == 0:\n",
    "                reward = custom_rewards[\"F\"]\n",
    "            else:\n",
    "                reward = custom_rewards[\"G\"]\n",
    "        else:\n",
    "            reward = custom_rewards[\"S\"]\n",
    "\n",
    "        # Update state visits count\n",
    "        state_visits[next_state] += 1\n",
    "\n",
    "        # Calculate penalty for visiting the same state\n",
    "        visit_penalty = -0.01 * (2 ** state_visits[next_state])\n",
    "\n",
    "        if next_state == state:\n",
    "            reward = visit_penalty\n",
    "\n",
    "        # Update Q-value using SARSA formula\n",
    "        next_action = np.argmax(Q[next_state, :])\n",
    "        Q[state, action] = Q[state, action] + learning_rate * (reward + discount_factor * Q[next_state, next_action] - Q[state, action])\n",
    "\n",
    "        # Decay the exploration rate\n",
    "        epsilon = max(min_exploration_rate, epsilon * exploration_decay_rate)\n",
    "\n",
    "        print(\"Step Result:\", step_result)\n",
    "        print(\"State Tuple:\", state_tuple)\n",
    "        print(\"State:\", state)\n",
    "        print(\"New State:\", next_state)\n",
    "        print(\"Next Action:\", next_action)\n",
    "        print(\"Reward:\", reward)\n",
    "        print(\"Done:\", done)\n",
    "        print(\"New Q-Value\", Q[state, action])\n",
    "        print(\"--------NEXT--------\")\n",
    "\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
