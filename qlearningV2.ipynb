{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import gymnasium as gym\n",
    "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the environment with a custom map\n",
    "desc = [\"SFFF\", \"FHHH\", \"FFFF\", \"HFHF\", \"FFGF\"]\n",
    "#env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x5\", is_slippery=False, render_mode='human') #render mode human set map\n",
    "#env = gym.make('FrozenLake-v1', desc=desc, map_name=\"5x5\", is_slippery=False) #render mode none human for fast training\n",
    "env = gym.make('FrozenLake-v1', desc = generate_random_map(size=5), is_slippery = False, render_mode = 'human') #render mode human non set map \n",
    "#env = gym.make('FrozenLake-v1', desc = generate_random_map(size=5), is_slippery = False) #render mode non human random map for training\n",
    "\n",
    "# Initialize the Q-table\n",
    "observationSpace = env.observation_space.n\n",
    "actionSpace = env.action_space.n\n",
    "q_table = np.random.rand(observationSpace, actionSpace) * 0.1\n",
    "\n",
    "\n",
    "# Learning parameters\n",
    "learning_rate = 0.8       # Alpha - how much we update our Q-value with the new information we gain\n",
    "discount_factor = 0.95    # Gamma - how much importance we give to future rewards\n",
    "exploration_rate = 1.0    # Epsilon - probability of choosing a random action\n",
    "max_exploration_rate = 1.0\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.001\n",
    "max_episodes = 100\n",
    "\n",
    "# Initialize a variable to count successful goal reaches\n",
    "goal_reaches = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, q_table, exploration_rate):\n",
    "    if np.random.uniform(0, 1) < exploration_rate:\n",
    "        action = env.action_space.sample()  # Explore: select a random action\n",
    "    else:\n",
    "        action = np.argmax(q_table[state, :])  # Exploit: select the action with the highest Q-value\n",
    "    return action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q_table(state, action, reward, new_state, q_table, learning_rate, discount_factor):\n",
    "    # Q-Learning formula\n",
    "    best_future_q = np.max(q_table[new_state, :])\n",
    "    current_q = q_table[state, action]\n",
    "    new_q = (1 - learning_rate) * current_q + learning_rate * (reward + discount_factor * best_future_q)\n",
    "    q_table[state, action] = new_q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 0, State: 0, Action: 3, Reward: 0.08, New State: 0, Visits: 1\n",
      "Episode: 0, State: 5, Action: 1, Reward: 0.060000000000000005, New State: 5, Visits: 2\n",
      "Episode: 0, State: 0, Action: 3, Reward: 0.060000000000000005, New State: 0, Visits: 2\n",
      "Episode: 0, State: 5, Action: 1, Reward: 0.020000000000000004, New State: 5, Visits: 3\n",
      "Episode: 0, State: 0, Action: 3, Reward: 0.020000000000000004, New State: 0, Visits: 3\n",
      "Episode: 0, State: 5, Action: 1, Reward: -0.06, New State: 5, Visits: 4\n",
      "Episode: 0, State: 0, Action: 3, Reward: -0.06, New State: 0, Visits: 4\n",
      "Episode: 0, State: 5, Action: 1, Reward: -0.22, New State: 5, Visits: 5\n",
      "Episode: 0, State: 0, Action: 3, Reward: -0.22, New State: 0, Visits: 5\n",
      "Episode: 0, State: 1, Action: 2, Reward: 0.08, New State: 1, Visits: 1\n",
      "Episode: 0, State: 2, Action: 2, Reward: 0.08, New State: 2, Visits: 1\n",
      "Episode: 0, State: 3, Action: 2, Reward: 0.08, New State: 3, Visits: 1\n",
      "Episode: 0, State: 4, Action: 2, Reward: 0.08, New State: 4, Visits: 1\n",
      "Episode: 0, State: 3, Action: 0, Reward: 0.060000000000000005, New State: 3, Visits: 2\n",
      "Episode: 0, State: 4, Action: 2, Reward: 0.060000000000000005, New State: 4, Visits: 2\n",
      "Episode: 0, State: 3, Action: 0, Reward: 0.020000000000000004, New State: 3, Visits: 3\n",
      "Episode: 0, State: 4, Action: 2, Reward: 0.020000000000000004, New State: 4, Visits: 3\n",
      "Episode: 0, State: 3, Action: 0, Reward: -0.06, New State: 3, Visits: 4\n",
      "Episode: 0, State: 4, Action: 2, Reward: -0.06, New State: 4, Visits: 4\n",
      "Episode: 0, State: 3, Action: 0, Reward: -0.22, New State: 3, Visits: 5\n",
      "Episode: 0, State: 4, Action: 2, Reward: -0.22, New State: 4, Visits: 5\n",
      "Episode: 0, State: 4, Action: 3, Reward: -0.64, New State: 4, Visits: 6\n",
      "Episode: 0, State: 9, Action: 1, Reward: 0.08, New State: 9, Visits: 1\n",
      "Episode: 0, State: 14, Action: 1, Reward: 0.08, New State: 14, Visits: 1\n",
      "Episode: 0, State: 13, Action: 0, Reward: 0.08, New State: 13, Visits: 1\n",
      "Episode: 0, State: 14, Action: 2, Reward: 0.060000000000000005, New State: 14, Visits: 2\n",
      "Episode: 0, State: 13, Action: 0, Reward: 0.060000000000000005, New State: 13, Visits: 2\n",
      "Episode: 0, State: 14, Action: 2, Reward: 0.020000000000000004, New State: 14, Visits: 3\n",
      "Episode: 0, State: 13, Action: 0, Reward: 0.020000000000000004, New State: 13, Visits: 3\n",
      "Episode: 0, State: 18, Action: 1, Reward: 0.08, New State: 18, Visits: 1\n",
      "Episode: 0, State: 23, Action: 1, Reward: 0.08, New State: 23, Visits: 1\n",
      "Episode: 0, State: 22, Action: 0, Reward: 0.08, New State: 22, Visits: 1\n",
      "Episode: 0, State: 23, Action: 2, Reward: 0.060000000000000005, New State: 23, Visits: 2\n",
      "Episode: 0, State: 22, Action: 0, Reward: 0.060000000000000005, New State: 22, Visits: 2\n",
      "Episode: 0, State: 23, Action: 2, Reward: 0.020000000000000004, New State: 23, Visits: 3\n",
      "Episode: 0, State: 22, Action: 0, Reward: 0.020000000000000004, New State: 22, Visits: 3\n",
      "Episode: 0, State: 23, Action: 2, Reward: -0.06, New State: 23, Visits: 4\n",
      "Episode: 0, State: 22, Action: 0, Reward: -0.06, New State: 22, Visits: 4\n",
      "Episode: 0, State: 23, Action: 2, Reward: -0.22, New State: 23, Visits: 5\n",
      "Episode: 0, State: 22, Action: 0, Reward: -0.22, New State: 22, Visits: 5\n",
      "Episode: 0, State: 21, Action: 0, Reward: 0.08, New State: 21, Visits: 1\n",
      "Episode: 0, State: 21, Action: 1, Reward: -0.04, New State: 21, Visits: 2\n",
      "Episode: 0, State: 22, Action: 2, Reward: -0.54, New State: 22, Visits: 6\n",
      "Episode: 0, State: 21, Action: 0, Reward: 0.020000000000000004, New State: 21, Visits: 3\n",
      "Episode: 0, State: 21, Action: 1, Reward: -0.16, New State: 21, Visits: 4\n",
      "Episode: 0, State: 20, Action: 0, Reward: 0.08, New State: 20, Visits: 1\n",
      "Episode: 0, State: 21, Action: 2, Reward: -0.22, New State: 21, Visits: 5\n",
      "Episode: 0, State: 20, Action: 0, Reward: 0.060000000000000005, New State: 20, Visits: 2\n",
      "Episode: 0, State: 20, Action: 1, Reward: -0.08, New State: 20, Visits: 3\n",
      "Episode: 0, State: 20, Action: 0, Reward: -0.16, New State: 20, Visits: 4\n",
      "Episode: 0, State: 15, Action: 3, Reward: 0.08, New State: 15, Visits: 1\n",
      "Episode: 0, State: 16, Action: 2, Reward: 0.08, New State: 16, Visits: 1\n",
      "Episode: 0, State: 15, Action: 0, Reward: 0.060000000000000005, New State: 15, Visits: 2\n",
      "Episode: 0, State: 16, Action: 2, Reward: 0.060000000000000005, New State: 16, Visits: 2\n",
      "Episode: 0, State: 15, Action: 0, Reward: 0.020000000000000004, New State: 15, Visits: 3\n",
      "Episode: 0, State: 16, Action: 2, Reward: 0.020000000000000004, New State: 16, Visits: 3\n",
      "Episode: 0, State: 15, Action: 0, Reward: -0.06, New State: 15, Visits: 4\n",
      "Episode: 0, State: 16, Action: 2, Reward: -0.06, New State: 16, Visits: 4\n",
      "Episode: 0, State: 15, Action: 0, Reward: -0.22, New State: 15, Visits: 5\n",
      "Episode: 0, State: 16, Action: 2, Reward: -0.22, New State: 16, Visits: 5\n",
      "Episode: 0, State: 21, Action: 1, Reward: -0.54, New State: 21, Visits: 6\n",
      "Episode: 0, State: 20, Action: 0, Reward: -0.22, New State: 20, Visits: 5\n",
      "Episode: 0, State: 15, Action: 3, Reward: -0.54, New State: 15, Visits: 6\n",
      "Episode: 0, State: 10, Action: 3, Reward: 0.08, New State: 10, Visits: 1\n",
      "Episode: 0, State: 15, Action: 1, Reward: -1.18, New State: 15, Visits: 7\n",
      "Episode: 0, State: 10, Action: 3, Reward: 0.060000000000000005, New State: 10, Visits: 2\n",
      "Episode: 0, State: 10, Action: 0, Reward: -0.08, New State: 10, Visits: 3\n",
      "Episode: 0, State: 11, Action: 2, Reward: 0.08, New State: 11, Visits: 1\n",
      "Episode: 0, State: 16, Action: 1, Reward: -0.54, New State: 16, Visits: 6\n",
      "Episode: 0, State: 11, Action: 3, Reward: 0.060000000000000005, New State: 11, Visits: 2\n",
      "Episode: 0, State: 10, Action: 0, Reward: -0.06, New State: 10, Visits: 4\n",
      "Episode: 0, State: 11, Action: 2, Reward: 0.020000000000000004, New State: 11, Visits: 3\n",
      "Episode: 0, State: 6, Action: 3, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 1, State: 1, Action: 2, Reward: 0.08, New State: 1, Visits: 1\n",
      "Episode: 1, State: 2, Action: 2, Reward: 0.08, New State: 2, Visits: 1\n",
      "Episode: 1, State: 3, Action: 2, Reward: 0.08, New State: 3, Visits: 1\n",
      "Episode: 1, State: 2, Action: 0, Reward: 0.060000000000000005, New State: 2, Visits: 2\n",
      "Episode: 1, State: 3, Action: 2, Reward: 0.060000000000000005, New State: 3, Visits: 2\n",
      "Episode: 1, State: 2, Action: 0, Reward: 0.020000000000000004, New State: 2, Visits: 3\n",
      "Episode: 1, State: 3, Action: 2, Reward: 0.020000000000000004, New State: 3, Visits: 3\n",
      "Episode: 1, State: 2, Action: 0, Reward: -0.06, New State: 2, Visits: 4\n",
      "Episode: 1, State: 3, Action: 2, Reward: -0.06, New State: 3, Visits: 4\n",
      "Episode: 1, State: 2, Action: 0, Reward: -0.22, New State: 2, Visits: 5\n",
      "Episode: 1, State: 3, Action: 2, Reward: -0.22, New State: 3, Visits: 5\n",
      "Episode: 1, State: 8, Action: 1, Reward: -0.52, New State: 8, Visits: 1\n",
      "Episode: 2, State: 1, Action: 2, Reward: 0.08, New State: 1, Visits: 1\n",
      "Episode: 2, State: 2, Action: 2, Reward: 0.08, New State: 2, Visits: 1\n",
      "Episode: 2, State: 7, Action: 1, Reward: 0.08, New State: 7, Visits: 1\n",
      "Episode: 2, State: 6, Action: 0, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 3, State: 1, Action: 2, Reward: 0.08, New State: 1, Visits: 1\n",
      "Episode: 3, State: 2, Action: 2, Reward: 0.08, New State: 2, Visits: 1\n",
      "Episode: 3, State: 7, Action: 1, Reward: 0.08, New State: 7, Visits: 1\n",
      "Episode: 3, State: 12, Action: 1, Reward: -0.52, New State: 12, Visits: 1\n",
      "Episode: 4, State: 1, Action: 2, Reward: 0.08, New State: 1, Visits: 1\n",
      "Episode: 4, State: 2, Action: 2, Reward: 0.08, New State: 2, Visits: 1\n",
      "Episode: 4, State: 7, Action: 1, Reward: 0.08, New State: 7, Visits: 1\n",
      "Episode: 4, State: 8, Action: 2, Reward: -0.52, New State: 8, Visits: 1\n",
      "Episode: 5, State: 1, Action: 2, Reward: 0.08, New State: 1, Visits: 1\n",
      "Episode: 5, State: 2, Action: 2, Reward: 0.08, New State: 2, Visits: 1\n",
      "Episode: 5, State: 7, Action: 1, Reward: 0.08, New State: 7, Visits: 1\n",
      "Episode: 5, State: 2, Action: 3, Reward: 0.060000000000000005, New State: 2, Visits: 2\n",
      "Episode: 5, State: 7, Action: 1, Reward: 0.060000000000000005, New State: 7, Visits: 2\n",
      "Episode: 5, State: 2, Action: 3, Reward: 0.020000000000000004, New State: 2, Visits: 3\n",
      "Episode: 5, State: 7, Action: 1, Reward: 0.020000000000000004, New State: 7, Visits: 3\n",
      "Episode: 5, State: 2, Action: 3, Reward: -0.06, New State: 2, Visits: 4\n",
      "Episode: 5, State: 7, Action: 1, Reward: -0.06, New State: 7, Visits: 4\n",
      "Episode: 5, State: 2, Action: 3, Reward: -0.22, New State: 2, Visits: 5\n",
      "Episode: 5, State: 7, Action: 1, Reward: -0.22, New State: 7, Visits: 5\n",
      "Episode: 5, State: 2, Action: 3, Reward: -0.54, New State: 2, Visits: 6\n",
      "Episode: 5, State: 2, Action: 3, Reward: -1.28, New State: 2, Visits: 7\n",
      "Episode: 5, State: 1, Action: 0, Reward: 0.060000000000000005, New State: 1, Visits: 2\n",
      "Episode: 5, State: 2, Action: 2, Reward: -2.46, New State: 2, Visits: 8\n",
      "Episode: 5, State: 1, Action: 0, Reward: 0.020000000000000004, New State: 1, Visits: 3\n",
      "Episode: 5, State: 0, Action: 0, Reward: 0.08, New State: 0, Visits: 1\n",
      "Episode: 5, State: 1, Action: 2, Reward: -0.06, New State: 1, Visits: 4\n",
      "Episode: 5, State: 0, Action: 0, Reward: 0.060000000000000005, New State: 0, Visits: 2\n",
      "Episode: 5, State: 1, Action: 2, Reward: -0.22, New State: 1, Visits: 5\n",
      "Episode: 5, State: 0, Action: 0, Reward: 0.020000000000000004, New State: 0, Visits: 3\n",
      "Episode: 5, State: 1, Action: 2, Reward: -0.54, New State: 1, Visits: 6\n",
      "Episode: 5, State: 0, Action: 0, Reward: -0.06, New State: 0, Visits: 4\n",
      "Episode: 5, State: 0, Action: 0, Reward: -0.32, New State: 0, Visits: 5\n",
      "Episode: 5, State: 0, Action: 3, Reward: -0.64, New State: 0, Visits: 6\n",
      "Episode: 5, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 5, State: 5, Action: 0, Reward: -0.04, New State: 5, Visits: 2\n",
      "Episode: 5, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 6, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 6, State: 5, Action: 0, Reward: -0.04, New State: 5, Visits: 2\n",
      "Episode: 6, State: 5, Action: 0, Reward: -0.08, New State: 5, Visits: 3\n",
      "Episode: 6, State: 10, Action: 1, Reward: 0.08, New State: 10, Visits: 1\n",
      "Episode: 6, State: 11, Action: 2, Reward: 0.08, New State: 11, Visits: 1\n",
      "Episode: 6, State: 10, Action: 0, Reward: 0.060000000000000005, New State: 10, Visits: 2\n",
      "Episode: 6, State: 11, Action: 2, Reward: 0.060000000000000005, New State: 11, Visits: 2\n",
      "Episode: 6, State: 10, Action: 0, Reward: 0.020000000000000004, New State: 10, Visits: 3\n",
      "Episode: 6, State: 11, Action: 2, Reward: 0.020000000000000004, New State: 11, Visits: 3\n",
      "Episode: 6, State: 10, Action: 0, Reward: -0.06, New State: 10, Visits: 4\n",
      "Episode: 6, State: 11, Action: 2, Reward: -0.06, New State: 11, Visits: 4\n",
      "Episode: 6, State: 10, Action: 0, Reward: -0.22, New State: 10, Visits: 5\n",
      "Episode: 6, State: 11, Action: 2, Reward: -0.22, New State: 11, Visits: 5\n",
      "Episode: 6, State: 12, Action: 2, Reward: -0.52, New State: 12, Visits: 1\n",
      "Episode: 7, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 7, State: 10, Action: 1, Reward: 0.08, New State: 10, Visits: 1\n",
      "Episode: 7, State: 5, Action: 3, Reward: 0.060000000000000005, New State: 5, Visits: 2\n",
      "Episode: 7, State: 10, Action: 1, Reward: 0.060000000000000005, New State: 10, Visits: 2\n",
      "Episode: 7, State: 5, Action: 3, Reward: 0.020000000000000004, New State: 5, Visits: 3\n",
      "Episode: 7, State: 10, Action: 1, Reward: 0.020000000000000004, New State: 10, Visits: 3\n",
      "Episode: 7, State: 5, Action: 3, Reward: -0.06, New State: 5, Visits: 4\n",
      "Episode: 7, State: 10, Action: 1, Reward: -0.06, New State: 10, Visits: 4\n",
      "Episode: 7, State: 5, Action: 3, Reward: -0.22, New State: 5, Visits: 5\n",
      "Episode: 7, State: 10, Action: 1, Reward: -0.22, New State: 10, Visits: 5\n",
      "Episode: 7, State: 10, Action: 0, Reward: -0.64, New State: 10, Visits: 6\n",
      "Episode: 7, State: 5, Action: 3, Reward: -0.54, New State: 5, Visits: 6\n",
      "Episode: 7, State: 5, Action: 0, Reward: -1.28, New State: 5, Visits: 7\n",
      "Episode: 7, State: 0, Action: 3, Reward: 0.08, New State: 0, Visits: 1\n",
      "Episode: 7, State: 5, Action: 1, Reward: -2.46, New State: 5, Visits: 8\n",
      "Episode: 7, State: 0, Action: 3, Reward: 0.060000000000000005, New State: 0, Visits: 2\n",
      "Episode: 7, State: 0, Action: 0, Reward: -0.08, New State: 0, Visits: 3\n",
      "Episode: 7, State: 0, Action: 0, Reward: -0.16, New State: 0, Visits: 4\n",
      "Episode: 7, State: 1, Action: 2, Reward: 0.08, New State: 1, Visits: 1\n",
      "Episode: 7, State: 1, Action: 3, Reward: -0.04, New State: 1, Visits: 2\n",
      "Episode: 7, State: 1, Action: 3, Reward: -0.08, New State: 1, Visits: 3\n",
      "Episode: 7, State: 6, Action: 1, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 8, State: 1, Action: 2, Reward: 0.08, New State: 1, Visits: 1\n",
      "Episode: 8, State: 0, Action: 0, Reward: 0.08, New State: 0, Visits: 1\n",
      "Episode: 8, State: 1, Action: 2, Reward: 0.060000000000000005, New State: 1, Visits: 2\n",
      "Episode: 8, State: 0, Action: 0, Reward: 0.060000000000000005, New State: 0, Visits: 2\n",
      "Episode: 8, State: 1, Action: 2, Reward: 0.020000000000000004, New State: 1, Visits: 3\n",
      "Episode: 8, State: 0, Action: 0, Reward: 0.020000000000000004, New State: 0, Visits: 3\n",
      "Episode: 8, State: 1, Action: 2, Reward: -0.06, New State: 1, Visits: 4\n",
      "Episode: 8, State: 0, Action: 0, Reward: -0.06, New State: 0, Visits: 4\n",
      "Episode: 8, State: 1, Action: 2, Reward: -0.22, New State: 1, Visits: 5\n",
      "Episode: 8, State: 0, Action: 0, Reward: -0.22, New State: 0, Visits: 5\n",
      "Episode: 8, State: 1, Action: 2, Reward: -0.54, New State: 1, Visits: 6\n",
      "Episode: 8, State: 1, Action: 3, Reward: -1.28, New State: 1, Visits: 7\n",
      "Episode: 8, State: 0, Action: 0, Reward: -0.54, New State: 0, Visits: 6\n",
      "Episode: 8, State: 0, Action: 0, Reward: -1.28, New State: 0, Visits: 7\n",
      "Episode: 8, State: 1, Action: 2, Reward: -2.46, New State: 1, Visits: 8\n",
      "Episode: 8, State: 6, Action: 1, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 9, State: 0, Action: 3, Reward: -0.02, New State: 0, Visits: 1\n",
      "Episode: 9, State: 0, Action: 3, Reward: -0.04, New State: 0, Visits: 2\n",
      "Episode: 9, State: 0, Action: 3, Reward: -0.08, New State: 0, Visits: 3\n",
      "Episode: 9, State: 0, Action: 3, Reward: -0.16, New State: 0, Visits: 4\n",
      "Episode: 9, State: 0, Action: 3, Reward: -0.32, New State: 0, Visits: 5\n",
      "Episode: 9, State: 0, Action: 3, Reward: -0.64, New State: 0, Visits: 6\n",
      "Episode: 9, State: 0, Action: 3, Reward: -1.28, New State: 0, Visits: 7\n",
      "Episode: 9, State: 0, Action: 0, Reward: -2.56, New State: 0, Visits: 8\n",
      "Episode: 9, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 9, State: 0, Action: 3, Reward: -5.0200000000000005, New State: 0, Visits: 9\n",
      "Episode: 9, State: 5, Action: 1, Reward: 0.060000000000000005, New State: 5, Visits: 2\n",
      "Episode: 9, State: 10, Action: 1, Reward: 0.08, New State: 10, Visits: 1\n",
      "Episode: 9, State: 11, Action: 2, Reward: 0.08, New State: 11, Visits: 1\n",
      "Episode: 9, State: 10, Action: 0, Reward: 0.060000000000000005, New State: 10, Visits: 2\n",
      "Episode: 9, State: 11, Action: 2, Reward: 0.060000000000000005, New State: 11, Visits: 2\n",
      "Episode: 9, State: 10, Action: 0, Reward: 0.020000000000000004, New State: 10, Visits: 3\n",
      "Episode: 9, State: 11, Action: 2, Reward: 0.020000000000000004, New State: 11, Visits: 3\n",
      "Episode: 9, State: 10, Action: 0, Reward: -0.06, New State: 10, Visits: 4\n",
      "Episode: 9, State: 11, Action: 2, Reward: -0.06, New State: 11, Visits: 4\n",
      "Episode: 9, State: 10, Action: 0, Reward: -0.22, New State: 10, Visits: 5\n",
      "Episode: 9, State: 11, Action: 2, Reward: -0.22, New State: 11, Visits: 5\n",
      "Episode: 9, State: 10, Action: 0, Reward: -0.54, New State: 10, Visits: 6\n",
      "Episode: 9, State: 11, Action: 2, Reward: -0.54, New State: 11, Visits: 6\n",
      "Episode: 9, State: 6, Action: 3, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 10, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 10, State: 10, Action: 1, Reward: 0.08, New State: 10, Visits: 1\n",
      "Episode: 10, State: 5, Action: 3, Reward: 0.060000000000000005, New State: 5, Visits: 2\n",
      "Episode: 10, State: 10, Action: 1, Reward: 0.060000000000000005, New State: 10, Visits: 2\n",
      "Episode: 10, State: 5, Action: 3, Reward: 0.020000000000000004, New State: 5, Visits: 3\n",
      "Episode: 10, State: 10, Action: 1, Reward: 0.020000000000000004, New State: 10, Visits: 3\n",
      "Episode: 10, State: 5, Action: 3, Reward: -0.06, New State: 5, Visits: 4\n",
      "Episode: 10, State: 10, Action: 1, Reward: -0.06, New State: 10, Visits: 4\n",
      "Episode: 10, State: 5, Action: 3, Reward: -0.22, New State: 5, Visits: 5\n",
      "Episode: 10, State: 10, Action: 1, Reward: -0.22, New State: 10, Visits: 5\n",
      "Episode: 10, State: 5, Action: 3, Reward: -0.54, New State: 5, Visits: 6\n",
      "Episode: 10, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 11, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 11, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 12, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 12, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 13, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 13, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 14, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 14, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 15, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 15, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 16, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 16, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 17, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 17, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 18, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 18, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 19, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 19, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 20, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 20, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 21, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 21, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 22, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 22, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 23, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 23, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 24, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 24, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 25, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 25, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 26, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 26, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 27, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 27, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 28, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 28, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 29, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 29, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 30, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 30, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 31, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 31, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 32, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 32, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 33, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 33, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 34, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 34, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 35, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 35, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 36, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 36, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 37, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 37, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 38, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 38, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 39, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 39, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 40, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 40, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 41, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 41, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 42, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 42, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 43, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 43, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 44, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 44, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 45, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 45, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 46, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 46, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 47, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 47, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 48, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 48, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 49, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 49, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 50, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 50, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 51, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 51, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 52, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 52, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n",
      "Episode: 53, State: 5, Action: 1, Reward: 0.08, New State: 5, Visits: 1\n",
      "Episode: 53, State: 6, Action: 2, Reward: -0.52, New State: 6, Visits: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m      9\u001b[0m     action \u001b[38;5;241m=\u001b[39m choose_action(state, q_table, exploration_rate)\n\u001b[1;32m---> 10\u001b[0m     new_state, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Update state visits count\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     state_visits[new_state] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gymnasium\\wrappers\\env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gymnasium\\envs\\toy_text\\frozen_lake.py:308\u001b[0m, in \u001b[0;36mFrozenLakeEnv.step\u001b[1;34m(self, a)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlastaction \u001b[38;5;241m=\u001b[39m a\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 308\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mint\u001b[39m(s), r, t, \u001b[38;5;28;01mFalse\u001b[39;00m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m\"\u001b[39m: p})\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gymnasium\\envs\\toy_text\\frozen_lake.py:338\u001b[0m, in \u001b[0;36mFrozenLakeEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_text()\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# self.render_mode in {\"human\", \"rgb_array\"}:\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_gui\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gymnasium\\envs\\toy_text\\frozen_lake.py:432\u001b[0m, in \u001b[0;36mFrozenLakeEnv._render_gui\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    430\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[0;32m    431\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[0;32m    435\u001b[0m         np\u001b[38;5;241m.\u001b[39marray(pygame\u001b[38;5;241m.\u001b[39msurfarray\u001b[38;5;241m.\u001b[39mpixels3d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_surface)), axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    436\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in range(max_episodes):\n",
    "    state = env.reset()[0]  # Extract the state identifier\n",
    "    done = False\n",
    "\n",
    "    # Reset state visits count for the new episode\n",
    "    state_visits = {s: 0 for s in range(observationSpace)}\n",
    "\n",
    "    while not done:\n",
    "        action = choose_action(state, q_table, exploration_rate)\n",
    "        new_state, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        # Update state visits count\n",
    "        state_visits[new_state] += 1\n",
    "\n",
    "        # Calculate penalty for visiting the same state\n",
    "        visit_penalty = -0.01 * (2 ** state_visits[new_state])\n",
    "\n",
    "        # Check if the agent stayed in the same state\n",
    "        if new_state == state:\n",
    "            reward = visit_penalty\n",
    "        else:\n",
    "            # Check for falling into the ice\n",
    "            if terminated and reward == 0:\n",
    "                reward = -0.5  # Penalty for falling into the ice\n",
    "            elif not terminated:\n",
    "                reward = 0.1  # Reward for a safe move\n",
    "            reward += visit_penalty  # Add penalty for repeated visits\n",
    "\n",
    "        # Update the Q-table\n",
    "        update_q_table(state, action, reward, new_state, q_table, learning_rate, discount_factor)\n",
    "        \n",
    "        if terminated and reward == 1:\n",
    "            goal_reaches += 1\n",
    "\n",
    "        state = new_state\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Decay the exploration rate\n",
    "        exploration_rate = max(min_exploration_rate, exploration_rate * exploration_decay_rate)\n",
    "\n",
    "        # Print statements for debugging\n",
    "        print(f\"Episode: {episode}, State: {state}, Action: {action}, Reward: {reward}, New State: {new_state}, Visits: {state_visits[new_state]}\")\n",
    "\n",
    "    # Optional: Add code here to track and print progress, e.g., every 100 episodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
